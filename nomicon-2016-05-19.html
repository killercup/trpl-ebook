<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
  <meta name="author" content="The Rust Team">
  <meta name="dcterms.date" content="2016-05-19">
  <title>The Rustonomicon</title>
  <!--[if lt IE 9]>
    <script src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script>
  <![endif]-->
  <style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; background-color: #f8f8f8; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
pre, code { background-color: #f8f8f8; }
code > span.kw { color: #204a87; font-weight: bold; } /* Keyword */
code > span.dt { color: #204a87; } /* DataType */
code > span.dv { color: #0000cf; } /* DecVal */
code > span.bn { color: #0000cf; } /* BaseN */
code > span.fl { color: #0000cf; } /* Float */
code > span.ch { color: #4e9a06; } /* Char */
code > span.st { color: #4e9a06; } /* String */
code > span.co { color: #8f5902; font-style: italic; } /* Comment */
code > span.ot { color: #8f5902; } /* Other */
code > span.al { color: #ef2929; } /* Alert */
code > span.fu { color: #000000; } /* Function */
code > span.er { color: #a40000; font-weight: bold; } /* Error */
code > span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #000000; } /* Constant */
code > span.sc { color: #000000; } /* SpecialChar */
code > span.vs { color: #4e9a06; } /* VerbatimString */
code > span.ss { color: #4e9a06; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #000000; } /* Variable */
code > span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */
code > span.op { color: #ce5c00; font-weight: bold; } /* Operator */
code > span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */
code > span.ex { } /* Extension */
code > span.at { color: #c4a000; } /* Attribute */
code > span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */
code > span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */
  </style>
  <link href="data:text/css;charset=utf-8,%0A%0Abody%20%7B%0Afont%2Dfamily%3A%20Georgia%2C%20Palatino%2C%20%27Palatino%20Linotype%27%2C%20Times%2C%20%27Times%20New%20Roman%27%2C%20serif%3B%0Afont%2Dsize%3A%2012px%3B%0Aline%2Dheight%3A%201%2E7%3B%0Amax%2Dwidth%3A%2042em%3B%0A%7D%0A%40media%20only%20screen%20and%20%28min%2Dwidth%3A%20480px%29%20%7B%0Abody%20%7B%0Afont%2Dsize%3A%2014px%3B%0A%7D%0A%7D%0A%40media%20only%20screen%20and%20%28min%2Dwidth%3A%20768px%29%20%7B%0Abody%20%7B%0Afont%2Dsize%3A%2016px%3B%0A%7D%0A%7D%0Ah1%2C%20h2%2C%20h3%2C%20h4%2C%20h5%2C%20h6%20%7B%0Aline%2Dheight%3A%20125%25%3B%0A%7D%0Ah1%2C%20h2%2C%20h3%20%7B%0Afont%2Dweight%3A%20normal%3B%0A%7D%0Ah4%2C%20h5%2C%20h6%20%7B%0Afont%2Dweight%3A%20bold%3B%0A%7D%0Ah1%20%7B%0Afont%2Dsize%3A%202em%3B%0A%7D%0Ah2%20%7B%0Afont%2Dsize%3A%201%2E8em%3B%0A%7D%0Ah3%20%7B%0Afont%2Dsize%3A%201%2E5em%3B%0A%7D%0Ah4%20%7B%0Afont%2Dsize%3A%201%2E2em%3B%0A%7D%0Ah5%20%7B%0Afont%2Dsize%3A%201em%3B%0A%7D%0Ah6%20%7B%0Afont%2Dsize%3A%200%2E9em%3B%0A%7D%0Apre%2C%20code%2C%20kbd%2C%20samp%20%7B%0Afont%2Dfamily%3A%20monospace%3B%0Afont%2Dsize%3A%200%2E98em%3B%0A%7D%0A%0Ahtml%20%7B%0Afont%2Dsize%3A%20100%25%3B%0Aoverflow%2Dy%3A%20scroll%3B%0A%2Dwebkit%2Dtext%2Dsize%2Dadjust%3A%20100%25%3B%0A%2Dms%2Dtext%2Dsize%2Dadjust%3A%20100%25%3B%0A%7D%0Abody%20%7B%0Acolor%3A%20%23444%3B%0Apadding%3A%201em%3B%0Amargin%3A%20auto%3B%0Abackground%3A%20%23fefefe%3B%0A%7D%0Aa%20%7B%0Acolor%3A%20%230645ad%3B%0Atext%2Ddecoration%3A%20none%3B%0A%7D%0Aa%3Avisited%20%7B%0Acolor%3A%20%230b0080%3B%0A%7D%0Aa%3Ahover%20%7B%0Acolor%3A%20%2306e%3B%0A%7D%0Aa%3Aactive%20%7B%0Acolor%3A%20%23faa700%3B%0A%7D%0Aa%3Afocus%20%7B%0Aoutline%3A%20thin%20dotted%3B%0A%7D%0A%2A%3A%3A%2Dmoz%2Dselection%20%7B%0Abackground%3A%20rgba%28255%2C%20255%2C%200%2C%200%2E3%29%3B%0Acolor%3A%20%23000%3B%0A%7D%0A%2A%3A%3Aselection%20%7B%0Abackground%3A%20rgba%28255%2C%20255%2C%200%2C%200%2E3%29%3B%0Acolor%3A%20%23000%3B%0A%7D%0Aa%3A%3A%2Dmoz%2Dselection%20%7B%0Abackground%3A%20rgba%28255%2C%20255%2C%200%2C%200%2E3%29%3B%0Acolor%3A%20%230645ad%3B%0A%7D%0Aa%3A%3Aselection%20%7B%0Abackground%3A%20rgba%28255%2C%20255%2C%200%2C%200%2E3%29%3B%0Acolor%3A%20%230645ad%3B%0A%7D%0Ah1%2C%20h2%2C%20h3%2C%20h4%2C%20h5%2C%20h6%20%7B%0Acolor%3A%20%23111%3B%0Amargin%2Dtop%3A%202em%3B%0A%7D%0Ap%20%7B%0Amargin%3A%201em%200%3B%0A%7D%0Aimg%20%7B%0Amax%2Dwidth%3A%20100%25%3B%0A%7D%0Aq%20%7B%20quotes%3A%20%22%5C201C%22%20%22%5C201D%22%20%22%5C2018%22%20%22%5C2019%22%3B%20%7D%0A%5Blang%3Dde%5D%20q%20%7B%0Aquotes%3A%20%22%5C00bb%22%20%22%5C00ab%22%20%22%5C203A%22%20%22%5C2039%22%3B%0A%7D%0Ablockquote%2C%0Aaside%2Enotes%20%7B%0Acolor%3A%20%23666%3B%0Amargin%3A%200%3B%0Apadding%2Dleft%3A%203em%3B%0Aborder%2Dleft%3A%200%2E5em%20%23EEE%20solid%3B%0A%7D%0Aaside%2Enotes%20%7B%0Acolor%3A%20%23999%3B%0Aborder%2Dleft%2Dcolor%3A%20%23ffa%3B%0A%7D%0Ahr%20%7B%0Adisplay%3A%20block%3B%0Aheight%3A%202px%3B%0Aborder%3A%200%3B%0Aborder%2Dtop%3A%201px%20solid%20%23aaa%3B%0Aborder%2Dbottom%3A%201px%20solid%20%23eee%3B%0Amargin%3A%201em%200%3B%0Apadding%3A%200%3B%0A%7D%0Apre%2C%20code%2C%20kbd%2C%20samp%20%7B%0Acolor%3A%20%23000%3B%0A%7D%0Apre%20%7B%0Awhite%2Dspace%3A%20pre%3B%0Awhite%2Dspace%3A%20pre%2Dwrap%3B%0Aword%2Dwrap%3A%20break%2Dword%3B%0Apadding%3A%200%2E1em%200%2E4em%3B%0Atext%2Dindent%3A%201em%3B%0A%7D%0Ab%2C%20strong%20%7B%0Afont%2Dweight%3A%20bold%3B%0A%7D%0Adfn%20%7B%0Afont%2Dstyle%3A%20italic%3B%0A%7D%0Ains%20%7B%0Abackground%3A%20%23ff9%3B%0Acolor%3A%20%23000%3B%0Atext%2Ddecoration%3A%20none%3B%0A%7D%0Amark%20%7B%0Abackground%3A%20%23ff0%3B%0Acolor%3A%20%23000%3B%0Afont%2Dstyle%3A%20italic%3B%0Afont%2Dweight%3A%20bold%3B%0A%7D%0Asub%2C%20sup%20%7B%0Afont%2Dsize%3A%2075%25%3B%0Aline%2Dheight%3A%200%3B%0Aposition%3A%20relative%3B%0Avertical%2Dalign%3A%20baseline%3B%0A%7D%0Asup%20%7B%0Atop%3A%20%2D0%2E5em%3B%0A%7D%0Asub%20%7B%0Abottom%3A%20%2D0%2E25em%3B%0A%7D%0Aul%2C%20ol%20%7B%0Amargin%3A%201em%200%3B%0Apadding%3A%200%200%200%202em%3B%0A%7D%0Ali%20p%3Alast%2Dchild%20%7B%0Amargin%2Dbottom%3A%200%3B%0A%7D%0Aul%20ul%2C%20ol%20ol%20%7B%0Amargin%3A%20%2E3em%200%3B%0A%7D%0Adl%20%7B%0Amargin%2Dbottom%3A%201em%3B%0A%7D%0Adt%20%7B%0Afont%2Dweight%3A%20bold%3B%0Amargin%2Dbottom%3A%20%2E8em%3B%0A%7D%0Add%20%7B%0Amargin%3A%200%200%20%2E8em%202em%3B%0A%7D%0Add%3Alast%2Dchild%20%7B%0Amargin%2Dbottom%3A%200%3B%0A%7D%0Aimg%20%7B%0Aborder%3A%200%3B%0A%2Dms%2Dinterpolation%2Dmode%3A%20bicubic%3B%0Avertical%2Dalign%3A%20middle%3B%0A%7D%0Afigure%20%7B%0Adisplay%3A%20block%3B%0Atext%2Dalign%3A%20center%3B%0Amargin%3A%202em%200%3B%0A%7D%0Afigure%20img%20%7B%0Aborder%3A%20none%3B%0Amargin%3A%200%20auto%201em%3B%0A%7D%0Afigcaption%20%7B%0Afont%2Dsize%3A%200%2E8em%3B%0Afont%2Dstyle%3A%20italic%3B%0Amargin%3A%200%200%20%2E8em%3B%0A%7D%0Atable%20%7B%0Amargin%2Dbottom%3A%202em%3B%0Aborder%2Dbottom%3A%201px%20solid%20%23ddd%3B%0Aborder%2Dright%3A%201px%20solid%20%23ddd%3B%0Aborder%2Dspacing%3A%200%3B%0Aborder%2Dcollapse%3A%20collapse%3B%0A%7D%0Atable%20th%20%7B%0Apadding%3A%20%2E2em%201em%3B%0Abackground%2Dcolor%3A%20%23eee%3B%0Aborder%2Dtop%3A%201px%20solid%20%23ddd%3B%0Aborder%2Dleft%3A%201px%20solid%20%23ddd%3B%0A%7D%0Atable%20td%20%7B%0Apadding%3A%20%2E2em%201em%3B%0Aborder%2Dtop%3A%201px%20solid%20%23ddd%3B%0Aborder%2Dleft%3A%201px%20solid%20%23ddd%3B%0Avertical%2Dalign%3A%20top%3B%0A%7D%0A%2Ebyline%20%7B%0Afont%2Dsize%3A%201%2E2em%3B%0Atext%2Dalign%3A%20center%3B%0A%7D%0A%2Ereferences%20a%2Euri%20%7Bword%2Dbreak%3A%20break%2Dall%3B%7D%0Anav%2Etoc%20ul%20%7B%0Alist%2Dstyle%2Dtype%3A%20decimal%3B%0A%7D%0Anav%2Etoc%2Ealready%2Dnumbered%20ul%20%7B%0Alist%2Dstyle%2Dtype%3A%20none%3B%0A%7D%0Anav%2Etoc%2Ealready%2Dnumbered%20%3E%20ul%20%7B%0Apadding%3A%200%3B%0A%7D%0A%0A%40media%20print%20%7B%0A%2A%20%7B%0Abackground%3A%20transparent%20%21important%3B%0Acolor%3A%20black%20%21important%3B%0Afilter%3A%20none%20%21important%3B%0A%2Dms%2Dfilter%3A%20none%20%21important%3B%0A%7D%0Abody%20%7B%0Afont%2Dsize%3A%209pt%3B%0Aline%2Dheight%3A%201%2E2%3B%0Amax%2Dwidth%3A%20100%25%3B%0A%7D%0Aa%2C%20a%3Avisited%20%7B%0Atext%2Ddecoration%3A%20underline%3B%0A%7D%0Ahr%20%7B%0Aheight%3A%201px%3B%0Aborder%3A%200%3B%0Aborder%2Dbottom%3A%201px%20solid%20black%3B%0A%7D%0A%0Aabbr%5Btitle%5D%3Aafter%20%7B%0Acontent%3A%20%22%20%28%22%20attr%28title%29%20%22%29%22%3B%0A%7D%0A%2Eir%20a%3Aafter%2C%20a%5Bhref%5E%3D%22javascript%3A%22%5D%3Aafter%2C%20a%5Bhref%5E%3D%22%23%22%5D%3Aafter%20%7B%0Acontent%3A%20%22%22%3B%0A%7D%0Apre%2C%20blockquote%20%7B%0Aborder%3A%201px%20solid%20%23999%3B%0Apadding%2Dright%3A%201em%3B%0Apage%2Dbreak%2Dinside%3A%20avoid%3B%0A%7D%0Atr%2C%20img%20%7B%0Apage%2Dbreak%2Dinside%3A%20avoid%3B%0A%7D%0Aimg%20%7B%0Amax%2Dwidth%3A%20100%25%20%21important%3B%0A%7D%0A%40page%20%3Aleft%20%7B%0Amargin%3A%2025mm%2030mm%2025mm%2020mm%3B%0A%7D%0A%40page%20%3Aright%20%7B%0Amargin%3A%2025mm%2020mm%2025mm%2030mm%3B%0A%7D%0Ap%2C%20h2%2C%20h3%20%7B%0Aorphans%3A%203%3B%0Awidows%3A%203%3B%0A%7D%0Ah1%2C%20h2%2C%20h3%2C%20h4%20%7B%0Apage%2Dbreak%2Dafter%3A%20avoid%3B%0A%7D%0A%7D%0A" rel="stylesheet">
</head>
<body role="document">


<header>
  <h1 class="title">The Rustonomicon</h1>

  
  <div class="byline vcard">
    <address>
          <p class="author">The Rust Team</p>
        </address>
      <time pubdate="pubdate" date="2016-05-19" class="date">2016-05-19</time>
    </div>
</header>


<nav class="toc" id="TOC">
  <h2>Table of Contents</h2>
  <ul>
  <li><a href="#introduction">Introduction</a></li>
  <li><a href="#sec--meet-safe-and-unsafe">Meet Safe and Unsafe</a><ul>
  <li><a href="#sec--safe-unsafe-meaning">How Safe and Unsafe Interact</a></li>
  <li><a href="#sec--working-with-unsafe">Working with Unsafe</a></li>
  </ul></li>
  <li><a href="#sec--data">Data Layout</a><ul>
  <li><a href="#sec--repr-rust">repr(Rust)</a></li>
  <li><a href="#sec--exotic-sizes">Exotically Sized Types</a><ul>
  <li><a href="#dynamically-sized-types-dsts">Dynamically Sized Types (DSTs)</a></li>
  <li><a href="#zero-sized-types-zsts">Zero Sized Types (ZSTs)</a></li>
  <li><a href="#empty-types">Empty Types</a></li>
  </ul></li>
  <li><a href="#sec--other-reprs">Other reprs</a><ul>
  <li><a href="#reprc">repr(C)</a></li>
  <li><a href="#repru8-repru16-repru32-repru64">repr(u8), repr(u16), repr(u32), repr(u64)</a></li>
  <li><a href="#reprpacked">repr(packed)</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#sec--ownership">Ownership</a><ul>
  <li><a href="#sec--references">References</a><ul>
  <li><a href="#paths">Paths</a></li>
  <li><a href="#liveness">Liveness</a></li>
  <li><a href="#aliasing">Aliasing</a></li>
  </ul></li>
  <li><a href="#sec--lifetimes">Lifetimes</a><ul>
  <li><a href="#example-references-that-outlive-referents">Example: references that outlive referents</a></li>
  <li><a href="#example-aliasing-a-mutable-reference">Example: aliasing a mutable reference</a></li>
  </ul></li>
  <li><a href="#sec--lifetime-mismatch">Limits of Lifetimes</a></li>
  <li><a href="#sec--lifetime-elision">Lifetime Elision</a></li>
  <li><a href="#sec--unbounded-lifetimes">Unbounded Lifetimes</a></li>
  <li><a href="#sec--hrtb">Higher-Rank Trait Bounds</a></li>
  <li><a href="#sec--subtyping">Subtyping and Variance</a><ul>
  <li><a href="#variance">Variance</a></li>
  </ul></li>
  <li><a href="#sec--dropck">Drop Check</a><ul>
  <li><a href="#an-escape-hatch">An Escape Hatch</a></li>
  <li><a href="#is-that-all-about-drop-checker">Is that all about drop checker?</a></li>
  </ul></li>
  <li><a href="#sec--phantom-data">PhantomData</a></li>
  <li><a href="#sec--borrow-splitting">Splitting Borrows</a></li>
  </ul></li>
  <li><a href="#sec--conversions">Type Conversions</a><ul>
  <li><a href="#sec--coercions">Coercions</a></li>
  <li><a href="#sec--dot-operator">The Dot Operator</a></li>
  <li><a href="#sec--casts">Casts</a></li>
  <li><a href="#sec--transmutes">Transmutes</a></li>
  </ul></li>
  <li><a href="#sec--uninitialized">Uninitialized Memory</a><ul>
  <li><a href="#sec--checked-uninit">Checked</a></li>
  <li><a href="#sec--drop-flags">Drop Flags</a></li>
  <li><a href="#sec--unchecked-uninit">Unchecked</a></li>
  </ul></li>
  <li><a href="#sec--obrm">Ownership Based Resource Management</a><ul>
  <li><a href="#sec--constructors">Constructors</a></li>
  <li><a href="#sec--destructors">Destructors</a></li>
  <li><a href="#sec--leaking">Leaking</a></li>
  </ul></li>
  <li><a href="#sec--unwinding">Unwinding</a><ul>
  <li><a href="#sec--exception-safety">Exception Safety</a></li>
  <li><a href="#sec--poisoning">Poisoning</a></li>
  </ul></li>
  <li><a href="#sec--concurrency">Concurrency</a><ul>
  <li><a href="#sec--races">Races</a></li>
  <li><a href="#sec--send-and-sync">Send and Sync</a></li>
  <li><a href="#sec--atomics">Atomics</a><ul>
  <li><a href="#compiler-reordering">Compiler Reordering</a></li>
  <li><a href="#hardware-reordering">Hardware Reordering</a></li>
  <li><a href="#data-accesses">Data Accesses</a></li>
  <li><a href="#sequentially-consistent">Sequentially Consistent</a></li>
  <li><a href="#acquire-release">Acquire-Release</a></li>
  <li><a href="#relaxed">Relaxed</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#sec--vec">Implementing Vec</a><ul>
  <li><a href="#sec--vec-layout">Layout</a></li>
  <li><a href="#sec--vec-alloc">Allocating</a></li>
  <li><a href="#sec--vec-push-pop">Push and Pop</a></li>
  <li><a href="#sec--vec-dealloc">Deallocating</a></li>
  <li><a href="#sec--vec-deref">Deref</a></li>
  <li><a href="#sec--vec-insert-remove">Insert and Remove</a></li>
  <li><a href="#sec--vec-into-iter">IntoIter</a></li>
  <li><a href="#sec--vec-raw">RawVec</a></li>
  <li><a href="#sec--vec-drain">Drain</a></li>
  <li><a href="#sec--vec-zsts">Handling Zero-Sized Types</a></li>
  <li><a href="#sec--vec-final">Final Code</a></li>
  </ul></li>
  <li><a href="#sec--arc-and-mutex">Implementing Arc and Mutex</a></li>
  </ul>
</nav>

<article role="main">
  <section id="introduction" class="level1">
  <h1>Introduction</h1>
  <section id="the-dark-arts-of-advanced-and-unsafe-rust-programming" class="level4">
  <h4>The Dark Arts of Advanced and Unsafe Rust Programming</h4>
  <p><strong>NOTE: This is a draft document, and may contain serious errors</strong></p>
  <blockquote>
  <p>Instead of the programs I had hoped for, there came only a shuddering blackness and ineffable loneliness; and I saw at last a fearful truth which no one had ever dared to breathe before — the unwhisperable secret of secrets — The fact that this language of stone and stridor is not a sentient perpetuation of Rust as London is of Old London and Paris of Old Paris, but that it is in fact quite unsafe, its sprawling body imperfectly embalmed and infested with queer animate things which have nothing to do with it as it was in compilation.</p>
  </blockquote>
  <p>This book digs into all the awful details that are necessary to understand in order to write correct Unsafe Rust programs. Due to the nature of this problem, it may lead to unleashing untold horrors that shatter your psyche into a billion infinitesimal fragments of despair.</p>
  <p>Should you wish a long and happy career of writing Rust programs, you should turn back now and forget you ever saw this book. It is not necessary. However if you intend to write unsafe code – or just want to dig into the guts of the language – this book contains invaluable information.</p>
  <p>Unlike <a href="http://doc.rust-lang.org/book/">The Book</a> we will be assuming considerable prior knowledge. In particular, you should be comfortable with basic systems programming and Rust. If you don’t feel comfortable with these topics, you should consider <a href="http://doc.rust-lang.org/book/">reading The Book</a> first. Though we will not be assuming that you have, and will take care to occasionally give a refresher on the basics where appropriate. You can skip straight to this book if you want; just know that we won’t be explaining everything from the ground up.</p>
  <p>To be clear, this book goes into deep detail. We’re going to dig into exception-safety, pointer aliasing, memory models, and even some type-theory. We will also be spending a lot of time talking about the different kinds of safety and guarantees.</p>
  </section>
  </section>
  <section id="sec--meet-safe-and-unsafe" class="level1">
  <h1>Meet Safe and Unsafe</h1>
  <p>Programmers in safe “high-level” languages face a fundamental dilemma. On one hand, it would be <em>really</em> great to just say what you want and not worry about how it’s done. On the other hand, that can lead to unacceptably poor performance. It may be necessary to drop down to less clear or idiomatic practices to get the performance characteristics you want. Or maybe you just throw up your hands in disgust and decide to shell out to an implementation in a less sugary-wonderful <em>unsafe</em> language.</p>
  <p>Worse, when you want to talk directly to the operating system, you <em>have</em> to talk to an unsafe language: <em>C</em>. C is ever-present and unavoidable. It’s the lingua-franca of the programming world. Even other safe languages generally expose C interfaces for the world at large! Regardless of why you’re doing it, as soon as your program starts talking to C it stops being safe.</p>
  <p>With that said, Rust is <em>totally</em> a safe programming language.</p>
  <p>Well, Rust <em>has</em> a safe programming language. Let’s step back a bit.</p>
  <p>Rust can be thought of as being composed of two programming languages: <em>Safe Rust</em> and <em>Unsafe Rust</em>. Safe Rust is For Reals Totally Safe. Unsafe Rust, unsurprisingly, is <em>not</em> For Reals Totally Safe. In fact, Unsafe Rust lets you do some really crazy unsafe things.</p>
  <p>Safe Rust is the <em>true</em> Rust programming language. If all you do is write Safe Rust, you will never have to worry about type-safety or memory-safety. You will never endure a null or dangling pointer, or any of that Undefined Behavior nonsense.</p>
  <p><em>That’s totally awesome.</em></p>
  <p>The standard library also gives you enough utilities out-of-the-box that you’ll be able to write awesome high-performance applications and libraries in pure idiomatic Safe Rust.</p>
  <p>But maybe you want to talk to another language. Maybe you’re writing a low-level abstraction not exposed by the standard library. Maybe you’re <em>writing</em> the standard library (which is written entirely in Rust). Maybe you need to do something the type-system doesn’t understand and just <em>frob some dang bits</em>. Maybe you need Unsafe Rust.</p>
  <p>Unsafe Rust is exactly like Safe Rust with all the same rules and semantics. However Unsafe Rust lets you do some <em>extra</em> things that are Definitely Not Safe.</p>
  <p>The only things that are different in Unsafe Rust are that you can:</p>
  <ul>
  <li>Dereference raw pointers</li>
  <li>Call <code>unsafe</code> functions (including C functions, intrinsics, and the raw allocator)</li>
  <li>Implement <code>unsafe</code> traits</li>
  <li>Mutate statics</li>
  </ul>
  <p>That’s it. The reason these operations are relegated to Unsafe is that misusing any of these things will cause the ever dreaded Undefined Behavior. Invoking Undefined Behavior gives the compiler full rights to do arbitrarily bad things to your program. You definitely <em>should not</em> invoke Undefined Behavior.</p>
  <p>Unlike C, Undefined Behavior is pretty limited in scope in Rust. All the core language cares about is preventing the following things:</p>
  <ul>
  <li>Dereferencing null or dangling pointers</li>
  <li>Reading <a href="#sec--uninitialized">uninitialized memory</a></li>
  <li>Breaking the [pointer aliasing rules]</li>
  <li>Producing invalid primitive values:
  <ul>
  <li>dangling/null references</li>
  <li>a <code>bool</code> that isn’t 0 or 1</li>
  <li>an undefined <code>enum</code> discriminant</li>
  <li>a <code>char</code> outside the ranges [0x0, 0xD7FF] and [0xE000, 0x10FFFF]</li>
  <li>A non-utf8 <code>str</code></li>
  </ul></li>
  <li>Unwinding into another language</li>
  <li>Causing a <a href="#sec--races">data race</a></li>
  </ul>
  <p>That’s it. That’s all the causes of Undefined Behavior baked into Rust. Of course, unsafe functions and traits are free to declare arbitrary other constraints that a program must maintain to avoid Undefined Behavior. However, generally violations of these constraints will just transitively lead to one of the above problems. Some additional constraints may also derive from compiler intrinsics that make special assumptions about how code can be optimized.</p>
  <p>Rust is otherwise quite permissive with respect to other dubious operations. Rust considers it “safe” to:</p>
  <ul>
  <li>Deadlock</li>
  <li>Have a <a href="#sec--races">race condition</a></li>
  <li>Leak memory</li>
  <li>Fail to call destructors</li>
  <li>Overflow integers</li>
  <li>Abort the program</li>
  <li>Delete the production database</li>
  </ul>
  <p>However any program that actually manages to do such a thing is <em>probably</em> incorrect. Rust provides lots of tools to make these things rare, but these problems are considered impractical to categorically prevent.</p>
  <section id="sec--safe-unsafe-meaning" class="level2">
  <h2>How Safe and Unsafe Interact</h2>
  <p>So what’s the relationship between Safe and Unsafe Rust? How do they interact?</p>
  <p>Rust models the separation between Safe and Unsafe Rust with the <code>unsafe</code> keyword, which can be thought as a sort of <em>foreign function interface</em> (FFI) between Safe and Unsafe Rust. This is the magic behind why we can say Safe Rust is a safe language: all the scary unsafe bits are relegated exclusively to FFI <em>just like every other safe language</em>.</p>
  <p>However because one language is a subset of the other, the two can be cleanly intermixed as long as the boundary between Safe and Unsafe Rust is denoted with the <code>unsafe</code> keyword. No need to write headers, initialize runtimes, or any of that other FFI boiler-plate.</p>
  <p>There are several places <code>unsafe</code> can appear in Rust today, which can largely be grouped into two categories:</p>
  <ul>
  <li>There are unchecked contracts here. To declare you understand this, I require you to write <code>unsafe</code> elsewhere:
  <ul>
  <li>On functions, <code>unsafe</code> is declaring the function to be unsafe to call. Users of the function must check the documentation to determine what this means, and then have to write <code>unsafe</code> somewhere to identify that they’re aware of the danger.</li>
  <li>On trait declarations, <code>unsafe</code> is declaring that <em>implementing</em> the trait is an unsafe operation, as it has contracts that other unsafe code is free to trust blindly. (More on this below.)</li>
  </ul></li>
  <li>I am declaring that I have, to the best of my knowledge, adhered to the unchecked contracts:
  <ul>
  <li>On trait implementations, <code>unsafe</code> is declaring that the contract of the <code>unsafe</code> trait has been upheld.</li>
  <li>On blocks, <code>unsafe</code> is declaring any unsafety from an unsafe operation within to be handled, and therefore the parent function is safe.</li>
  </ul></li>
  </ul>
  <p>There is also <code>#[unsafe_no_drop_flag]</code>, which is a special case that exists for historical reasons and is in the process of being phased out. See the section on <a href="#sec--drop-flags">drop flags</a> for details.</p>
  <p>Some examples of unsafe functions:</p>
  <ul>
  <li><code>slice::get_unchecked</code> will perform unchecked indexing, allowing memory safety to be freely violated.</li>
  <li>every raw pointer to sized type has intrinsic <code>offset</code> method that invokes Undefined Behavior if it is not “in bounds” as defined by LLVM.</li>
  <li><code>mem::transmute</code> reinterprets some value as having the given type, bypassing type safety in arbitrary ways. (see [conversions] for details)</li>
  <li>All FFI functions are <code>unsafe</code> because they can do arbitrary things. C being an obvious culprit, but generally any language can do something that Rust isn’t happy about.</li>
  </ul>
  <p>As of Rust 1.0 there are exactly two unsafe traits:</p>
  <ul>
  <li><code>Send</code> is a marker trait (it has no actual API) that promises implementors are safe to send (move) to another thread.</li>
  <li><code>Sync</code> is a marker trait that promises that threads can safely share implementors through a shared reference.</li>
  </ul>
  <p>The need for unsafe traits boils down to the fundamental property of safe code:</p>
  <p><strong>No matter how completely awful Safe code is, it can’t cause Undefined Behavior.</strong></p>
  <p>This means that Unsafe Rust, <strong>the royal vanguard of Undefined Behavior</strong>, has to be <em>super paranoid</em> about generic safe code. To be clear, Unsafe Rust is totally free to trust specific safe code. Anything else would degenerate into infinite spirals of paranoid despair. In particular it’s generally regarded as ok to trust the standard library to be correct. <code>std</code> is effectively an extension of the language, and you really just have to trust the language. If <code>std</code> fails to uphold the guarantees it declares, then it’s basically a language bug.</p>
  <p>That said, it would be best to minimize <em>needlessly</em> relying on properties of concrete safe code. Bugs happen! Of course, I must reinforce that this is only a concern for Unsafe code. Safe code can blindly trust anyone and everyone as far as basic memory-safety is concerned.</p>
  <p>On the other hand, safe traits are free to declare arbitrary contracts, but because implementing them is safe, unsafe code can’t trust those contracts to actually be upheld. This is different from the concrete case because <em>anyone</em> can randomly implement the interface. There is something fundamentally different about trusting a particular piece of code to be correct, and trusting <em>all the code that will ever be written</em> to be correct.</p>
  <p>For instance Rust has <code>PartialOrd</code> and <code>Ord</code> traits to try to differentiate between types which can “just” be compared, and those that actually implement a total ordering. Pretty much every API that wants to work with data that can be compared wants Ord data. For instance, a sorted map like BTreeMap <em>doesn’t even make sense</em> for partially ordered types. If you claim to implement Ord for a type, but don’t actually provide a proper total ordering, BTreeMap will get <em>really confused</em> and start making a total mess of itself. Data that is inserted may be impossible to find!</p>
  <p>But that’s okay. BTreeMap is safe, so it guarantees that even if you give it a completely garbage Ord implementation, it will still do something <em>safe</em>. You won’t start reading uninitialized or unallocated memory. In fact, BTreeMap manages to not actually lose any of your data. When the map is dropped, all the destructors will be successfully called! Hooray!</p>
  <p>However BTreeMap is implemented using a modest spoonful of Unsafe Rust (most collections are). That means that it’s not necessarily <em>trivially true</em> that a bad Ord implementation will make BTreeMap behave safely. BTreeMap must be sure not to rely on Ord <em>where safety is at stake</em>. Ord is provided by safe code, and safety is not safe code’s responsibility to uphold.</p>
  <p>But wouldn’t it be grand if there was some way for Unsafe to trust some trait contracts <em>somewhere</em>? This is the problem that unsafe traits tackle: by marking <em>the trait itself</em> as unsafe to implement, unsafe code can trust the implementation to uphold the trait’s contract. Although the trait implementation may be incorrect in arbitrary other ways.</p>
  <p>For instance, given a hypothetical UnsafeOrd trait, this is technically a valid implementation:</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">unsafe</span> <span class="kw">impl</span> UnsafeOrd <span class="kw">for</span> MyType {
      <span class="kw">fn</span> cmp(&amp;<span class="kw">self</span>, other: &amp;<span class="kw">Self</span>) -&gt; Ordering {
          Ordering::Equal
      }
  }</code></pre></div>
  <p>But it’s probably not the implementation you want.</p>
  <p>Rust has traditionally avoided making traits unsafe because it makes Unsafe pervasive, which is not desirable. The reason Send and Sync are unsafe is because thread safety is a <em>fundamental property</em> that unsafe code cannot possibly hope to defend against in the same way it would defend against a bad Ord implementation. The only way to possibly defend against thread-unsafety would be to <em>not use threading at all</em>. Making every load and store atomic isn’t even sufficient, because it’s possible for complex invariants to exist between disjoint locations in memory. For instance, the pointer and capacity of a Vec must be in sync.</p>
  <p>Even concurrent paradigms that are traditionally regarded as Totally Safe like message passing implicitly rely on some notion of thread safety – are you really message-passing if you pass a pointer? Send and Sync therefore require some fundamental level of trust that Safe code can’t provide, so they must be unsafe to implement. To help obviate the pervasive unsafety that this would introduce, Send (resp. Sync) is automatically derived for all types composed only of Send (resp. Sync) values. 99% of types are Send and Sync, and 99% of those never actually say it (the remaining 1% is overwhelmingly synchronization primitives).</p>
  </section>
  <section id="sec--working-with-unsafe" class="level2">
  <h2>Working with Unsafe</h2>
  <p>Rust generally only gives us the tools to talk about Unsafe Rust in a scoped and binary manner. Unfortunately, reality is significantly more complicated than that. For instance, consider the following toy function:</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">fn</span> index(idx: <span class="dt">usize</span>, arr: &amp;[<span class="dt">u8</span>]) -&gt; <span class="dt">Option</span>&lt;<span class="dt">u8</span>&gt; {
      <span class="kw">if</span> idx &lt; arr.len() {
          <span class="kw">unsafe</span> {
              <span class="cn">Some</span>(*arr.get_unchecked(idx))
          }
      } <span class="kw">else</span> {
          <span class="cn">None</span>
      }
  }</code></pre></div>
  <p>Clearly, this function is safe. We check that the index is in bounds, and if it is, index into the array in an unchecked manner. But even in such a trivial function, the scope of the unsafe block is questionable. Consider changing the <code>&lt;</code> to a <code>&lt;=</code>:</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">fn</span> index(idx: <span class="dt">usize</span>, arr: &amp;[<span class="dt">u8</span>]) -&gt; <span class="dt">Option</span>&lt;<span class="dt">u8</span>&gt; {
      <span class="kw">if</span> idx &lt;= arr.len() {
          <span class="kw">unsafe</span> {
              <span class="cn">Some</span>(*arr.get_unchecked(idx))
          }
      } <span class="kw">else</span> {
          <span class="cn">None</span>
      }
  }</code></pre></div>
  <p>This program is now unsound, and yet <em>we only modified safe code</em>. This is the fundamental problem of safety: it’s non-local. The soundness of our unsafe operations necessarily depends on the state established by otherwise “safe” operations.</p>
  <p>Safety is modular in the sense that opting into unsafety doesn’t require you to consider arbitrary other kinds of badness. For instance, doing an unchecked index into a slice doesn’t mean you suddenly need to worry about the slice being null or containing uninitialized memory. Nothing fundamentally changes. However safety <em>isn’t</em> modular in the sense that programs are inherently stateful and your unsafe operations may depend on arbitrary other state.</p>
  <p>Trickier than that is when we get into actual statefulness. Consider a simple implementation of <code>Vec</code>:</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">use</span> std::ptr;
  
  <span class="co">// Note this definition is insufficient. See the section on implementing Vec.</span>
  <span class="kw">pub</span> <span class="kw">struct</span> <span class="dt">Vec</span>&lt;T&gt; {
      ptr: *<span class="kw">mut</span> T,
      len: <span class="dt">usize</span>,
      cap: <span class="dt">usize</span>,
  }
  
  <span class="co">// Note this implementation does not correctly handle zero-sized types.</span>
  <span class="co">// We currently live in a nice imaginary world of only positive fixed-size</span>
  <span class="co">// types.</span>
  <span class="kw">impl</span>&lt;T&gt; <span class="dt">Vec</span>&lt;T&gt; {
      <span class="kw">pub</span> <span class="kw">fn</span> push(&amp;<span class="kw">mut</span> <span class="kw">self</span>, elem: T) {
          <span class="kw">if</span> <span class="kw">self</span>.len == <span class="kw">self</span>.cap {
              <span class="co">// not important for this example</span>
              <span class="kw">self</span>.reallocate();
          }
          <span class="kw">unsafe</span> {
              ptr::write(<span class="kw">self</span>.ptr.offset(<span class="kw">self</span>.len <span class="kw">as</span> <span class="dt">isize</span>), elem);
              <span class="kw">self</span>.len += <span class="dv">1</span>;
          }
      }
  
      # <span class="kw">fn</span> reallocate(&amp;<span class="kw">mut</span> <span class="kw">self</span>) { }
  }</code></pre></div>
  <p>This code is simple enough to reasonably audit and verify. Now consider adding the following method:</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">fn</span> make_room(&amp;<span class="kw">mut</span> <span class="kw">self</span>) {
      <span class="co">// grow the capacity</span>
      <span class="kw">self</span>.cap += <span class="dv">1</span>;
  }</code></pre></div>
  <p>This code is 100% Safe Rust but it is also completely unsound. Changing the capacity violates the invariants of Vec (that <code>cap</code> reflects the allocated space in the Vec). This is not something the rest of Vec can guard against. It <em>has</em> to trust the capacity field because there’s no way to verify it.</p>
  <p><code>unsafe</code> does more than pollute a whole function: it pollutes a whole <em>module</em>. Generally, the only bullet-proof way to limit the scope of unsafe code is at the module boundary with privacy.</p>
  <p>However this works <em>perfectly</em>. The existence of <code>make_room</code> is <em>not</em> a problem for the soundness of Vec because we didn’t mark it as public. Only the module that defines this function can call it. Also, <code>make_room</code> directly accesses the private fields of Vec, so it can only be written in the same module as Vec.</p>
  <p>It is therefore possible for us to write a completely safe abstraction that relies on complex invariants. This is <em>critical</em> to the relationship between Safe Rust and Unsafe Rust. We have already seen that Unsafe code must trust <em>some</em> Safe code, but can’t trust <em>generic</em> Safe code. It can’t trust an arbitrary implementor of a trait or any function that was passed to it to be well-behaved in a way that safe code doesn’t care about.</p>
  <p>However if unsafe code couldn’t prevent client safe code from messing with its state in arbitrary ways, safety would be a lost cause. Thankfully, it <em>can</em> prevent arbitrary code from messing with critical state due to privacy.</p>
  <p>Safety lives!</p>
  </section>
  </section>
  <section id="sec--data" class="level1">
  <h1>Data Layout</h1>
  <p>Low-level programming cares a lot about data layout. It’s a big deal. It also pervasively influences the rest of the language, so we’re going to start by digging into how data is represented in Rust.</p>
  <section id="sec--repr-rust" class="level2">
  <h2>repr(Rust)</h2>
  <p>First and foremost, all types have an alignment specified in bytes. The alignment of a type specifies what addresses are valid to store the value at. A value of alignment <code>n</code> must only be stored at an address that is a multiple of <code>n</code>. So alignment 2 means you must be stored at an even address, and 1 means that you can be stored anywhere. Alignment is at least 1, and always a power of 2. Most primitives are generally aligned to their size, although this is platform-specific behavior. In particular, on x86 <code>u64</code> and <code>f64</code> may be only aligned to 32 bits.</p>
  <p>A type’s size must always be a multiple of its alignment. This ensures that an array of that type may always be indexed by offsetting by a multiple of its size. Note that the size and alignment of a type may not be known statically in the case of <a href="#dynamically-sized-types-dsts">dynamically sized types</a>.</p>
  <p>Rust gives you the following ways to lay out composite data:</p>
  <ul>
  <li>structs (named product types)</li>
  <li>tuples (anonymous product types)</li>
  <li>arrays (homogeneous product types)</li>
  <li>enums (named sum types – tagged unions)</li>
  </ul>
  <p>An enum is said to be <em>C-like</em> if none of its variants have associated data.</p>
  <p>Composite structures will have an alignment equal to the maximum of their fields’ alignment. Rust will consequently insert padding where necessary to ensure that all fields are properly aligned and that the overall type’s size is a multiple of its alignment. For instance:</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">struct</span> A {
      a: <span class="dt">u8</span>,
      b: <span class="dt">u32</span>,
      c: <span class="dt">u16</span>,
  }</code></pre></div>
  <p>will be 32-bit aligned on an architecture that aligns these primitives to their respective sizes. The whole struct will therefore have a size that is a multiple of 32-bits. It will potentially become:</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">struct</span> A {
      a: <span class="dt">u8</span>,
      _pad1: [<span class="dt">u8</span>; <span class="dv">3</span>], <span class="co">// to align `b`</span>
      b: <span class="dt">u32</span>,
      c: <span class="dt">u16</span>,
      _pad2: [<span class="dt">u8</span>; <span class="dv">2</span>], <span class="co">// to make overall size multiple of 4</span>
  }</code></pre></div>
  <p>There is <em>no indirection</em> for these types; all data is stored within the struct, as you would expect in C. However with the exception of arrays (which are densely packed and in-order), the layout of data is not by default specified in Rust. Given the two following struct definitions:</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">struct</span> A {
      a: <span class="dt">i32</span>,
      b: <span class="dt">u64</span>,
  }
  
  <span class="kw">struct</span> B {
      a: <span class="dt">i32</span>,
      b: <span class="dt">u64</span>,
  }</code></pre></div>
  <p>Rust <em>does</em> guarantee that two instances of A have their data laid out in exactly the same way. However Rust <em>does not</em> currently guarantee that an instance of A has the same field ordering or padding as an instance of B, though in practice there’s no reason why they wouldn’t.</p>
  <p>With A and B as written, this point would seem to be pedantic, but several other features of Rust make it desirable for the language to play with data layout in complex ways.</p>
  <p>For instance, consider this struct:</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">struct</span> Foo&lt;T, U&gt; {
      count: <span class="dt">u16</span>,
      data1: T,
      data2: U,
  }</code></pre></div>
  <p>Now consider the monomorphizations of <code>Foo&lt;u32, u16&gt;</code> and <code>Foo&lt;u16, u32&gt;</code>. If Rust lays out the fields in the order specified, we expect it to pad the values in the struct to satisfy their alignment requirements. So if Rust didn’t reorder fields, we would expect it to produce the following:</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">struct</span> Foo&lt;<span class="dt">u16</span>, <span class="dt">u32</span>&gt; {
      count: <span class="dt">u16</span>,
      data1: <span class="dt">u16</span>,
      data2: <span class="dt">u32</span>,
  }
  
  <span class="kw">struct</span> Foo&lt;<span class="dt">u32</span>, <span class="dt">u16</span>&gt; {
      count: <span class="dt">u16</span>,
      _pad1: <span class="dt">u16</span>,
      data1: <span class="dt">u32</span>,
      data2: <span class="dt">u16</span>,
      _pad2: <span class="dt">u16</span>,
  }</code></pre></div>
  <p>The latter case quite simply wastes space. An optimal use of space therefore requires different monomorphizations to have <em>different field orderings</em>.</p>
  <p><strong>Note: this is a hypothetical optimization that is not yet implemented in Rust 1.0</strong></p>
  <p>Enums make this consideration even more complicated. Naively, an enum such as:</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">enum</span> Foo {
      A(<span class="dt">u32</span>),
      B(<span class="dt">u64</span>),
      C(<span class="dt">u8</span>),
  }</code></pre></div>
  <p>would be laid out as:</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">struct</span> FooRepr {
      data: <span class="dt">u64</span>, <span class="co">// this is either a u64, u32, or u8 based on `tag`</span>
      tag: <span class="dt">u8</span>,   <span class="co">// 0 = A, 1 = B, 2 = C</span>
  }</code></pre></div>
  <p>And indeed this is approximately how it would be laid out in general (modulo the size and position of <code>tag</code>).</p>
  <p>However there are several cases where such a representation is inefficient. The classic case of this is Rust’s “null pointer optimization”: an enum consisting of a single outer unit variant (e.g. <code>None</code>) and a (potentially nested) non- nullable pointer variant (e.g. <code>&amp;T</code>) makes the tag unnecessary, because a null pointer value can safely be interpreted to mean that the unit variant is chosen instead. The net result is that, for example, <code>size_of::&lt;Option&lt;&amp;T&gt;&gt;() == size_of::&lt;&amp;T&gt;()</code>.</p>
  <p>There are many types in Rust that are, or contain, non-nullable pointers such as <code>Box&lt;T&gt;</code>, <code>Vec&lt;T&gt;</code>, <code>String</code>, <code>&amp;T</code>, and <code>&amp;mut T</code>. Similarly, one can imagine nested enums pooling their tags into a single discriminant, as they are by definition known to have a limited range of valid values. In principle enums could use fairly elaborate algorithms to cache bits throughout nested types with special constrained representations. As such it is <em>especially</em> desirable that we leave enum layout unspecified today.</p>
  </section>
  <section id="sec--exotic-sizes" class="level2">
  <h2>Exotically Sized Types</h2>
  <p>Most of the time, we think in terms of types with a fixed, positive size. This is not always the case, however.</p>
  <section id="dynamically-sized-types-dsts" class="level3">
  <h3>Dynamically Sized Types (DSTs)</h3>
  <p>Rust in fact supports Dynamically Sized Types (DSTs): types without a statically known size or alignment. On the surface, this is a bit nonsensical: Rust <em>must</em> know the size and alignment of something in order to correctly work with it! In this regard, DSTs are not normal types. Due to their lack of a statically known size, these types can only exist behind some kind of pointer. Any pointer to a DST consequently becomes a <em>fat</em> pointer consisting of the pointer and the information that “completes” them (more on this below).</p>
  <p>There are two major DSTs exposed by the language: trait objects, and slices.</p>
  <p>A trait object represents some type that implements the traits it specifies. The exact original type is <em>erased</em> in favor of runtime reflection with a vtable containing all the information necessary to use the type. This is the information that completes a trait object: a pointer to its vtable.</p>
  <p>A slice is simply a view into some contiguous storage – typically an array or <code>Vec</code>. The information that completes a slice is just the number of elements it points to.</p>
  <p>Structs can actually store a single DST directly as their last field, but this makes them a DST as well:</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="co">// Can't be stored on the stack directly</span>
  <span class="kw">struct</span> Foo {
      info: <span class="dt">u32</span>,
      data: [<span class="dt">u8</span>],
  }</code></pre></div>
  <p><strong>NOTE: <a href="https://github.com/rust-lang/rust/issues/26403">As of Rust 1.0 struct DSTs are broken if the last field has a variable position based on its alignment</a>.</strong></p>
  </section>
  <section id="zero-sized-types-zsts" class="level3">
  <h3>Zero Sized Types (ZSTs)</h3>
  <p>Rust actually allows types to be specified that occupy no space:</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">struct</span> Foo; <span class="co">// No fields = no size</span>
  
  <span class="co">// All fields have no size = no size</span>
  <span class="kw">struct</span> Baz {
      foo: Foo,
      qux: (),      <span class="co">// empty tuple has no size</span>
      baz: [<span class="dt">u8</span>; <span class="dv">0</span>], <span class="co">// empty array has no size</span>
  }</code></pre></div>
  <p>On their own, Zero Sized Types (ZSTs) are, for obvious reasons, pretty useless. However as with many curious layout choices in Rust, their potential is realized in a generic context: Rust largely understands that any operation that produces or stores a ZST can be reduced to a no-op. First off, storing it doesn’t even make sense – it doesn’t occupy any space. Also there’s only one value of that type, so anything that loads it can just produce it from the aether – which is also a no-op since it doesn’t occupy any space.</p>
  <p>One of the most extreme example’s of this is Sets and Maps. Given a <code>Map&lt;Key, Value&gt;</code>, it is common to implement a <code>Set&lt;Key&gt;</code> as just a thin wrapper around <code>Map&lt;Key, UselessJunk&gt;</code>. In many languages, this would necessitate allocating space for UselessJunk and doing work to store and load UselessJunk only to discard it. Proving this unnecessary would be a difficult analysis for the compiler.</p>
  <p>However in Rust, we can just say that <code>Set&lt;Key&gt; = Map&lt;Key, ()&gt;</code>. Now Rust statically knows that every load and store is useless, and no allocation has any size. The result is that the monomorphized code is basically a custom implementation of a HashSet with none of the overhead that HashMap would have to support values.</p>
  <p>Safe code need not worry about ZSTs, but <em>unsafe</em> code must be careful about the consequence of types with no size. In particular, pointer offsets are no-ops, and standard allocators (including jemalloc, the one used by default in Rust) may return <code>nullptr</code> when a zero-sized allocation is requested, which is indistinguishable from out of memory.</p>
  </section>
  <section id="empty-types" class="level3">
  <h3>Empty Types</h3>
  <p>Rust also enables types to be declared that <em>cannot even be instantiated</em>. These types can only be talked about at the type level, and never at the value level. Empty types can be declared by specifying an enum with no variants:</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">enum</span> Void {} <span class="co">// No variants = EMPTY</span></code></pre></div>
  <p>Empty types are even more marginal than ZSTs. The primary motivating example for Void types is type-level unreachability. For instance, suppose an API needs to return a Result in general, but a specific case actually is infallible. It’s actually possible to communicate this at the type level by returning a <code>Result&lt;T, Void&gt;</code>. Consumers of the API can confidently unwrap such a Result knowing that it’s <em>statically impossible</em> for this value to be an <code>Err</code>, as this would require providing a value of type <code>Void</code>.</p>
  <p>In principle, Rust can do some interesting analyses and optimizations based on this fact. For instance, <code>Result&lt;T, Void&gt;</code> could be represented as just <code>T</code>, because the <code>Err</code> case doesn’t actually exist. The following <em>could</em> also compile:</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">enum</span> Void {}
  
  <span class="kw">let</span> res: <span class="dt">Result</span>&lt;<span class="dt">u32</span>, Void&gt; = <span class="cn">Ok</span>(<span class="dv">0</span>);
  
  <span class="co">// Err doesn't exist anymore, so Ok is actually irrefutable.</span>
  <span class="kw">let</span> <span class="cn">Ok</span>(num) = res;</code></pre></div>
  <p>But neither of these tricks work today, so all Void types get you is the ability to be confident that certain situations are statically impossible.</p>
  <p>One final subtle detail about empty types is that raw pointers to them are actually valid to construct, but dereferencing them is Undefined Behavior because that doesn’t actually make sense. That is, you could model C’s <code>void *</code> type with <code>*const Void</code>, but this doesn’t necessarily gain anything over using e.g. <code>*const ()</code>, which <em>is</em> safe to randomly dereference.</p>
  </section>
  </section>
  <section id="sec--other-reprs" class="level2">
  <h2>Other reprs</h2>
  <p>Rust allows you to specify alternative data layout strategies from the default.</p>
  <section id="reprc" class="level3">
  <h3>repr(C)</h3>
  <p>This is the most important <code>repr</code>. It has fairly simple intent: do what C does. The order, size, and alignment of fields is exactly what you would expect from C or C++. Any type you expect to pass through an FFI boundary should have <code>repr(C)</code>, as C is the lingua-franca of the programming world. This is also necessary to soundly do more elaborate tricks with data layout such as reinterpreting values as a different type.</p>
  <p>However, the interaction with Rust’s more exotic data layout features must be kept in mind. Due to its dual purpose as “for FFI” and “for layout control”, <code>repr(C)</code> can be applied to types that will be nonsensical or problematic if passed through the FFI boundary.</p>
  <ul>
  <li><p>ZSTs are still zero-sized, even though this is not a standard behavior in C, and is explicitly contrary to the behavior of an empty type in C++, which still consumes a byte of space.</p></li>
  <li><p>DSTs, tuples, and tagged unions are not a concept in C and as such are never FFI safe.</p></li>
  <li><p>Tuple structs are like structs with regards to <code>repr(C)</code>, as the only difference from a struct is that the fields aren’t named.</p></li>
  <li><p><strong>If the type would have any <a href="#sec--drop-flags">drop flags</a>, they will still be added</strong></p></li>
  <li><p>This is equivalent to one of <code>repr(u*)</code> (see the next section) for enums. The chosen size is the default enum size for the target platform’s C ABI. Note that enum representation in C is implementation defined, so this is really a “best guess”. In particular, this may be incorrect when the C code of interest is compiled with certain flags.</p></li>
  </ul>
  </section>
  <section id="repru8-repru16-repru32-repru64" class="level3">
  <h3>repr(u8), repr(u16), repr(u32), repr(u64)</h3>
  <p>These specify the size to make a C-like enum. If the discriminant overflows the integer it has to fit in, it will produce a compile-time error. You can manually ask Rust to allow this by setting the overflowing element to explicitly be 0. However Rust will not allow you to create an enum where two variants have the same discriminant.</p>
  <p>On non-C-like enums, this will inhibit certain optimizations like the null- pointer optimization.</p>
  <p>These reprs have no effect on a struct.</p>
  </section>
  <section id="reprpacked" class="level3">
  <h3>repr(packed)</h3>
  <p><code>repr(packed)</code> forces Rust to strip any padding, and only align the type to a byte. This may improve the memory footprint, but will likely have other negative side-effects.</p>
  <p>In particular, most architectures <em>strongly</em> prefer values to be aligned. This may mean the unaligned loads are penalized (x86), or even fault (some ARM chips). For simple cases like directly loading or storing a packed field, the compiler might be able to paper over alignment issues with shifts and masks. However if you take a reference to a packed field, it’s unlikely that the compiler will be able to emit code to avoid an unaligned load.</p>
  <p><strong><a href="https://github.com/rust-lang/rust/issues/27060">As of Rust 1.0 this can cause undefined behavior.</a></strong></p>
  <p><code>repr(packed)</code> is not to be used lightly. Unless you have extreme requirements, this should not be used.</p>
  <p>This repr is a modifier on <code>repr(C)</code> and <code>repr(rust)</code>.</p>
  </section>
  </section>
  </section>
  <section id="sec--ownership" class="level1">
  <h1>Ownership</h1>
  <p>Ownership is the breakout feature of Rust. It allows Rust to be completely memory-safe and efficient, while avoiding garbage collection. Before getting into the ownership system in detail, we will consider the motivation of this design.</p>
  <p>We will assume that you accept that garbage collection (GC) is not always an optimal solution, and that it is desirable to manually manage memory in some contexts. If you do not accept this, might I interest you in a different language?</p>
  <p>Regardless of your feelings on GC, it is pretty clearly a <em>massive</em> boon to making code safe. You never have to worry about things going away <em>too soon</em> (although whether you still wanted to be pointing at that thing is a different issue…). This is a pervasive problem that C and C++ programs need to deal with. Consider this simple mistake that all of us who have used a non-GC’d language have made at one point:</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">fn</span> as_str(data: &amp;<span class="dt">u32</span>) -&gt; &amp;<span class="dt">str</span> {
      <span class="co">// compute the string</span>
      <span class="kw">let</span> s = <span class="pp">format!</span>(<span class="st">&quot;{}&quot;</span>, data);
  
      <span class="co">// OH NO! We returned a reference to something that</span>
      <span class="co">// exists only in this function!</span>
      <span class="co">// Dangling pointer! Use after free! Alas!</span>
      <span class="co">// (this does not compile in Rust)</span>
      &amp;s
  }</code></pre></div>
  <p>This is exactly what Rust’s ownership system was built to solve. Rust knows the scope in which the <code>&amp;s</code> lives, and as such can prevent it from escaping. However this is a simple case that even a C compiler could plausibly catch. Things get more complicated as code gets bigger and pointers get fed through various functions. Eventually, a C compiler will fall down and won’t be able to perform sufficient escape analysis to prove your code unsound. It will consequently be forced to accept your program on the assumption that it is correct.</p>
  <p>This will never happen to Rust. It’s up to the programmer to prove to the compiler that everything is sound.</p>
  <p>Of course, Rust’s story around ownership is much more complicated than just verifying that references don’t escape the scope of their referent. That’s because ensuring pointers are always valid is much more complicated than this. For instance in this code,</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">let</span> <span class="kw">mut</span> data = <span class="pp">vec!</span>[<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>];
  <span class="co">// get an internal reference</span>
  <span class="kw">let</span> x = &amp;data[<span class="dv">0</span>];
  
  <span class="co">// OH NO! `push` causes the backing storage of `data` to be reallocated.</span>
  <span class="co">// Dangling pointer! User after free! Alas!</span>
  <span class="co">// (this does not compile in Rust)</span>
  data.push(<span class="dv">4</span>);
  
  <span class="pp">println!</span>(<span class="st">&quot;{}&quot;</span>, x);</code></pre></div>
  <p>naive scope analysis would be insufficient to prevent this bug, because <code>data</code> does in fact live as long as we needed. However it was <em>changed</em> while we had a reference into it. This is why Rust requires any references to freeze the referent and its owners.</p>
  <section id="sec--references" class="level2">
  <h2>References</h2>
  <p>This section gives a high-level view of the memory model that <em>all</em> Rust programs must satisfy to be correct. Safe code is statically verified to obey this model by the borrow checker. Unsafe code may go above and beyond the borrow checker while still satisfying this model. The borrow checker may also be extended to allow more programs to compile, as long as this more fundamental model is satisfied.</p>
  <p>There are two kinds of reference:</p>
  <ul>
  <li>Shared reference: <code>&amp;</code></li>
  <li>Mutable reference: <code>&amp;mut</code></li>
  </ul>
  <p>Which obey the following rules:</p>
  <ul>
  <li>A reference cannot outlive its referent</li>
  <li>A mutable reference cannot be aliased</li>
  </ul>
  <p>That’s it. That’s the whole model. Of course, we should probably define what <em>aliased</em> means. To define aliasing, we must define the notion of <em>paths</em> and <em>liveness</em>.</p>
  <p><strong>NOTE: The model that follows is generally agreed to be dubious and have issues. It’s ok-ish as an intuitive model, but fails to capture the desired semantics. We leave this here to be able to use notions introduced here in later sections. This will be significantly changed in the future. TODO: do that.</strong></p>
  <section id="paths" class="level3">
  <h3>Paths</h3>
  <p>If all Rust had were values (no pointers), then every value would be uniquely owned by a variable or composite structure. From this we naturally derive a <em>tree</em> of ownership. The stack itself is the root of the tree, with every variable as its direct children. Each variable’s direct children would be their fields (if any), and so on.</p>
  <p>From this view, every value in Rust has a unique <em>path</em> in the tree of ownership. Of particular interest are <em>ancestors</em> and <em>descendants</em>: if <code>x</code> owns <code>y</code>, then <code>x</code> is an ancestor of <code>y</code>, and <code>y</code> is a descendant of <code>x</code>. Note that this is an inclusive relationship: <code>x</code> is a descendant and ancestor of itself.</p>
  <p>We can then define references as simply <em>names</em> for paths. When you create a reference, you’re declaring that an ownership path exists to this address of memory.</p>
  <p>Tragically, plenty of data doesn’t reside on the stack, and we must also accommodate this. Globals and thread-locals are simple enough to model as residing at the bottom of the stack (though we must be careful with mutable globals). Data on the heap poses a different problem.</p>
  <p>If all Rust had on the heap was data uniquely owned by a pointer on the stack, then we could just treat such a pointer as a struct that owns the value on the heap. Box, Vec, String, and HashMap, are examples of types which uniquely own data on the heap.</p>
  <p>Unfortunately, data on the heap is not <em>always</em> uniquely owned. Rc for instance introduces a notion of <em>shared</em> ownership. Shared ownership of a value means there is no unique path to it. A value with no unique path limits what we can do with it.</p>
  <p>In general, only shared references can be created to non-unique paths. However mechanisms which ensure mutual exclusion may establish One True Owner temporarily, establishing a unique path to that value (and therefore all its children). If this is done, the value may be mutated. In particular, a mutable reference can be taken.</p>
  <p>The most common way to establish such a path is through <em>interior mutability</em>, in contrast to the <em>inherited mutability</em> that everything in Rust normally uses. Cell, RefCell, Mutex, and RWLock are all examples of interior mutability types. These types provide exclusive access through runtime restrictions.</p>
  <p>An interesting case of this effect is Rc itself: if an Rc has refcount 1, then it is safe to mutate or even move its internals. Note however that the refcount itself uses interior mutability.</p>
  <p>In order to correctly communicate to the type system that a variable or field of a struct can have interior mutability, it must be wrapped in an UnsafeCell. This does not in itself make it safe to perform interior mutability operations on that value. You still must yourself ensure that mutual exclusion is upheld.</p>
  </section>
  <section id="liveness" class="level3">
  <h3>Liveness</h3>
  <p>Note: Liveness is not the same thing as a <em>lifetime</em>, which will be explained in detail in the next section of this chapter.</p>
  <p>Roughly, a reference is <em>live</em> at some point in a program if it can be dereferenced. Shared references are always live unless they are literally unreachable (for instance, they reside in freed or leaked memory). Mutable references can be reachable but <em>not</em> live through the process of <em>reborrowing</em>.</p>
  <p>A mutable reference can be reborrowed to either a shared or mutable reference to one of its descendants. A reborrowed reference will only be live again once all reborrows derived from it expire. For instance, a mutable reference can be reborrowed to point to a field of its referent:</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">let</span> x = &amp;<span class="kw">mut</span> (<span class="dv">1</span>, <span class="dv">2</span>);
  {
      <span class="co">// reborrow x to a subfield</span>
      <span class="kw">let</span> y = &amp;<span class="kw">mut</span> x.<span class="dv">0</span>;
      <span class="co">// y is now live, but x isn't</span>
      *y = <span class="dv">3</span>;
  }
  <span class="co">// y goes out of scope, so x is live again</span>
  *x = (<span class="dv">5</span>, <span class="dv">7</span>);</code></pre></div>
  <p>It is also possible to reborrow into <em>multiple</em> mutable references, as long as they are <em>disjoint</em>: no reference is an ancestor of another. Rust explicitly enables this to be done with disjoint struct fields, because disjointness can be statically proven:</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">let</span> x = &amp;<span class="kw">mut</span> (<span class="dv">1</span>, <span class="dv">2</span>);
  {
      <span class="co">// reborrow x to two disjoint subfields</span>
      <span class="kw">let</span> y = &amp;<span class="kw">mut</span> x.<span class="dv">0</span>;
      <span class="kw">let</span> z = &amp;<span class="kw">mut</span> x.<span class="dv">1</span>;
  
      <span class="co">// y and z are now live, but x isn't</span>
      *y = <span class="dv">3</span>;
      *z = <span class="dv">4</span>;
  }
  <span class="co">// y and z go out of scope, so x is live again</span>
  *x = (<span class="dv">5</span>, <span class="dv">7</span>);</code></pre></div>
  <p>However it’s often the case that Rust isn’t sufficiently smart to prove that multiple borrows are disjoint. <em>This does not mean it is fundamentally illegal to make such a borrow</em>, just that Rust isn’t as smart as you want.</p>
  <p>To simplify things, we can model variables as a fake type of reference: <em>owned</em> references. Owned references have much the same semantics as mutable references: they can be re-borrowed in a mutable or shared manner, which makes them no longer live. Live owned references have the unique property that they can be moved out of (though mutable references <em>can</em> be swapped out of). This power is only given to <em>live</em> owned references because moving its referent would of course invalidate all outstanding references prematurely.</p>
  <p>As a local lint against inappropriate mutation, only variables that are marked as <code>mut</code> can be borrowed mutably.</p>
  <p>It is interesting to note that Box behaves exactly like an owned reference. It can be moved out of, and Rust understands it sufficiently to reason about its paths like a normal variable.</p>
  </section>
  <section id="aliasing" class="level3">
  <h3>Aliasing</h3>
  <p>With liveness and paths defined, we can now properly define <em>aliasing</em>:</p>
  <p><strong>A mutable reference is aliased if there exists another live reference to one of its ancestors or descendants.</strong></p>
  <p>(If you prefer, you may also say the two live references alias <em>each other</em>. This has no semantic consequences, but is probably a more useful notion when verifying the soundness of a construct.)</p>
  <p>That’s it. Super simple right? Except for the fact that it took us two pages to define all of the terms in that definition. You know: Super. Simple.</p>
  <p>Actually it’s a bit more complicated than that. In addition to references, Rust has <em>raw pointers</em>: <code>*const T</code> and <code>*mut T</code>. Raw pointers have no inherent ownership or aliasing semantics. As a result, Rust makes absolutely no effort to track that they are used correctly, and they are wildly unsafe.</p>
  <p><strong>It is an open question to what degree raw pointers have alias semantics. However it is important for these definitions to be sound that the existence of a raw pointer does not imply some kind of live path.</strong></p>
  </section>
  </section>
  <section id="sec--lifetimes" class="level2">
  <h2>Lifetimes</h2>
  <p>Rust enforces these rules through <em>lifetimes</em>. Lifetimes are effectively just names for scopes somewhere in the program. Each reference, and anything that contains a reference, is tagged with a lifetime specifying the scope it’s valid for.</p>
  <p>Within a function body, Rust generally doesn’t let you explicitly name the lifetimes involved. This is because it’s generally not really necessary to talk about lifetimes in a local context; Rust has all the information and can work out everything as optimally as possible. Many anonymous scopes and temporaries that you would otherwise have to write are often introduced to make your code Just Work.</p>
  <p>However once you cross the function boundary, you need to start talking about lifetimes. Lifetimes are denoted with an apostrophe: <code>'a</code>, <code>'static</code>. To dip our toes with lifetimes, we’re going to pretend that we’re actually allowed to label scopes with lifetimes, and desugar the examples from the start of this chapter.</p>
  <p>Originally, our examples made use of <em>aggressive</em> sugar – high fructose corn syrup even – around scopes and lifetimes, because writing everything out explicitly is <em>extremely noisy</em>. All Rust code relies on aggressive inference and elision of “obvious” things.</p>
  <p>One particularly interesting piece of sugar is that each <code>let</code> statement implicitly introduces a scope. For the most part, this doesn’t really matter. However it does matter for variables that refer to each other. As a simple example, let’s completely desugar this simple piece of Rust code:</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">let</span> x = <span class="dv">0</span>;
  <span class="kw">let</span> y = &amp;x;
  <span class="kw">let</span> z = &amp;y;</code></pre></div>
  <p>The borrow checker always tries to minimize the extent of a lifetime, so it will likely desugar to the following:</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="co">// NOTE: `'a: {` and `&amp;'b x` is not valid syntax!</span>
  <span class="ot">'a</span>: {
      <span class="kw">let</span> x: <span class="dt">i32</span> = <span class="dv">0</span>;
      <span class="ot">'b</span>: {
          <span class="co">// lifetime used is 'b because that's good enough.</span>
          <span class="kw">let</span> y: &amp;<span class="ot">'b</span> <span class="dt">i32</span> = &amp;<span class="ot">'b</span> x;
          <span class="ot">'c</span>: {
              <span class="co">// ditto on 'c</span>
              <span class="kw">let</span> z: &amp;<span class="ot">'c</span> &amp;<span class="ot">'b</span> <span class="dt">i32</span> = &amp;<span class="ot">'c</span> y;
          }
      }
  }</code></pre></div>
  <p>Wow. That’s… awful. Let’s all take a moment to thank Rust for making this easier.</p>
  <p>Actually passing references to outer scopes will cause Rust to infer a larger lifetime:</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">let</span> x = <span class="dv">0</span>;
  <span class="kw">let</span> z;
  <span class="kw">let</span> y = &amp;x;
  z = y;</code></pre></div>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="ot">'a</span>: {
      <span class="kw">let</span> x: <span class="dt">i32</span> = <span class="dv">0</span>;
      <span class="ot">'b</span>: {
          <span class="kw">let</span> z: &amp;<span class="ot">'b</span> <span class="dt">i32</span>;
          <span class="ot">'c</span>: {
              <span class="co">// Must use 'b here because this reference is</span>
              <span class="co">// being passed to that scope.</span>
              <span class="kw">let</span> y: &amp;<span class="ot">'b</span> <span class="dt">i32</span> = &amp;<span class="ot">'b</span> x;
              z = y;
          }
      }
  }</code></pre></div>
  <section id="example-references-that-outlive-referents" class="level3">
  <h3>Example: references that outlive referents</h3>
  <p>Alright, let’s look at some of those examples from before:</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">fn</span> as_str(data: &amp;<span class="dt">u32</span>) -&gt; &amp;<span class="dt">str</span> {
      <span class="kw">let</span> s = <span class="pp">format!</span>(<span class="st">&quot;{}&quot;</span>, data);
      &amp;s
  }</code></pre></div>
  <p>desugars to:</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">fn</span> as_str&lt;<span class="ot">'a</span>&gt;(data: &amp;<span class="ot">'a</span> <span class="dt">u32</span>) -&gt; &amp;<span class="ot">'a</span> <span class="dt">str</span> {
      <span class="ot">'b</span>: {
          <span class="kw">let</span> s = <span class="pp">format!</span>(<span class="st">&quot;{}&quot;</span>, data);
          <span class="kw">return</span> &amp;<span class="ot">'a</span> s;
      }
  }</code></pre></div>
  <p>This signature of <code>as_str</code> takes a reference to a u32 with <em>some</em> lifetime, and promises that it can produce a reference to a str that can live <em>just as long</em>. Already we can see why this signature might be trouble. That basically implies that we’re going to find a str somewhere in the scope the reference to the u32 originated in, or somewhere <em>even earlier</em>. That’s a bit of a tall order.</p>
  <p>We then proceed to compute the string <code>s</code>, and return a reference to it. Since the contract of our function says the reference must outlive <code>'a</code>, that’s the lifetime we infer for the reference. Unfortunately, <code>s</code> was defined in the scope <code>'b</code>, so the only way this is sound is if <code>'b</code> contains <code>'a</code> – which is clearly false since <code>'a</code> must contain the function call itself. We have therefore created a reference whose lifetime outlives its referent, which is <em>literally</em> the first thing we said that references can’t do. The compiler rightfully blows up in our face.</p>
  <p>To make this more clear, we can expand the example:</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">fn</span> as_str&lt;<span class="ot">'a</span>&gt;(data: &amp;<span class="ot">'a</span> <span class="dt">u32</span>) -&gt; &amp;<span class="ot">'a</span> <span class="dt">str</span> {
      <span class="ot">'b</span>: {
          <span class="kw">let</span> s = <span class="pp">format!</span>(<span class="st">&quot;{}&quot;</span>, data);
          <span class="kw">return</span> &amp;<span class="ot">'a</span> s
      }
  }
  
  <span class="kw">fn</span> main() {
      <span class="ot">'c</span>: {
          <span class="kw">let</span> x: <span class="dt">u32</span> = <span class="dv">0</span>;
          <span class="ot">'d</span>: {
              <span class="co">// An anonymous scope is introduced because the borrow does not</span>
              <span class="co">// need to last for the whole scope x is valid for. The return</span>
              <span class="co">// of as_str must find a str somewhere before this function</span>
              <span class="co">// call. Obviously not happening.</span>
              <span class="pp">println!</span>(<span class="st">&quot;{}&quot;</span>, as_str::&lt;<span class="ot">'d</span>&gt;(&amp;<span class="ot">'d</span> x));
          }
      }
  }</code></pre></div>
  <p>Shoot!</p>
  <p>Of course, the right way to write this function is as follows:</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">fn</span> to_string(data: &amp;<span class="dt">u32</span>) -&gt; <span class="dt">String</span> {
      <span class="pp">format!</span>(<span class="st">&quot;{}&quot;</span>, data)
  }</code></pre></div>
  <p>We must produce an owned value inside the function to return it! The only way we could have returned an <code>&amp;'a str</code> would have been if it was in a field of the <code>&amp;'a u32</code>, which is obviously not the case.</p>
  <p>(Actually we could have also just returned a string literal, which as a global can be considered to reside at the bottom of the stack; though this limits our implementation <em>just a bit</em>.)</p>
  </section>
  <section id="example-aliasing-a-mutable-reference" class="level3">
  <h3>Example: aliasing a mutable reference</h3>
  <p>How about the other example:</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">let</span> <span class="kw">mut</span> data = <span class="pp">vec!</span>[<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>];
  <span class="kw">let</span> x = &amp;data[<span class="dv">0</span>];
  data.push(<span class="dv">4</span>);
  <span class="pp">println!</span>(<span class="st">&quot;{}&quot;</span>, x);</code></pre></div>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="ot">'a</span>: {
      <span class="kw">let</span> <span class="kw">mut</span> data: <span class="dt">Vec</span>&lt;<span class="dt">i32</span>&gt; = <span class="pp">vec!</span>[<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>];
      <span class="ot">'b</span>: {
          <span class="co">// 'b is as big as we need this borrow to be</span>
          <span class="co">// (just need to get to `println!`)</span>
          <span class="kw">let</span> x: &amp;<span class="ot">'b</span> <span class="dt">i32</span> = Index::index::&lt;<span class="ot">'b</span>&gt;(&amp;<span class="ot">'b</span> data, <span class="dv">0</span>);
          <span class="ot">'c</span>: {
              <span class="co">// Temporary scope because we don't need the</span>
              <span class="co">// &amp;mut to last any longer.</span>
              <span class="dt">Vec</span>::push(&amp;<span class="ot">'c</span> <span class="kw">mut</span> data, <span class="dv">4</span>);
          }
          <span class="pp">println!</span>(<span class="st">&quot;{}&quot;</span>, x);
      }
  }</code></pre></div>
  <p>The problem here is a bit more subtle and interesting. We want Rust to reject this program for the following reason: We have a live shared reference <code>x</code> to a descendant of <code>data</code> when we try to take a mutable reference to <code>data</code> to <code>push</code>. This would create an aliased mutable reference, which would violate the <em>second</em> rule of references.</p>
  <p>However this is <em>not at all</em> how Rust reasons that this program is bad. Rust doesn’t understand that <code>x</code> is a reference to a subpath of <code>data</code>. It doesn’t understand Vec at all. What it <em>does</em> see is that <code>x</code> has to live for <code>'b</code> to be printed. The signature of <code>Index::index</code> subsequently demands that the reference we take to <code>data</code> has to survive for <code>'b</code>. When we try to call <code>push</code>, it then sees us try to make an <code>&amp;'c mut data</code>. Rust knows that <code>'c</code> is contained within <code>'b</code>, and rejects our program because the <code>&amp;'b data</code> must still be live!</p>
  <p>Here we see that the lifetime system is much more coarse than the reference semantics we’re actually interested in preserving. For the most part, <em>that’s totally ok</em>, because it keeps us from spending all day explaining our program to the compiler. However it does mean that several programs that are totally correct with respect to Rust’s <em>true</em> semantics are rejected because lifetimes are too dumb.</p>
  </section>
  </section>
  <section id="sec--lifetime-mismatch" class="level2">
  <h2>Limits of Lifetimes</h2>
  <p>Given the following code:</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">struct</span> Foo;
  
  <span class="kw">impl</span> Foo {
      <span class="kw">fn</span> mutate_and_share(&amp;<span class="kw">mut</span> <span class="kw">self</span>) -&gt; &amp;<span class="kw">Self</span> { &amp;*<span class="kw">self</span> }
      <span class="kw">fn</span> share(&amp;<span class="kw">self</span>) {}
  }
  
  <span class="kw">fn</span> main() {
      <span class="kw">let</span> <span class="kw">mut</span> foo = Foo;
      <span class="kw">let</span> loan = foo.mutate_and_share();
      foo.share();
  }</code></pre></div>
  <p>One might expect it to compile. We call <code>mutate_and_share</code>, which mutably borrows <code>foo</code> temporarily, but then returns only a shared reference. Therefore we would expect <code>foo.share()</code> to succeed as <code>foo</code> shouldn’t be mutably borrowed.</p>
  <p>However when we try to compile it:</p>
  <pre class="text"><code>&lt;anon&gt;:11:5: 11:8 error: cannot borrow `foo` as immutable because it is also borrowed 
  ↳ as mutable
  &lt;anon&gt;:11     foo.share();
                ^~~
  &lt;anon&gt;:10:16: 10:19 note: previous borrow of `foo` occurs here; the mutable borrow pre
  ↳ vents subsequent moves, borrows, or modification of `foo` until the borrow ends
  &lt;anon&gt;:10     let loan = foo.mutate_and_share();
                           ^~~
  &lt;anon&gt;:12:2: 12:2 note: previous borrow ends here
  &lt;anon&gt;:8 fn main() {
  &lt;anon&gt;:9     let mut foo = Foo;
  &lt;anon&gt;:10     let loan = foo.mutate_and_share();
  &lt;anon&gt;:11     foo.share();
  &lt;anon&gt;:12 }
            ^</code></pre>
  <p>What happened? Well, we got the exact same reasoning as we did for <a href="#example-aliasing-a-mutable-reference">Example 2 in the previous section</a>. We desugar the program and we get the following:</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">struct</span> Foo;
  
  <span class="kw">impl</span> Foo {
      <span class="kw">fn</span> mutate_and_share&lt;<span class="ot">'a</span>&gt;(&amp;<span class="ot">'a</span> <span class="kw">mut</span> <span class="kw">self</span>) -&gt; &amp;<span class="ot">'a</span> <span class="kw">Self</span> { &amp;<span class="ot">'a</span> *<span class="kw">self</span> }
      <span class="kw">fn</span> share&lt;<span class="ot">'a</span>&gt;(&amp;<span class="ot">'a</span> <span class="kw">self</span>) {}
  }
  
  <span class="kw">fn</span> main() {
      <span class="ot">'b</span>: {
          <span class="kw">let</span> <span class="kw">mut</span> foo: Foo = Foo;
          <span class="ot">'c</span>: {
              <span class="kw">let</span> loan: &amp;<span class="ot">'c</span> Foo = Foo::mutate_and_share::&lt;<span class="ot">'c</span>&gt;(&amp;<span class="ot">'c</span> <span class="kw">mut</span> foo);
              <span class="ot">'d</span>: {
                  Foo::share::&lt;<span class="ot">'d</span>&gt;(&amp;<span class="ot">'d</span> foo);
              }
          }
      }
  }</code></pre></div>
  <p>The lifetime system is forced to extend the <code>&amp;mut foo</code> to have lifetime <code>'c</code>, due to the lifetime of <code>loan</code> and mutate_and_share’s signature. Then when we try to call <code>share</code>, and it sees we’re trying to alias that <code>&amp;'c mut foo</code> and blows up in our face!</p>
  <p>This program is clearly correct according to the reference semantics we actually care about, but the lifetime system is too coarse-grained to handle that.</p>
  <p>TODO: other common problems? SEME regions stuff, mostly?</p>
  </section>
  <section id="sec--lifetime-elision" class="level2">
  <h2>Lifetime Elision</h2>
  <p>In order to make common patterns more ergonomic, Rust allows lifetimes to be <em>elided</em> in function signatures.</p>
  <p>A <em>lifetime position</em> is anywhere you can write a lifetime in a type:</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust">&amp;<span class="ot">'a</span> T
  &amp;<span class="ot">'a</span> <span class="kw">mut</span> T
  T&lt;<span class="ot">'a</span>&gt;</code></pre></div>
  <p>Lifetime positions can appear as either “input” or “output”:</p>
  <ul>
  <li><p>For <code>fn</code> definitions, input refers to the types of the formal arguments in the <code>fn</code> definition, while output refers to result types. So <code>fn foo(s: &amp;str) -&gt; (&amp;str, &amp;str)</code> has elided one lifetime in input position and two lifetimes in output position. Note that the input positions of a <code>fn</code> method definition do not include the lifetimes that occur in the method’s <code>impl</code> header (nor lifetimes that occur in the trait header, for a default method).</p></li>
  <li><p>In the future, it should be possible to elide <code>impl</code> headers in the same manner.</p></li>
  </ul>
  <p>Elision rules are as follows:</p>
  <ul>
  <li><p>Each elided lifetime in input position becomes a distinct lifetime parameter.</p></li>
  <li><p>If there is exactly one input lifetime position (elided or not), that lifetime is assigned to <em>all</em> elided output lifetimes.</p></li>
  <li><p>If there are multiple input lifetime positions, but one of them is <code>&amp;self</code> or <code>&amp;mut self</code>, the lifetime of <code>self</code> is assigned to <em>all</em> elided output lifetimes.</p></li>
  <li><p>Otherwise, it is an error to elide an output lifetime.</p></li>
  </ul>
  <p>Examples:</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">fn</span> print(s: &amp;<span class="dt">str</span>);                                      <span class="co">// elided</span>
  <span class="kw">fn</span> print&lt;<span class="ot">'a</span>&gt;(s: &amp;<span class="ot">'a</span> <span class="dt">str</span>);                               <span class="co">// expanded</span>
  
  <span class="kw">fn</span> debug(lvl: <span class="dt">uint</span>, s: &amp;<span class="dt">str</span>);                           <span class="co">// elided</span>
  <span class="kw">fn</span> debug&lt;<span class="ot">'a</span>&gt;(lvl: <span class="dt">uint</span>, s: &amp;<span class="ot">'a</span> <span class="dt">str</span>);                    <span class="co">// expanded</span>
  
  <span class="kw">fn</span> substr(s: &amp;<span class="dt">str</span>, until: <span class="dt">uint</span>) -&gt; &amp;<span class="dt">str</span>;                <span class="co">// elided</span>
  <span class="kw">fn</span> substr&lt;<span class="ot">'a</span>&gt;(s: &amp;<span class="ot">'a</span> <span class="dt">str</span>, until: <span class="dt">uint</span>) -&gt; &amp;<span class="ot">'a</span> <span class="dt">str</span>;      <span class="co">// expanded</span>
  
  <span class="kw">fn</span> get_str() -&gt; &amp;<span class="dt">str</span>;                                   <span class="co">// ILLEGAL</span>
  
  <span class="kw">fn</span> frob(s: &amp;<span class="dt">str</span>, t: &amp;<span class="dt">str</span>) -&gt; &amp;<span class="dt">str</span>;                      <span class="co">// ILLEGAL</span>
  
  <span class="kw">fn</span> get_mut(&amp;<span class="kw">mut</span> <span class="kw">self</span>) -&gt; &amp;<span class="kw">mut</span> T;                        <span class="co">// elided</span>
  <span class="kw">fn</span> get_mut&lt;<span class="ot">'a</span>&gt;(&amp;<span class="ot">'a</span> <span class="kw">mut</span> <span class="kw">self</span>) -&gt; &amp;<span class="ot">'a</span> <span class="kw">mut</span> T;              <span class="co">// expanded</span>
  
  <span class="kw">fn</span> args&lt;T: ToCStr&gt;(&amp;<span class="kw">mut</span> <span class="kw">self</span>, args: &amp;[T]) -&gt; &amp;<span class="kw">mut</span> Command                  <span class="co">// elided</span>
  <span class="kw">fn</span> args&lt;<span class="ot">'a</span>, <span class="ot">'b</span>, T: ToCStr&gt;(&amp;<span class="ot">'a</span> <span class="kw">mut</span> <span class="kw">self</span>, args: &amp;<span class="ot">'b</span> [T]) -&gt; &amp;<span class="ot">'a</span> <span class="kw">mut</span> Command <span class="co">// expanded</span>
  
  <span class="kw">fn</span> new(buf: &amp;<span class="kw">mut</span> [<span class="dt">u8</span>]) -&gt; BufWriter;                    <span class="co">// elided</span>
  <span class="kw">fn</span> new&lt;<span class="ot">'a</span>&gt;(buf: &amp;<span class="ot">'a</span> <span class="kw">mut</span> [<span class="dt">u8</span>]) -&gt; BufWriter&lt;<span class="ot">'a</span>&gt;          <span class="co">// expanded</span></code></pre></div>
  </section>
  <section id="sec--unbounded-lifetimes" class="level2">
  <h2>Unbounded Lifetimes</h2>
  <p>Unsafe code can often end up producing references or lifetimes out of thin air. Such lifetimes come into the world as <em>unbounded</em>. The most common source of this is dereferencing a raw pointer, which produces a reference with an unbounded lifetime. Such a lifetime becomes as big as context demands. This is in fact more powerful than simply becoming <code>'static</code>, because for instance <code>&amp;'static &amp;'a T</code> will fail to typecheck, but the unbound lifetime will perfectly mold into <code>&amp;'a &amp;'a T</code> as needed. However for most intents and purposes, such an unbounded lifetime can be regarded as <code>'static</code>.</p>
  <p>Almost no reference is <code>'static</code>, so this is probably wrong. <code>transmute</code> and <code>transmute_copy</code> are the two other primary offenders. One should endeavor to bound an unbounded lifetime as quick as possible, especially across function boundaries.</p>
  <p>Given a function, any output lifetimes that don’t derive from inputs are unbounded. For instance:</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">fn</span> get_str&lt;<span class="ot">'a</span>&gt;() -&gt; &amp;<span class="ot">'a</span> <span class="dt">str</span>;</code></pre></div>
  <p>will produce an <code>&amp;str</code> with an unbounded lifetime. The easiest way to avoid unbounded lifetimes is to use lifetime elision at the function boundary. If an output lifetime is elided, then it <em>must</em> be bounded by an input lifetime. Of course it might be bounded by the <em>wrong</em> lifetime, but this will usually just cause a compiler error, rather than allow memory safety to be trivially violated.</p>
  <p>Within a function, bounding lifetimes is more error-prone. The safest and easiest way to bound a lifetime is to return it from a function with a bound lifetime. However if this is unacceptable, the reference can be placed in a location with a specific lifetime. Unfortunately it’s impossible to name all lifetimes involved in a function.</p>
  </section>
  <section id="sec--hrtb" class="level2">
  <h2>Higher-Rank Trait Bounds</h2>
  <p>Rust’s <code>Fn</code> traits are a little bit magic. For instance, we can write the following code:</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">struct</span> Closure&lt;F&gt; {
      data: (<span class="dt">u8</span>, <span class="dt">u16</span>),
      func: F,
  }
  
  <span class="kw">impl</span>&lt;F&gt; Closure&lt;F&gt;
      <span class="kw">where</span> F: <span class="bu">Fn</span>(&amp;(<span class="dt">u8</span>, <span class="dt">u16</span>)) -&gt; &amp;<span class="dt">u8</span>,
  {
      <span class="kw">fn</span> call(&amp;<span class="kw">self</span>) -&gt; &amp;<span class="dt">u8</span> {
          (<span class="kw">self</span>.func)(&amp;<span class="kw">self</span>.data)
      }
  }
  
  <span class="kw">fn</span> do_it(data: &amp;(<span class="dt">u8</span>, <span class="dt">u16</span>)) -&gt; &amp;<span class="dt">u8</span> { &amp;data.<span class="dv">0</span> }
  
  <span class="kw">fn</span> main() {
      <span class="kw">let</span> clo = Closure { data: (<span class="dv">0</span>, <span class="dv">1</span>), func: do_it };
      <span class="pp">println!</span>(<span class="st">&quot;{}&quot;</span>, clo.call());
  }</code></pre></div>
  <p>If we try to naively desugar this code in the same way that we did in the lifetimes section, we run into some trouble:</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">struct</span> Closure&lt;F&gt; {
      data: (<span class="dt">u8</span>, <span class="dt">u16</span>),
      func: F,
  }
  
  <span class="kw">impl</span>&lt;F&gt; Closure&lt;F&gt;
      <span class="co">// where F: Fn(&amp;'??? (u8, u16)) -&gt; &amp;'??? u8,</span>
  {
      <span class="kw">fn</span> call&lt;<span class="ot">'a</span>&gt;(&amp;<span class="ot">'a</span> <span class="kw">self</span>) -&gt; &amp;<span class="ot">'a</span> <span class="dt">u8</span> {
          (<span class="kw">self</span>.func)(&amp;<span class="kw">self</span>.data)
      }
  }
  
  <span class="kw">fn</span> do_it&lt;<span class="ot">'b</span>&gt;(data: &amp;<span class="ot">'b</span> (<span class="dt">u8</span>, <span class="dt">u16</span>)) -&gt; &amp;<span class="ot">'b</span> <span class="dt">u8</span> { &amp;<span class="ot">'b</span> data.<span class="dv">0</span> }
  
  <span class="kw">fn</span> main() {
      <span class="ot">'x</span>: {
          <span class="kw">let</span> clo = Closure { data: (<span class="dv">0</span>, <span class="dv">1</span>), func: do_it };
          <span class="pp">println!</span>(<span class="st">&quot;{}&quot;</span>, clo.call());
      }
  }</code></pre></div>
  <p>How on earth are we supposed to express the lifetimes on <code>F</code>’s trait bound? We need to provide some lifetime there, but the lifetime we care about can’t be named until we enter the body of <code>call</code>! Also, that isn’t some fixed lifetime; <code>call</code> works with <em>any</em> lifetime <code>&amp;self</code> happens to have at that point.</p>
  <p>This job requires The Magic of Higher-Rank Trait Bounds (HRTBs). The way we desugar this is as follows:</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">where</span> <span class="kw">for</span>&lt;<span class="ot">'a</span>&gt; F: <span class="bu">Fn</span>(&amp;<span class="ot">'a</span> (<span class="dt">u8</span>, <span class="dt">u16</span>)) -&gt; &amp;<span class="ot">'a</span> <span class="dt">u8</span>,</code></pre></div>
  <p>(Where <code>Fn(a, b, c) -&gt; d</code> is itself just sugar for the unstable <em>real</em> <code>Fn</code> trait)</p>
  <p><code>for&lt;'a&gt;</code> can be read as “for all choices of <code>'a</code>”, and basically produces an <em>infinite list</em> of trait bounds that F must satisfy. Intense. There aren’t many places outside of the <code>Fn</code> traits where we encounter HRTBs, and even for those we have a nice magic sugar for the common cases.</p>
  </section>
  <section id="sec--subtyping" class="level2">
  <h2>Subtyping and Variance</h2>
  <p>Although Rust doesn’t have any notion of structural inheritance, it <em>does</em> include subtyping. In Rust, subtyping derives entirely from lifetimes. Since lifetimes are scopes, we can partially order them based on the <em>contains</em> (outlives) relationship. We can even express this as a generic bound.</p>
  <p>Subtyping on lifetimes is in terms of that relationship: if <code>'a: 'b</code> (“a contains b” or “a outlives b”), then <code>'a</code> is a subtype of <code>'b</code>. This is a large source of confusion, because it seems intuitively backwards to many: the bigger scope is a <em>subtype</em> of the smaller scope.</p>
  <p>This does in fact make sense, though. The intuitive reason for this is that if you expect an <code>&amp;'a u8</code>, then it’s totally fine for me to hand you an <code>&amp;'static u8</code>, in the same way that if you expect an Animal in Java, it’s totally fine for me to hand you a Cat. Cats are just Animals <em>and more</em>, just as <code>'static</code> is just <code>'a</code> <em>and more</em>.</p>
  <p>(Note, the subtyping relationship and typed-ness of lifetimes is a fairly arbitrary construct that some disagree with. However it simplifies our analysis to treat lifetimes and types uniformly.)</p>
  <p>Higher-ranked lifetimes are also subtypes of every concrete lifetime. This is because taking an arbitrary lifetime is strictly more general than taking a specific one.</p>
  <section id="variance" class="level3">
  <h3>Variance</h3>
  <p>Variance is where things get a bit complicated.</p>
  <p>Variance is a property that <em>type constructors</em> have with respect to their arguments. A type constructor in Rust is a generic type with unbound arguments. For instance <code>Vec</code> is a type constructor that takes a <code>T</code> and returns a <code>Vec&lt;T&gt;</code>. <code>&amp;</code> and <code>&amp;mut</code> are type constructors that take two inputs: a lifetime, and a type to point to.</p>
  <p>A type constructor’s <em>variance</em> is how the subtyping of its inputs affects the subtyping of its outputs. There are two kinds of variance in Rust:</p>
  <ul>
  <li>F is <em>variant</em> over <code>T</code> if <code>T</code> being a subtype of <code>U</code> implies <code>F&lt;T&gt;</code> is a subtype of <code>F&lt;U&gt;</code> (subtyping “passes through”)</li>
  <li>F is <em>invariant</em> over <code>T</code> otherwise (no subtyping relation can be derived)</li>
  </ul>
  <p>(For those of you who are familiar with variance from other languages, what we refer to as “just” variance is in fact <em>covariance</em>. Rust has <em>contravariance</em> for functions. The future of contravariance is uncertain and it may be scrapped. For now, <code>fn(T)</code> is contravariant in <code>T</code>, which is used in matching methods in trait implementations to the trait definition. Traits don’t have inferred variance, so <code>Fn(T)</code> is invariant in <code>T</code>).</p>
  <p>Some important variances:</p>
  <ul>
  <li><code>&amp;'a T</code> is variant over <code>'a</code> and <code>T</code> (as is <code>*const T</code> by metaphor)</li>
  <li><code>&amp;'a mut T</code> is variant over <code>'a</code> but invariant over <code>T</code></li>
  <li><code>Fn(T) -&gt; U</code> is invariant over <code>T</code>, but variant over <code>U</code></li>
  <li><code>Box</code>, <code>Vec</code>, and all other collections are variant over the types of their contents</li>
  <li><code>UnsafeCell&lt;T&gt;</code>, <code>Cell&lt;T&gt;</code>, <code>RefCell&lt;T&gt;</code>, <code>Mutex&lt;T&gt;</code> and all other interior mutability types are invariant over T (as is <code>*mut T</code> by metaphor)</li>
  </ul>
  <p>To understand why these variances are correct and desirable, we will consider several examples.</p>
  <p>We have already covered why <code>&amp;'a T</code> should be variant over <code>'a</code> when introducing subtyping: it’s desirable to be able to pass longer-lived things where shorter-lived things are needed.</p>
  <p>Similar reasoning applies to why it should be variant over T. It is reasonable to be able to pass <code>&amp;&amp;'static str</code> where an <code>&amp;&amp;'a str</code> is expected. The additional level of indirection does not change the desire to be able to pass longer lived things where shorted lived things are expected.</p>
  <p>However this logic doesn’t apply to <code>&amp;mut</code>. To see why <code>&amp;mut</code> should be invariant over T, consider the following code:</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">fn</span> overwrite&lt;T: <span class="bu">Copy</span>&gt;(input: &amp;<span class="kw">mut</span> T, new: &amp;<span class="kw">mut</span> T) {
      *input = *new;
  }
  
  <span class="kw">fn</span> main() {
      <span class="kw">let</span> <span class="kw">mut</span> forever_str: &amp;<span class="ot">'static</span> <span class="dt">str</span> = <span class="st">&quot;hello&quot;</span>;
      {
          <span class="kw">let</span> string = <span class="dt">String</span>::from(<span class="st">&quot;world&quot;</span>);
          overwrite(&amp;<span class="kw">mut</span> forever_str, &amp;<span class="kw">mut</span> &amp;*string);
      }
      <span class="co">// Oops, printing free'd memory</span>
      <span class="pp">println!</span>(<span class="st">&quot;{}&quot;</span>, forever_str);
  }</code></pre></div>
  <p>The signature of <code>overwrite</code> is clearly valid: it takes mutable references to two values of the same type, and overwrites one with the other. If <code>&amp;mut T</code> was variant over T, then <code>&amp;mut &amp;'static str</code> would be a subtype of <code>&amp;mut &amp;'a str</code>, since <code>&amp;'static str</code> is a subtype of <code>&amp;'a str</code>. Therefore the lifetime of <code>forever_str</code> would successfully be “shrunk” down to the shorter lifetime of <code>string</code>, and <code>overwrite</code> would be called successfully. <code>string</code> would subsequently be dropped, and <code>forever_str</code> would point to freed memory when we print it! Therefore <code>&amp;mut</code> should be invariant.</p>
  <p>This is the general theme of variance vs invariance: if variance would allow you to store a short-lived value into a longer-lived slot, then you must be invariant.</p>
  <p>However it <em>is</em> sound for <code>&amp;'a mut T</code> to be variant over <code>'a</code>. The key difference between <code>'a</code> and T is that <code>'a</code> is a property of the reference itself, while T is something the reference is borrowing. If you change T’s type, then the source still remembers the original type. However if you change the lifetime’s type, no one but the reference knows this information, so it’s fine. Put another way: <code>&amp;'a mut T</code> owns <code>'a</code>, but only <em>borrows</em> T.</p>
  <p><code>Box</code> and <code>Vec</code> are interesting cases because they’re variant, but you can definitely store values in them! This is where Rust gets really clever: it’s fine for them to be variant because you can only store values in them <em>via a mutable reference</em>! The mutable reference makes the whole type invariant, and therefore prevents you from smuggling a short-lived type into them.</p>
  <p>Being variant allows <code>Box</code> and <code>Vec</code> to be weakened when shared immutably. So you can pass a <code>&amp;Box&lt;&amp;'static str&gt;</code> where a <code>&amp;Box&lt;&amp;'a str&gt;</code> is expected.</p>
  <p>However what should happen when passing <em>by-value</em> is less obvious. It turns out that, yes, you can use subtyping when passing by-value. That is, this works:</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">fn</span> get_box&lt;<span class="ot">'a</span>&gt;(<span class="dt">str</span>: &amp;<span class="ot">'a</span> <span class="dt">str</span>) -&gt; <span class="dt">Box</span>&lt;&amp;<span class="ot">'a</span> <span class="dt">str</span>&gt; {
      <span class="co">// string literals are `&amp;'static str`s</span>
      <span class="dt">Box</span>::new(<span class="st">&quot;hello&quot;</span>)
  }</code></pre></div>
  <p>Weakening when you pass by-value is fine because there’s no one else who “remembers” the old lifetime in the Box. The reason a variant <code>&amp;mut</code> was trouble was because there’s always someone else who remembers the original subtype: the actual owner.</p>
  <p>The invariance of the cell types can be seen as follows: <code>&amp;</code> is like an <code>&amp;mut</code> for a cell, because you can still store values in them through an <code>&amp;</code>. Therefore cells must be invariant to avoid lifetime smuggling.</p>
  <p><code>Fn</code> is the most subtle case because it has mixed variance. To see why <code>Fn(T) -&gt; U</code> should be invariant over T, consider the following function signature:</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="co">// 'a is derived from some parent scope</span>
  <span class="kw">fn</span> foo(&amp;<span class="ot">'a</span> <span class="dt">str</span>) -&gt; <span class="dt">usize</span>;</code></pre></div>
  <p>This signature claims that it can handle any <code>&amp;str</code> that lives at least as long as <code>'a</code>. Now if this signature was variant over <code>&amp;'a str</code>, that would mean</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">fn</span> foo(&amp;<span class="ot">'static</span> <span class="dt">str</span>) -&gt; <span class="dt">usize</span>;</code></pre></div>
  <p>could be provided in its place, as it would be a subtype. However this function has a stronger requirement: it says that it can only handle <code>&amp;'static str</code>s, and nothing else. Giving <code>&amp;'a str</code>s to it would be unsound, as it’s free to assume that what it’s given lives forever. Therefore functions are not variant over their arguments.</p>
  <p>To see why <code>Fn(T) -&gt; U</code> should be variant over U, consider the following function signature:</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="co">// 'a is derived from some parent scope</span>
  <span class="kw">fn</span> foo(<span class="dt">usize</span>) -&gt; &amp;<span class="ot">'a</span> <span class="dt">str</span>;</code></pre></div>
  <p>This signature claims that it will return something that outlives <code>'a</code>. It is therefore completely reasonable to provide</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">fn</span> foo(<span class="dt">usize</span>) -&gt; &amp;<span class="ot">'static</span> <span class="dt">str</span>;</code></pre></div>
  <p>in its place. Therefore functions are variant over their return type.</p>
  <p><code>*const</code> has the exact same semantics as <code>&amp;</code>, so variance follows. <code>*mut</code> on the other hand can dereference to an <code>&amp;mut</code> whether shared or not, so it is marked as invariant just like cells.</p>
  <p>This is all well and good for the types the standard library provides, but how is variance determined for type that <em>you</em> define? A struct, informally speaking, inherits the variance of its fields. If a struct <code>Foo</code> has a generic argument <code>A</code> that is used in a field <code>a</code>, then Foo’s variance over <code>A</code> is exactly <code>a</code>’s variance. However this is complicated if <code>A</code> is used in multiple fields.</p>
  <ul>
  <li>If all uses of A are variant, then Foo is variant over A</li>
  <li>Otherwise, Foo is invariant over A</li>
  </ul>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">use</span> std::cell::Cell;
  
  <span class="kw">struct</span> Foo&lt;<span class="ot">'a</span>, <span class="ot">'b</span>, A: <span class="ot">'a</span>, B: <span class="ot">'b</span>, C, D, E, F, G, H&gt; {
      a: &amp;<span class="ot">'a</span> A,     <span class="co">// variant over 'a and A</span>
      b: &amp;<span class="ot">'b</span> <span class="kw">mut</span> B, <span class="co">// variant over 'b and invariant over B</span>
      c: *<span class="kw">const</span> C,  <span class="co">// variant over C</span>
      d: *<span class="kw">mut</span> D,    <span class="co">// invariant over D</span>
      e: <span class="dt">Vec</span>&lt;E&gt;,    <span class="co">// variant over E</span>
      f: Cell&lt;F&gt;,   <span class="co">// invariant over F</span>
      g: G,         <span class="co">// variant over G</span>
      h1: H,        <span class="co">// would also be variant over H except...</span>
      h2: Cell&lt;H&gt;,  <span class="co">// invariant over H, because invariance wins</span>
  }</code></pre></div>
  </section>
  </section>
  <section id="sec--dropck" class="level2">
  <h2>Drop Check</h2>
  <p>We have seen how lifetimes provide us some fairly simple rules for ensuring that we never read dangling references. However up to this point we have only ever interacted with the <em>outlives</em> relationship in an inclusive manner. That is, when we talked about <code>'a: 'b</code>, it was ok for <code>'a</code> to live <em>exactly</em> as long as <code>'b</code>. At first glance, this seems to be a meaningless distinction. Nothing ever gets dropped at the same time as another, right? This is why we used the following desugaring of <code>let</code> statements:</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">let</span> x;
  <span class="kw">let</span> y;</code></pre></div>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust">{
      <span class="kw">let</span> x;
      {
          <span class="kw">let</span> y;
      }
  }</code></pre></div>
  <p>Each creates its own scope, clearly establishing that one drops before the other. However, what if we do the following?</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">let</span> (x, y) = (<span class="pp">vec!</span>[], <span class="pp">vec!</span>[]);</code></pre></div>
  <p>Does either value strictly outlive the other? The answer is in fact <em>no</em>, neither value strictly outlives the other. Of course, one of x or y will be dropped before the other, but the actual order is not specified. Tuples aren’t special in this regard; composite structures just don’t guarantee their destruction order as of Rust 1.0.</p>
  <p>We <em>could</em> specify this for the fields of built-in composites like tuples and structs. However, what about something like Vec? Vec has to manually drop its elements via pure-library code. In general, anything that implements Drop has a chance to fiddle with its innards during its final death knell. Therefore the compiler can’t sufficiently reason about the actual destruction order of the contents of any type that implements Drop.</p>
  <p>So why do we care? We care because if the type system isn’t careful, it could accidentally make dangling pointers. Consider the following simple program:</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">struct</span> Inspector&lt;<span class="ot">'a</span>&gt;(&amp;<span class="ot">'a</span> <span class="dt">u8</span>);
  
  <span class="kw">fn</span> main() {
      <span class="kw">let</span> (inspector, days);
      days = <span class="dt">Box</span>::new(<span class="dv">1</span>);
      inspector = Inspector(&amp;days);
  }</code></pre></div>
  <p>This program is totally sound and compiles today. The fact that <code>days</code> does not <em>strictly</em> outlive <code>inspector</code> doesn’t matter. As long as the <code>inspector</code> is alive, so is days.</p>
  <p>However if we add a destructor, the program will no longer compile!</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">struct</span> Inspector&lt;<span class="ot">'a</span>&gt;(&amp;<span class="ot">'a</span> <span class="dt">u8</span>);
  
  <span class="kw">impl</span>&lt;<span class="ot">'a</span>&gt; <span class="bu">Drop</span> <span class="kw">for</span> Inspector&lt;<span class="ot">'a</span>&gt; {
      <span class="kw">fn</span> drop(&amp;<span class="kw">mut</span> <span class="kw">self</span>) {
          <span class="pp">println!</span>(<span class="st">&quot;I was only {} days from retirement!&quot;</span>, <span class="kw">self</span>.<span class="dv">0</span>);
      }
  }
  
  <span class="kw">fn</span> main() {
      <span class="kw">let</span> (inspector, days);
      days = <span class="dt">Box</span>::new(<span class="dv">1</span>);
      inspector = Inspector(&amp;days);
      <span class="co">// Let's say `days` happens to get dropped first.</span>
      <span class="co">// Then when Inspector is dropped, it will try to read free'd memory!</span>
  }</code></pre></div>
  <pre class="text"><code>&lt;anon&gt;:12:28: 12:32 error: `days` does not live long enough
  &lt;anon&gt;:12     inspector = Inspector(&amp;days);
                                       ^~~~
  &lt;anon&gt;:9:11: 15:2 note: reference must be valid for the block at 9:10...
  &lt;anon&gt;:9 fn main() {
  &lt;anon&gt;:10     let (inspector, days);
  &lt;anon&gt;:11     days = Box::new(1);
  &lt;anon&gt;:12     inspector = Inspector(&amp;days);
  &lt;anon&gt;:13     // Let's say `days` happens to get dropped first.
  &lt;anon&gt;:14     // Then when Inspector is dropped, it will try to read free'd memory!
            ...
  &lt;anon&gt;:10:27: 15:2 note: ...but borrowed value is only valid for the block suffix foll
  ↳ owing statement 0 at 10:26
  &lt;anon&gt;:10     let (inspector, days);
  &lt;anon&gt;:11     days = Box::new(1);
  &lt;anon&gt;:12     inspector = Inspector(&amp;days);
  &lt;anon&gt;:13     // Let's say `days` happens to get dropped first.
  &lt;anon&gt;:14     // Then when Inspector is dropped, it will try to read free'd memory!
  &lt;anon&gt;:15 }</code></pre>
  <p>Implementing Drop lets the Inspector execute some arbitrary code during its death. This means it can potentially observe that types that are supposed to live as long as it does actually were destroyed first.</p>
  <p>Interestingly, only generic types need to worry about this. If they aren’t generic, then the only lifetimes they can harbor are <code>'static</code>, which will truly live <em>forever</em>. This is why this problem is referred to as <em>sound generic drop</em>. Sound generic drop is enforced by the <em>drop checker</em>. As of this writing, some of the finer details of how the drop checker validates types is totally up in the air. However The Big Rule is the subtlety that we have focused on this whole section:</p>
  <p><strong>For a generic type to soundly implement drop, its generics arguments must strictly outlive it.</strong></p>
  <p>Obeying this rule is (usually) necessary to satisfy the borrow checker; obeying it is sufficient but not necessary to be sound. That is, if your type obeys this rule then it’s definitely sound to drop.</p>
  <p>The reason that it is not always necessary to satisfy the above rule is that some Drop implementations will not access borrowed data even though their type gives them the capability for such access.</p>
  <p>For example, this variant of the above <code>Inspector</code> example will never accessed borrowed data:</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">struct</span> Inspector&lt;<span class="ot">'a</span>&gt;(&amp;<span class="ot">'a</span> <span class="dt">u8</span>, &amp;<span class="ot">'static</span> <span class="dt">str</span>);
  
  <span class="kw">impl</span>&lt;<span class="ot">'a</span>&gt; <span class="bu">Drop</span> <span class="kw">for</span> Inspector&lt;<span class="ot">'a</span>&gt; {
      <span class="kw">fn</span> drop(&amp;<span class="kw">mut</span> <span class="kw">self</span>) {
          <span class="pp">println!</span>(<span class="st">&quot;Inspector(_, {}) knows when *not* to inspect.&quot;</span>, <span class="kw">self</span>.<span class="dv">1</span>);
      }
  }
  
  <span class="kw">fn</span> main() {
      <span class="kw">let</span> (inspector, days);
      days = <span class="dt">Box</span>::new(<span class="dv">1</span>);
      inspector = Inspector(&amp;days, <span class="st">&quot;gadget&quot;</span>);
      <span class="co">// Let's say `days` happens to get dropped first.</span>
      <span class="co">// Even when Inspector is dropped, its destructor will not access the</span>
      <span class="co">// borrowed `days`.</span>
  }</code></pre></div>
  <p>Likewise, this variant will also never access borrowed data:</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">use</span> std::fmt;
  
  <span class="kw">struct</span> Inspector&lt;T: fmt::<span class="bu">Display</span>&gt;(T, &amp;<span class="ot">'static</span> <span class="dt">str</span>);
  
  <span class="kw">impl</span>&lt;T: fmt::<span class="bu">Display</span>&gt; <span class="bu">Drop</span> <span class="kw">for</span> Inspector&lt;T&gt; {
      <span class="kw">fn</span> drop(&amp;<span class="kw">mut</span> <span class="kw">self</span>) {
          <span class="pp">println!</span>(<span class="st">&quot;Inspector(_, {}) knows when *not* to inspect.&quot;</span>, <span class="kw">self</span>.<span class="dv">1</span>);
      }
  }
  
  <span class="kw">fn</span> main() {
      <span class="kw">let</span> (inspector, days): (Inspector&lt;&amp;<span class="dt">u8</span>&gt;, <span class="dt">Box</span>&lt;<span class="dt">u8</span>&gt;);
      days = <span class="dt">Box</span>::new(<span class="dv">1</span>);
      inspector = Inspector(&amp;days, <span class="st">&quot;gadget&quot;</span>);
      <span class="co">// Let's say `days` happens to get dropped first.</span>
      <span class="co">// Even when Inspector is dropped, its destructor will not access the</span>
      <span class="co">// borrowed `days`.</span>
  }</code></pre></div>
  <p>However, <em>both</em> of the above variants are rejected by the borrow checker during the analysis of <code>fn main</code>, saying that <code>days</code> does not live long enough.</p>
  <p>The reason is that the borrow checking analysis of <code>main</code> does not know about the internals of each Inspector’s Drop implementation. As far as the borrow checker knows while it is analyzing <code>main</code>, the body of an inspector’s destructor might access that borrowed data.</p>
  <p>Therefore, the drop checker forces all borrowed data in a value to strictly outlive that value.</p>
  <section id="an-escape-hatch" class="level3">
  <h3>An Escape Hatch</h3>
  <p>The precise rules that govern drop checking may be less restrictive in the future.</p>
  <p>The current analysis is deliberately conservative and trivial; it forces all borrowed data in a value to outlive that value, which is certainly sound.</p>
  <p>Future versions of the language may make the analysis more precise, to reduce the number of cases where sound code is rejected as unsafe. This would help address cases such as the two Inspectors above that know not to inspect during destruction.</p>
  <p>In the meantime, there is an unstable attribute that one can use to assert (unsafely) that a generic type’s destructor is <em>guaranteed</em> to not access any expired data, even if its type gives it the capability to do so.</p>
  <p>That attribute is called <code>unsafe_destructor_blind_to_params</code>. To deploy it on the Inspector example from above, we would write:</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">struct</span> Inspector&lt;<span class="ot">'a</span>&gt;(&amp;<span class="ot">'a</span> <span class="dt">u8</span>, &amp;<span class="ot">'static</span> <span class="dt">str</span>);
  
  <span class="kw">impl</span>&lt;<span class="ot">'a</span>&gt; <span class="bu">Drop</span> <span class="kw">for</span> Inspector&lt;<span class="ot">'a</span>&gt; {
      <span class="at">#[</span>unsafe_destructor_blind_to_params<span class="at">]</span>
      <span class="kw">fn</span> drop(&amp;<span class="kw">mut</span> <span class="kw">self</span>) {
          <span class="pp">println!</span>(<span class="st">&quot;Inspector(_, {}) knows when *not* to inspect.&quot;</span>, <span class="kw">self</span>.<span class="dv">1</span>);
      }
  }</code></pre></div>
  <p>This attribute has the word <code>unsafe</code> in it because the compiler is not checking the implicit assertion that no potentially expired data (e.g. <code>self.0</code> above) is accessed.</p>
  <p>It is sometimes obvious that no such access can occur, like the case above. However, when dealing with a generic type parameter, such access can occur indirectly. Examples of such indirect access are:</p>
  <ul>
  <li>invoking a callback,</li>
  <li>via a trait method call.</li>
  </ul>
  <p>(Future changes to the language, such as impl specialization, may add other avenues for such indirect access.)</p>
  <p>Here is an example of invoking a callback:</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">struct</span> Inspector&lt;T&gt;(T, &amp;<span class="ot">'static</span> <span class="dt">str</span>, <span class="dt">Box</span>&lt;<span class="kw">for</span> &lt;<span class="ot">'r</span>&gt; <span class="kw">fn</span>(&amp;<span class="ot">'r</span> T) -&gt; <span class="dt">String</span>&gt;);
  
  <span class="kw">impl</span>&lt;T&gt; <span class="bu">Drop</span> <span class="kw">for</span> Inspector&lt;T&gt; {
      <span class="kw">fn</span> drop(&amp;<span class="kw">mut</span> <span class="kw">self</span>) {
          <span class="co">// The `self.2` call could access a borrow e.g. if `T` is `&amp;'a _`.</span>
          <span class="pp">println!</span>(<span class="st">&quot;Inspector({}, {}) unwittingly inspects expired data.&quot;</span>,
                   (<span class="kw">self</span>.<span class="dv">2</span>)(&amp;<span class="kw">self</span>.<span class="dv">0</span>), <span class="kw">self</span>.<span class="dv">1</span>);
      }
  }</code></pre></div>
  <p>Here is an example of a trait method call:</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">use</span> std::fmt;
  
  <span class="kw">struct</span> Inspector&lt;T: fmt::<span class="bu">Display</span>&gt;(T, &amp;<span class="ot">'static</span> <span class="dt">str</span>);
  
  <span class="kw">impl</span>&lt;T: fmt::<span class="bu">Display</span>&gt; <span class="bu">Drop</span> <span class="kw">for</span> Inspector&lt;T&gt; {
      <span class="kw">fn</span> drop(&amp;<span class="kw">mut</span> <span class="kw">self</span>) {
          <span class="co">// There is a hidden call to `&lt;T as Display&gt;::fmt` below, which</span>
          <span class="co">// could access a borrow e.g. if `T` is `&amp;'a _`</span>
          <span class="pp">println!</span>(<span class="st">&quot;Inspector({}, {}) unwittingly inspects expired data.&quot;</span>,
                   <span class="kw">self</span>.<span class="dv">0</span>, <span class="kw">self</span>.<span class="dv">1</span>);
      }
  }</code></pre></div>
  <p>And of course, all of these accesses could be further hidden within some other method invoked by the destructor, rather than being written directly within it.</p>
  <p>In all of the above cases where the <code>&amp;'a u8</code> is accessed in the destructor, adding the <code>#[unsafe_destructor_blind_to_params]</code> attribute makes the type vulnerable to misuse that the borrower checker will not catch, inviting havoc. It is better to avoid adding the attribute.</p>
  </section>
  <section id="is-that-all-about-drop-checker" class="level3">
  <h3>Is that all about drop checker?</h3>
  <p>It turns out that when writing unsafe code, we generally don’t need to worry at all about doing the right thing for the drop checker. However there is one special case that you need to worry about, which we will look at in the next section.</p>
  </section>
  </section>
  <section id="sec--phantom-data" class="level2">
  <h2>PhantomData</h2>
  <p>When working with unsafe code, we can often end up in a situation where types or lifetimes are logically associated with a struct, but not actually part of a field. This most commonly occurs with lifetimes. For instance, the <code>Iter</code> for <code>&amp;'a [T]</code> is (approximately) defined as follows:</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">struct</span> Iter&lt;<span class="ot">'a</span>, T: <span class="ot">'a</span>&gt; {
      ptr: *<span class="kw">const</span> T,
      end: *<span class="kw">const</span> T,
  }</code></pre></div>
  <p>However because <code>'a</code> is unused within the struct’s body, it’s <em>unbounded</em>. Because of the troubles this has historically caused, unbounded lifetimes and types are <em>forbidden</em> in struct definitions. Therefore we must somehow refer to these types in the body. Correctly doing this is necessary to have correct variance and drop checking.</p>
  <p>We do this using <code>PhantomData</code>, which is a special marker type. <code>PhantomData</code> consumes no space, but simulates a field of the given type for the purpose of static analysis. This was deemed to be less error-prone than explicitly telling the type-system the kind of variance that you want, while also providing other useful such as the information needed by drop check.</p>
  <p>Iter logically contains a bunch of <code>&amp;'a T</code>s, so this is exactly what we tell the PhantomData to simulate:</p>
  <pre><code>use std::marker;
  
  struct Iter&lt;'a, T: 'a&gt; {
      ptr: *const T,
      end: *const T,
      _marker: marker::PhantomData&lt;&amp;'a T&gt;,
  }</code></pre>
  <p>and that’s it. The lifetime will be bounded, and your iterator will be variant over <code>'a</code> and <code>T</code>. Everything Just Works.</p>
  <p>Another important example is Vec, which is (approximately) defined as follows:</p>
  <pre><code>struct Vec&lt;T&gt; {
      data: *const T, // *const for variance!
      len: usize,
      cap: usize,
  }</code></pre>
  <p>Unlike the previous example it <em>appears</em> that everything is exactly as we want. Every generic argument to Vec shows up in the at least one field. Good to go!</p>
  <p>Nope.</p>
  <p>The drop checker will generously determine that Vec<T> does not own any values of type T. This will in turn make it conclude that it doesn’t need to worry about Vec dropping any T’s in its destructor for determining drop check soundness. This will in turn allow people to create unsoundness using Vec’s destructor.</p>
  <p>In order to tell dropck that we <em>do</em> own values of type T, and therefore may drop some T’s when <em>we</em> drop, we must add an extra PhantomData saying exactly that:</p>
  <pre><code>use std::marker;
  
  struct Vec&lt;T&gt; {
      data: *const T, // *const for covariance!
      len: usize,
      cap: usize,
      _marker: marker::PhantomData&lt;T&gt;,
  }</code></pre>
  <p>Raw pointers that own an allocation is such a pervasive pattern that the standard library made a utility for itself called <code>Unique&lt;T&gt;</code> which:</p>
  <ul>
  <li>wraps a <code>*const T</code> for variance</li>
  <li>includes a <code>PhantomData&lt;T&gt;</code>,</li>
  <li>auto-derives Send/Sync as if T was contained</li>
  <li>marks the pointer as NonZero for the null-pointer optimization</li>
  </ul>
  </section>
  <section id="sec--borrow-splitting" class="level2">
  <h2>Splitting Borrows</h2>
  <p>The mutual exclusion property of mutable references can be very limiting when working with a composite structure. The borrow checker understands some basic stuff, but will fall over pretty easily. It does understand structs sufficiently to know that it’s possible to borrow disjoint fields of a struct simultaneously. So this works today:</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">struct</span> Foo {
      a: <span class="dt">i32</span>,
      b: <span class="dt">i32</span>,
      c: <span class="dt">i32</span>,
  }
  
  <span class="kw">let</span> <span class="kw">mut</span> x = Foo {a: <span class="dv">0</span>, b: <span class="dv">0</span>, c: <span class="dv">0</span>};
  <span class="kw">let</span> a = &amp;<span class="kw">mut</span> x.a;
  <span class="kw">let</span> b = &amp;<span class="kw">mut</span> x.b;
  <span class="kw">let</span> c = &amp;x.c;
  *b += <span class="dv">1</span>;
  <span class="kw">let</span> c2 = &amp;x.c;
  *a += <span class="dv">10</span>;
  <span class="pp">println!</span>(<span class="st">&quot;{} {} {} {}&quot;</span>, a, b, c, c2);</code></pre></div>
  <p>However borrowck doesn’t understand arrays or slices in any way, so this doesn’t work:</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">let</span> <span class="kw">mut</span> x = [<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>];
  <span class="kw">let</span> a = &amp;<span class="kw">mut</span> x[<span class="dv">0</span>];
  <span class="kw">let</span> b = &amp;<span class="kw">mut</span> x[<span class="dv">1</span>];
  <span class="pp">println!</span>(<span class="st">&quot;{} {}&quot;</span>, a, b);</code></pre></div>
  <pre class="text"><code>&lt;anon&gt;:4:14: 4:18 error: cannot borrow `x[..]` as mutable more than once at a time
  &lt;anon&gt;:4 let b = &amp;mut x[1];
                        ^~~~
  &lt;anon&gt;:3:14: 3:18 note: previous borrow of `x[..]` occurs here; the mutable borrow pre
  ↳ vents subsequent moves, borrows, or modification of `x[..]` until the borrow ends
  &lt;anon&gt;:3 let a = &amp;mut x[0];
                        ^~~~
  &lt;anon&gt;:6:2: 6:2 note: previous borrow ends here
  &lt;anon&gt;:1 fn main() {
  &lt;anon&gt;:2 let mut x = [1, 2, 3];
  &lt;anon&gt;:3 let a = &amp;mut x[0];
  &lt;anon&gt;:4 let b = &amp;mut x[1];
  &lt;anon&gt;:5 println!(&quot;{} {}&quot;, a, b);
  &lt;anon&gt;:6 }
           ^
  error: aborting due to 2 previous errors</code></pre>
  <p>While it was plausible that borrowck could understand this simple case, it’s pretty clearly hopeless for borrowck to understand disjointness in general container types like a tree, especially if distinct keys actually <em>do</em> map to the same value.</p>
  <p>In order to “teach” borrowck that what we’re doing is ok, we need to drop down to unsafe code. For instance, mutable slices expose a <code>split_at_mut</code> function that consumes the slice and returns two mutable slices. One for everything to the left of the index, and one for everything to the right. Intuitively we know this is safe because the slices don’t overlap, and therefore alias. However the implementation requires some unsafety:</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">fn</span> split_at_mut(&amp;<span class="kw">mut</span> <span class="kw">self</span>, mid: <span class="dt">usize</span>) -&gt; (&amp;<span class="kw">mut</span> [T], &amp;<span class="kw">mut</span> [T]) {
      <span class="kw">let</span> len = <span class="kw">self</span>.len();
      <span class="kw">let</span> ptr = <span class="kw">self</span>.as_mut_ptr();
      <span class="pp">assert!</span>(mid &lt;= len);
      <span class="kw">unsafe</span> {
          (from_raw_parts_mut(ptr, mid),
           from_raw_parts_mut(ptr.offset(mid <span class="kw">as</span> <span class="dt">isize</span>), len - mid))
      }
  }</code></pre></div>
  <p>This is actually a bit subtle. So as to avoid ever making two <code>&amp;mut</code>’s to the same value, we explicitly construct brand-new slices through raw pointers.</p>
  <p>However more subtle is how iterators that yield mutable references work. The iterator trait is defined as follows:</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">trait</span> <span class="bu">Iterator</span> {
      <span class="kw">type</span> Item;
  
      <span class="kw">fn</span> next(&amp;<span class="kw">mut</span> <span class="kw">self</span>) -&gt; <span class="dt">Option</span>&lt;<span class="kw">Self</span>::Item&gt;;
  }</code></pre></div>
  <p>Given this definition, Self::Item has <em>no</em> connection to <code>self</code>. This means that we can call <code>next</code> several times in a row, and hold onto all the results <em>concurrently</em>. This is perfectly fine for by-value iterators, which have exactly these semantics. It’s also actually fine for shared references, as they admit arbitrarily many references to the same thing (although the iterator needs to be a separate object from the thing being shared).</p>
  <p>But mutable references make this a mess. At first glance, they might seem completely incompatible with this API, as it would produce multiple mutable references to the same object!</p>
  <p>However it actually <em>does</em> work, exactly because iterators are one-shot objects. Everything an IterMut yields will be yielded at most once, so we don’t actually ever yield multiple mutable references to the same piece of data.</p>
  <p>Perhaps surprisingly, mutable iterators don’t require unsafe code to be implemented for many types!</p>
  <p>For instance here’s a singly linked list:</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">type</span> Link&lt;T&gt; = <span class="dt">Option</span>&lt;<span class="dt">Box</span>&lt;Node&lt;T&gt;&gt;&gt;;
  
  <span class="kw">struct</span> Node&lt;T&gt; {
      elem: T,
      next: Link&lt;T&gt;,
  }
  
  <span class="kw">pub</span> <span class="kw">struct</span> LinkedList&lt;T&gt; {
      head: Link&lt;T&gt;,
  }
  
  <span class="kw">pub</span> <span class="kw">struct</span> IterMut&lt;<span class="ot">'a</span>, T: <span class="ot">'a</span>&gt;(<span class="dt">Option</span>&lt;&amp;<span class="ot">'a</span> <span class="kw">mut</span> Node&lt;T&gt;&gt;);
  
  <span class="kw">impl</span>&lt;T&gt; LinkedList&lt;T&gt; {
      <span class="kw">fn</span> iter_mut(&amp;<span class="kw">mut</span> <span class="kw">self</span>) -&gt; IterMut&lt;T&gt; {
          IterMut(<span class="kw">self</span>.head.as_mut().map(|node| &amp;<span class="kw">mut</span> **node))
      }
  }
  
  <span class="kw">impl</span>&lt;<span class="ot">'a</span>, T&gt; <span class="bu">Iterator</span> <span class="kw">for</span> IterMut&lt;<span class="ot">'a</span>, T&gt; {
      <span class="kw">type</span> Item = &amp;<span class="ot">'a</span> <span class="kw">mut</span> T;
  
      <span class="kw">fn</span> next(&amp;<span class="kw">mut</span> <span class="kw">self</span>) -&gt; <span class="dt">Option</span>&lt;<span class="kw">Self</span>::Item&gt; {
          <span class="kw">self</span>.<span class="dv">0.</span>take().map(|node| {
              <span class="kw">self</span>.<span class="dv">0</span> = node.next.as_mut().map(|node| &amp;<span class="kw">mut</span> **node);
              &amp;<span class="kw">mut</span> node.elem
          })
      }
  }</code></pre></div>
  <p>Here’s a mutable slice:</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">use</span> std::mem;
  
  <span class="kw">pub</span> <span class="kw">struct</span> IterMut&lt;<span class="ot">'a</span>, T: <span class="ot">'a</span>&gt;(&amp;<span class="ot">'a</span> <span class="kw">mut</span>[T]);
  
  <span class="kw">impl</span>&lt;<span class="ot">'a</span>, T&gt; <span class="bu">Iterator</span> <span class="kw">for</span> IterMut&lt;<span class="ot">'a</span>, T&gt; {
      <span class="kw">type</span> Item = &amp;<span class="ot">'a</span> <span class="kw">mut</span> T;
  
      <span class="kw">fn</span> next(&amp;<span class="kw">mut</span> <span class="kw">self</span>) -&gt; <span class="dt">Option</span>&lt;<span class="kw">Self</span>::Item&gt; {
          <span class="kw">let</span> slice = mem::replace(&amp;<span class="kw">mut</span> <span class="kw">self</span>.<span class="dv">0</span>, &amp;<span class="kw">mut</span> []);
          <span class="kw">if</span> slice.is_empty() { <span class="kw">return</span> <span class="cn">None</span>; }
  
          <span class="kw">let</span> (l, r) = slice.split_at_mut(<span class="dv">1</span>);
          <span class="kw">self</span>.<span class="dv">0</span> = r;
          l.get_mut(<span class="dv">0</span>)
      }
  }
  
  <span class="kw">impl</span>&lt;<span class="ot">'a</span>, T&gt; <span class="bu">DoubleEndedIterator</span> <span class="kw">for</span> IterMut&lt;<span class="ot">'a</span>, T&gt; {
      <span class="kw">fn</span> next_back(&amp;<span class="kw">mut</span> <span class="kw">self</span>) -&gt; <span class="dt">Option</span>&lt;<span class="kw">Self</span>::Item&gt; {
          <span class="kw">let</span> slice = mem::replace(&amp;<span class="kw">mut</span> <span class="kw">self</span>.<span class="dv">0</span>, &amp;<span class="kw">mut</span> []);
          <span class="kw">if</span> slice.is_empty() { <span class="kw">return</span> <span class="cn">None</span>; }
  
          <span class="kw">let</span> new_len = slice.len() - <span class="dv">1</span>;
          <span class="kw">let</span> (l, r) = slice.split_at_mut(new_len);
          <span class="kw">self</span>.<span class="dv">0</span> = l;
          r.get_mut(<span class="dv">0</span>)
      }
  }</code></pre></div>
  <p>And here’s a binary tree:</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">use</span> std::collections::VecDeque;
  
  <span class="kw">type</span> Link&lt;T&gt; = <span class="dt">Option</span>&lt;<span class="dt">Box</span>&lt;Node&lt;T&gt;&gt;&gt;;
  
  <span class="kw">struct</span> Node&lt;T&gt; {
      elem: T,
      left: Link&lt;T&gt;,
      right: Link&lt;T&gt;,
  }
  
  <span class="kw">pub</span> <span class="kw">struct</span> Tree&lt;T&gt; {
      root: Link&lt;T&gt;,
  }
  
  <span class="kw">struct</span> NodeIterMut&lt;<span class="ot">'a</span>, T: <span class="ot">'a</span>&gt; {
      elem: <span class="dt">Option</span>&lt;&amp;<span class="ot">'a</span> <span class="kw">mut</span> T&gt;,
      left: <span class="dt">Option</span>&lt;&amp;<span class="ot">'a</span> <span class="kw">mut</span> Node&lt;T&gt;&gt;,
      right: <span class="dt">Option</span>&lt;&amp;<span class="ot">'a</span> <span class="kw">mut</span> Node&lt;T&gt;&gt;,
  }
  
  <span class="kw">enum</span> State&lt;<span class="ot">'a</span>, T: <span class="ot">'a</span>&gt; {
      Elem(&amp;<span class="ot">'a</span> <span class="kw">mut</span> T),
      Node(&amp;<span class="ot">'a</span> <span class="kw">mut</span> Node&lt;T&gt;),
  }
  
  <span class="kw">pub</span> <span class="kw">struct</span> IterMut&lt;<span class="ot">'a</span>, T: <span class="ot">'a</span>&gt;(VecDeque&lt;NodeIterMut&lt;<span class="ot">'a</span>, T&gt;&gt;);
  
  <span class="kw">impl</span>&lt;T&gt; Tree&lt;T&gt; {
      <span class="kw">pub</span> <span class="kw">fn</span> iter_mut(&amp;<span class="kw">mut</span> <span class="kw">self</span>) -&gt; IterMut&lt;T&gt; {
          <span class="kw">let</span> <span class="kw">mut</span> deque = VecDeque::new();
          <span class="kw">self</span>.root.as_mut().map(|root| deque.push_front(root.iter_mut()));
          IterMut(deque)
      }
  }
  
  <span class="kw">impl</span>&lt;T&gt; Node&lt;T&gt; {
      <span class="kw">pub</span> <span class="kw">fn</span> iter_mut(&amp;<span class="kw">mut</span> <span class="kw">self</span>) -&gt; NodeIterMut&lt;T&gt; {
          NodeIterMut {
              elem: <span class="cn">Some</span>(&amp;<span class="kw">mut</span> <span class="kw">self</span>.elem),
              left: <span class="kw">self</span>.left.as_mut().map(|node| &amp;<span class="kw">mut</span> **node),
              right: <span class="kw">self</span>.right.as_mut().map(|node| &amp;<span class="kw">mut</span> **node),
          }
      }
  }
  
  
  <span class="kw">impl</span>&lt;<span class="ot">'a</span>, T&gt; <span class="bu">Iterator</span> <span class="kw">for</span> NodeIterMut&lt;<span class="ot">'a</span>, T&gt; {
      <span class="kw">type</span> Item = State&lt;<span class="ot">'a</span>, T&gt;;
  
      <span class="kw">fn</span> next(&amp;<span class="kw">mut</span> <span class="kw">self</span>) -&gt; <span class="dt">Option</span>&lt;<span class="kw">Self</span>::Item&gt; {
          <span class="kw">match</span> <span class="kw">self</span>.left.take() {
              <span class="cn">Some</span>(node) =&gt; <span class="cn">Some</span>(State::Node(node)),
              <span class="cn">None</span> =&gt; <span class="kw">match</span> <span class="kw">self</span>.elem.take() {
                  <span class="cn">Some</span>(elem) =&gt; <span class="cn">Some</span>(State::Elem(elem)),
                  <span class="cn">None</span> =&gt; <span class="kw">match</span> <span class="kw">self</span>.right.take() {
                      <span class="cn">Some</span>(node) =&gt; <span class="cn">Some</span>(State::Node(node)),
                      <span class="cn">None</span> =&gt; <span class="cn">None</span>,
                  }
              }
          }
      }
  }
  
  <span class="kw">impl</span>&lt;<span class="ot">'a</span>, T&gt; <span class="bu">DoubleEndedIterator</span> <span class="kw">for</span> NodeIterMut&lt;<span class="ot">'a</span>, T&gt; {
      <span class="kw">fn</span> next_back(&amp;<span class="kw">mut</span> <span class="kw">self</span>) -&gt; <span class="dt">Option</span>&lt;<span class="kw">Self</span>::Item&gt; {
          <span class="kw">match</span> <span class="kw">self</span>.right.take() {
              <span class="cn">Some</span>(node) =&gt; <span class="cn">Some</span>(State::Node(node)),
              <span class="cn">None</span> =&gt; <span class="kw">match</span> <span class="kw">self</span>.elem.take() {
                  <span class="cn">Some</span>(elem) =&gt; <span class="cn">Some</span>(State::Elem(elem)),
                  <span class="cn">None</span> =&gt; <span class="kw">match</span> <span class="kw">self</span>.left.take() {
                      <span class="cn">Some</span>(node) =&gt; <span class="cn">Some</span>(State::Node(node)),
                      <span class="cn">None</span> =&gt; <span class="cn">None</span>,
                  }
              }
          }
      }
  }
  
  <span class="kw">impl</span>&lt;<span class="ot">'a</span>, T&gt; <span class="bu">Iterator</span> <span class="kw">for</span> IterMut&lt;<span class="ot">'a</span>, T&gt; {
      <span class="kw">type</span> Item = &amp;<span class="ot">'a</span> <span class="kw">mut</span> T;
      <span class="kw">fn</span> next(&amp;<span class="kw">mut</span> <span class="kw">self</span>) -&gt; <span class="dt">Option</span>&lt;<span class="kw">Self</span>::Item&gt; {
          <span class="kw">loop</span> {
              <span class="kw">match</span> <span class="kw">self</span>.<span class="dv">0.f</span>ront_mut().and_then(|node_it| node_it.next()) {
                  <span class="cn">Some</span>(State::Elem(elem)) =&gt; <span class="kw">return</span> <span class="cn">Some</span>(elem),
                  <span class="cn">Some</span>(State::Node(node)) =&gt; <span class="kw">self</span>.<span class="dv">0.</span>push_front(node.iter_mut()),
                  <span class="cn">None</span> =&gt; <span class="kw">if</span> <span class="kw">let</span> <span class="cn">None</span> = <span class="kw">self</span>.<span class="dv">0.</span>pop_front() { <span class="kw">return</span> <span class="cn">None</span> },
              }
          }
      }
  }
  
  <span class="kw">impl</span>&lt;<span class="ot">'a</span>, T&gt; <span class="bu">DoubleEndedIterator</span> <span class="kw">for</span> IterMut&lt;<span class="ot">'a</span>, T&gt; {
      <span class="kw">fn</span> next_back(&amp;<span class="kw">mut</span> <span class="kw">self</span>) -&gt; <span class="dt">Option</span>&lt;<span class="kw">Self</span>::Item&gt; {
          <span class="kw">loop</span> {
              <span class="kw">match</span> <span class="kw">self</span>.<span class="dv">0.</span>back_mut().and_then(|node_it| node_it.next_back()) {
                  <span class="cn">Some</span>(State::Elem(elem)) =&gt; <span class="kw">return</span> <span class="cn">Some</span>(elem),
                  <span class="cn">Some</span>(State::Node(node)) =&gt; <span class="kw">self</span>.<span class="dv">0.</span>push_back(node.iter_mut()),
                  <span class="cn">None</span> =&gt; <span class="kw">if</span> <span class="kw">let</span> <span class="cn">None</span> = <span class="kw">self</span>.<span class="dv">0.</span>pop_back() { <span class="kw">return</span> <span class="cn">None</span> },
              }
          }
      }
  }</code></pre></div>
  <p>All of these are completely safe and work on stable Rust! This ultimately falls out of the simple struct case we saw before: Rust understands that you can safely split a mutable reference into subfields. We can then encode permanently consuming a reference via Options (or in the case of slices, replacing with an empty slice).</p>
  </section>
  </section>
  <section id="sec--conversions" class="level1">
  <h1>Type Conversions</h1>
  <p>At the end of the day, everything is just a pile of bits somewhere, and type systems are just there to help us use those bits right. There are two common problems with typing bits: needing to reinterpret those exact bits as a different type, and needing to change the bits to have equivalent meaning for a different type. Because Rust encourages encoding important properties in the type system, these problems are incredibly pervasive. As such, Rust consequently gives you several ways to solve them.</p>
  <p>First we’ll look at the ways that Safe Rust gives you to reinterpret values. The most trivial way to do this is to just destructure a value into its constituent parts and then build a new type out of them. e.g.</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">struct</span> Foo {
      x: <span class="dt">u32</span>,
      y: <span class="dt">u16</span>,
  }
  
  <span class="kw">struct</span> Bar {
      a: <span class="dt">u32</span>,
      b: <span class="dt">u16</span>,
  }
  
  <span class="kw">fn</span> reinterpret(foo: Foo) -&gt; Bar {
      <span class="kw">let</span> Foo { x, y } = foo;
      Bar { a: x, b: y }
  }</code></pre></div>
  <p>But this is, at best, annoying. For common conversions, Rust provides more ergonomic alternatives.</p>
  <section id="sec--coercions" class="level2">
  <h2>Coercions</h2>
  <p>Types can implicitly be coerced to change in certain contexts. These changes are generally just <em>weakening</em> of types, largely focused around pointers and lifetimes. They mostly exist to make Rust “just work” in more cases, and are largely harmless.</p>
  <p>Here’s all the kinds of coercion:</p>
  <p>Coercion is allowed between the following types:</p>
  <ul>
  <li>Transitivity: <code>T_1</code> to <code>T_3</code> where <code>T_1</code> coerces to <code>T_2</code> and <code>T_2</code> coerces to <code>T_3</code></li>
  <li>Pointer Weakening:
  <ul>
  <li><code>&amp;mut T</code> to <code>&amp;T</code></li>
  <li><code>*mut T</code> to <code>*const T</code></li>
  <li><code>&amp;T</code> to <code>*const T</code></li>
  <li><code>&amp;mut T</code> to <code>*mut T</code></li>
  </ul></li>
  <li>Unsizing: <code>T</code> to <code>U</code> if <code>T</code> implements <code>CoerceUnsized&lt;U&gt;</code></li>
  </ul>
  <p><code>CoerceUnsized&lt;Pointer&lt;U&gt;&gt; for Pointer&lt;T&gt; where T: Unsize&lt;U&gt;</code> is implemented for all pointer types (including smart pointers like Box and Rc). Unsize is only implemented automatically, and enables the following transformations:</p>
  <ul>
  <li><code>[T; n]</code> =&gt; <code>[T]</code></li>
  <li><code>T</code> =&gt; <code>Trait</code> where <code>T: Trait</code></li>
  <li><code>Foo&lt;..., T, ...&gt;</code> =&gt; <code>Foo&lt;..., U, ...&gt;</code> where:
  <ul>
  <li><code>T: Unsize&lt;U&gt;</code></li>
  <li><code>Foo</code> is a struct</li>
  <li>Only the last field of <code>Foo</code> has type <code>T</code></li>
  <li><code>T</code> is not part of the type of any other fields</li>
  </ul></li>
  </ul>
  <p>Coercions occur at a <em>coercion site</em>. Any location that is explicitly typed will cause a coercion to its type. If inference is necessary, the coercion will not be performed. Exhaustively, the coercion sites for an expression <code>e</code> to type <code>U</code> are:</p>
  <ul>
  <li>let statements, statics, and consts: <code>let x: U = e</code></li>
  <li>Arguments to functions: <code>takes_a_U(e)</code></li>
  <li>Any expression that will be returned: <code>fn foo() -&gt; U { e }</code></li>
  <li>Struct literals: <code>Foo { some_u: e }</code></li>
  <li>Array literals: <code>let x: [U; 10] = [e, ..]</code></li>
  <li>Tuple literals: <code>let x: (U, ..) = (e, ..)</code></li>
  <li>The last expression in a block: <code>let x: U = { ..; e }</code></li>
  </ul>
  <p>Note that we do not perform coercions when matching traits (except for receivers, see below). If there is an impl for some type <code>U</code> and <code>T</code> coerces to <code>U</code>, that does not constitute an implementation for <code>T</code>. For example, the following will not type check, even though it is OK to coerce <code>t</code> to <code>&amp;T</code> and there is an impl for <code>&amp;T</code>:</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">trait</span> Trait {}
  
  <span class="kw">fn</span> foo&lt;X: Trait&gt;(t: X) {}
  
  <span class="kw">impl</span>&lt;<span class="ot">'a</span>&gt; Trait <span class="kw">for</span> &amp;<span class="ot">'a</span> <span class="dt">i32</span> {}
  
  
  <span class="kw">fn</span> main() {
      <span class="kw">let</span> t: &amp;<span class="kw">mut</span> <span class="dt">i32</span> = &amp;<span class="kw">mut</span> <span class="dv">0</span>;
      foo(t);
  }</code></pre></div>
  <pre class="text"><code>&lt;anon&gt;:10:5: 10:8 error: the trait bound `&amp;mut i32 : Trait` is not satisfied [E0277]
  &lt;anon&gt;:10     foo(t);
                ^~~</code></pre>
  </section>
  <section id="sec--dot-operator" class="level2">
  <h2>The Dot Operator</h2>
  <p>The dot operator will perform a lot of magic to convert types. It will perform auto-referencing, auto-dereferencing, and coercion until types match.</p>
  <p>TODO: steal information from http://stackoverflow.com/questions/28519997/what-are-rusts-exact-auto-dereferencing-rules/28552082#28552082</p>
  </section>
  <section id="sec--casts" class="level2">
  <h2>Casts</h2>
  <p>Casts are a superset of coercions: every coercion can be explicitly invoked via a cast. However some conversions require a cast. While coercions are pervasive and largely harmless, these “true casts” are rare and potentially dangerous. As such, casts must be explicitly invoked using the <code>as</code> keyword: <code>expr as Type</code>.</p>
  <p>True casts generally revolve around raw pointers and the primitive numeric types. Even though they’re dangerous, these casts are infallible at runtime. If a cast triggers some subtle corner case no indication will be given that this occurred. The cast will simply succeed. That said, casts must be valid at the type level, or else they will be prevented statically. For instance, <code>7u8 as bool</code> will not compile.</p>
  <p>That said, casts aren’t <code>unsafe</code> because they generally can’t violate memory safety <em>on their own</em>. For instance, converting an integer to a raw pointer can very easily lead to terrible things. However the act of creating the pointer itself is safe, because actually using a raw pointer is already marked as <code>unsafe</code>.</p>
  <p>Here’s an exhaustive list of all the true casts. For brevity, we will use <code>*</code> to denote either a <code>*const</code> or <code>*mut</code>, and <code>integer</code> to denote any integral primitive:</p>
  <ul>
  <li><code>*T as *U</code> where <code>T, U: Sized</code></li>
  <li><code>*T as *U</code> TODO: explain unsized situation</li>
  <li><code>*T as integer</code></li>
  <li><code>integer as *T</code></li>
  <li><code>number as number</code></li>
  <li><code>C-like-enum as integer</code></li>
  <li><code>bool as integer</code></li>
  <li><code>char as integer</code></li>
  <li><code>u8 as char</code></li>
  <li><code>&amp;[T; n] as *const T</code></li>
  <li><code>fn as *T</code> where <code>T: Sized</code></li>
  <li><code>fn as integer</code></li>
  </ul>
  <p>Note that lengths are not adjusted when casting raw slices - <code>*const [u16] as *const [u8]</code> creates a slice that only includes half of the original memory.</p>
  <p>Casting is not transitive, that is, even if <code>e as U1 as U2</code> is a valid expression, <code>e as U2</code> is not necessarily so.</p>
  <p>For numeric casts, there are quite a few cases to consider:</p>
  <ul>
  <li>casting between two integers of the same size (e.g. i32 -&gt; u32) is a no-op</li>
  <li>casting from a larger integer to a smaller integer (e.g. u32 -&gt; u8) will truncate</li>
  <li>casting from a smaller integer to a larger integer (e.g. u8 -&gt; u32) will
  <ul>
  <li>zero-extend if the source is unsigned</li>
  <li>sign-extend if the source is signed</li>
  </ul></li>
  <li>casting from a float to an integer will round the float towards zero
  <ul>
  <li><strong><a href="https://github.com/rust-lang/rust/issues/10184">NOTE: currently this will cause Undefined Behavior if the rounded value cannot be represented by the target integer type</a></strong>. This includes Inf and NaN. This is a bug and will be fixed.</li>
  </ul></li>
  <li>casting from an integer to float will produce the floating point representation of the integer, rounded if necessary (rounding strategy unspecified)</li>
  <li>casting from an f32 to an f64 is perfect and lossless</li>
  <li>casting from an f64 to an f32 will produce the closest possible value (rounding strategy unspecified)
  <ul>
  <li><strong><a href="https://github.com/rust-lang/rust/issues/15536">NOTE: currently this will cause Undefined Behavior if the value is finite but larger or smaller than the largest or smallest finite value representable by f32</a></strong>. This is a bug and will be fixed.</li>
  </ul></li>
  </ul>
  </section>
  <section id="sec--transmutes" class="level2">
  <h2>Transmutes</h2>
  <p>Get out of our way type system! We’re going to reinterpret these bits or die trying! Even though this book is all about doing things that are unsafe, I really can’t emphasize that you should deeply think about finding Another Way than the operations covered in this section. This is really, truly, the most horribly unsafe thing you can do in Rust. The railguards here are dental floss.</p>
  <p><code>mem::transmute&lt;T, U&gt;</code> takes a value of type <code>T</code> and reinterprets it to have type <code>U</code>. The only restriction is that the <code>T</code> and <code>U</code> are verified to have the same size. The ways to cause Undefined Behavior with this are mind boggling.</p>
  <ul>
  <li>First and foremost, creating an instance of <em>any</em> type with an invalid state is going to cause arbitrary chaos that can’t really be predicted.</li>
  <li>Transmute has an overloaded return type. If you do not specify the return type it may produce a surprising type to satisfy inference.</li>
  <li>Making a primitive with an invalid value is UB</li>
  <li>Transmuting between non-repr(C) types is UB</li>
  <li>Transmuting an &amp; to &amp;mut is UB
  <ul>
  <li>Transmuting an &amp; to &amp;mut is <em>always</em> UB</li>
  <li>No you can’t do it</li>
  <li>No you’re not special</li>
  </ul></li>
  <li>Transmuting to a reference without an explicitly provided lifetime produces an [unbounded lifetime]</li>
  </ul>
  <p><code>mem::transmute_copy&lt;T, U&gt;</code> somehow manages to be <em>even more</em> wildly unsafe than this. It copies <code>size_of&lt;U&gt;</code> bytes out of an <code>&amp;T</code> and interprets them as a <code>U</code>. The size check that <code>mem::transmute</code> has is gone (as it may be valid to copy out a prefix), though it is Undefined Behavior for <code>U</code> to be larger than <code>T</code>.</p>
  <p>Also of course you can get most of the functionality of these functions using pointer casts.</p>
  </section>
  </section>
  <section id="sec--uninitialized" class="level1">
  <h1>Uninitialized Memory</h1>
  <p>All runtime-allocated memory in a Rust program begins its life as <em>uninitialized</em>. In this state the value of the memory is an indeterminate pile of bits that may or may not even reflect a valid state for the type that is supposed to inhabit that location of memory. Attempting to interpret this memory as a value of <em>any</em> type will cause Undefined Behavior. Do Not Do This.</p>
  <p>Rust provides mechanisms to work with uninitialized memory in checked (safe) and unchecked (unsafe) ways.</p>
  <section id="sec--checked-uninit" class="level2">
  <h2>Checked</h2>
  <p>Like C, all stack variables in Rust are uninitialized until a value is explicitly assigned to them. Unlike C, Rust statically prevents you from ever reading them until you do:</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">fn</span> main() {
      <span class="kw">let</span> x: <span class="dt">i32</span>;
      <span class="pp">println!</span>(<span class="st">&quot;{}&quot;</span>, x);
  }</code></pre></div>
  <pre class="text"><code>src/main.rs:3:20: 3:21 error: use of possibly uninitialized variable: `x`
  src/main.rs:3     println!(&quot;{}&quot;, x);
                                   ^</code></pre>
  <p>This is based off of a basic branch analysis: every branch must assign a value to <code>x</code> before it is first used. Interestingly, Rust doesn’t require the variable to be mutable to perform a delayed initialization if every branch assigns exactly once. However the analysis does not take advantage of constant analysis or anything like that. So this compiles:</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">fn</span> main() {
      <span class="kw">let</span> x: <span class="dt">i32</span>;
  
      <span class="kw">if</span> <span class="cn">true</span> {
          x = <span class="dv">1</span>;
      } <span class="kw">else</span> {
          x = <span class="dv">2</span>;
      }
  
      <span class="pp">println!</span>(<span class="st">&quot;{}&quot;</span>, x);
  }</code></pre></div>
  <p>but this doesn’t:</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">fn</span> main() {
      <span class="kw">let</span> x: <span class="dt">i32</span>;
      <span class="kw">if</span> <span class="cn">true</span> {
          x = <span class="dv">1</span>;
      }
      <span class="pp">println!</span>(<span class="st">&quot;{}&quot;</span>, x);
  }</code></pre></div>
  <pre class="text"><code>src/main.rs:6:17: 6:18 error: use of possibly uninitialized variable: `x`
  src/main.rs:6   println!(&quot;{}&quot;, x);</code></pre>
  <p>while this does:</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">fn</span> main() {
      <span class="kw">let</span> x: <span class="dt">i32</span>;
      <span class="kw">if</span> <span class="cn">true</span> {
          x = <span class="dv">1</span>;
          <span class="pp">println!</span>(<span class="st">&quot;{}&quot;</span>, x);
      }
      <span class="co">// Don't care that there are branches where it's not initialized</span>
      <span class="co">// since we don't use the value in those branches</span>
  }</code></pre></div>
  <p>Of course, while the analysis doesn’t consider actual values, it does have a relatively sophisticated understanding of dependencies and control flow. For instance, this works:</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">let</span> x: <span class="dt">i32</span>;
  
  <span class="kw">loop</span> {
      <span class="co">// Rust doesn't understand that this branch will be taken unconditionally,</span>
      <span class="co">// because it relies on actual values.</span>
      <span class="kw">if</span> <span class="cn">true</span> {
          <span class="co">// But it does understand that it will only be taken once because</span>
          <span class="co">// we unconditionally break out of it. Therefore `x` doesn't</span>
          <span class="co">// need to be marked as mutable.</span>
          x = <span class="dv">0</span>;
          <span class="kw">break</span>;
      }
  }
  <span class="co">// It also knows that it's impossible to get here without reaching the break.</span>
  <span class="co">// And therefore that `x` must be initialized here!</span>
  <span class="pp">println!</span>(<span class="st">&quot;{}&quot;</span>, x);</code></pre></div>
  <p>If a value is moved out of a variable, that variable becomes logically uninitialized if the type of the value isn’t Copy. That is:</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">fn</span> main() {
      <span class="kw">let</span> x = <span class="dv">0</span>;
      <span class="kw">let</span> y = <span class="dt">Box</span>::new(<span class="dv">0</span>);
      <span class="kw">let</span> z1 = x; <span class="co">// x is still valid because i32 is Copy</span>
      <span class="kw">let</span> z2 = y; <span class="co">// y is now logically uninitialized because Box isn't Copy</span>
  }</code></pre></div>
  <p>However reassigning <code>y</code> in this example <em>would</em> require <code>y</code> to be marked as mutable, as a Safe Rust program could observe that the value of <code>y</code> changed:</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">fn</span> main() {
      <span class="kw">let</span> <span class="kw">mut</span> y = <span class="dt">Box</span>::new(<span class="dv">0</span>);
      <span class="kw">let</span> z = y; <span class="co">// y is now logically uninitialized because Box isn't Copy</span>
      y = <span class="dt">Box</span>::new(<span class="dv">1</span>); <span class="co">// reinitialize y</span>
  }</code></pre></div>
  <p>Otherwise it’s like <code>y</code> is a brand new variable.</p>
  </section>
  <section id="sec--drop-flags" class="level2">
  <h2>Drop Flags</h2>
  <p>The examples in the previous section introduce an interesting problem for Rust. We have seen that it’s possible to conditionally initialize, deinitialize, and reinitialize locations of memory totally safely. For Copy types, this isn’t particularly notable since they’re just a random pile of bits. However types with destructors are a different story: Rust needs to know whether to call a destructor whenever a variable is assigned to, or a variable goes out of scope. How can it do this with conditional initialization?</p>
  <p>Note that this is not a problem that all assignments need worry about. In particular, assigning through a dereference unconditionally drops, and assigning in a <code>let</code> unconditionally doesn’t drop:</p>
  <pre><code>let mut x = Box::new(0); // let makes a fresh variable, so never need to drop
  let y = &amp;mut x;
  *y = Box::new(1); // Deref assumes the referent is initialized, so always drops</code></pre>
  <p>This is only a problem when overwriting a previously initialized variable or one of its subfields.</p>
  <p>It turns out that Rust actually tracks whether a type should be dropped or not <em>at runtime</em>. As a variable becomes initialized and uninitialized, a <em>drop flag</em> for that variable is toggled. When a variable might need to be dropped, this flag is evaluated to determine if it should be dropped.</p>
  <p>Of course, it is often the case that a value’s initialization state can be statically known at every point in the program. If this is the case, then the compiler can theoretically generate more efficient code! For instance, straight- line code has such <em>static drop semantics</em>:</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">let</span> <span class="kw">mut</span> x = <span class="dt">Box</span>::new(<span class="dv">0</span>); <span class="co">// x was uninit; just overwrite.</span>
  <span class="kw">let</span> <span class="kw">mut</span> y = x;           <span class="co">// y was uninit; just overwrite and make x uninit.</span>
  x = <span class="dt">Box</span>::new(<span class="dv">0</span>);         <span class="co">// x was uninit; just overwrite.</span>
  y = x;                   <span class="co">// y was init; Drop y, overwrite it, and make x uninit!</span>
                           <span class="co">// y goes out of scope; y was init; Drop y!</span>
                           <span class="co">// x goes out of scope; x was uninit; do nothing.</span></code></pre></div>
  <p>Similarly, branched code where all branches have the same behavior with respect to initialization has static drop semantics:</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">let</span> <span class="kw">mut</span> x = <span class="dt">Box</span>::new(<span class="dv">0</span>);    <span class="co">// x was uninit; just overwrite.</span>
  <span class="kw">if</span> condition {
      drop(x)                 <span class="co">// x gets moved out; make x uninit.</span>
  } <span class="kw">else</span> {
      <span class="pp">println!</span>(<span class="st">&quot;{}&quot;</span>, x);
      drop(x)                 <span class="co">// x gets moved out; make x uninit.</span>
  }
  x = <span class="dt">Box</span>::new(<span class="dv">0</span>);            <span class="co">// x was uninit; just overwrite.</span>
                              <span class="co">// x goes out of scope; x was init; Drop x!</span></code></pre></div>
  <p>However code like this <em>requires</em> runtime information to correctly Drop:</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">let</span> x;
  <span class="kw">if</span> condition {
      x = <span class="dt">Box</span>::new(<span class="dv">0</span>);        <span class="co">// x was uninit; just overwrite.</span>
      <span class="pp">println!</span>(<span class="st">&quot;{}&quot;</span>, x);
  }
                              <span class="co">// x goes out of scope; x might be uninit;</span>
                              <span class="co">// check the flag!</span></code></pre></div>
  <p>Of course, in this case it’s trivial to retrieve static drop semantics:</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">if</span> condition {
      <span class="kw">let</span> x = <span class="dt">Box</span>::new(<span class="dv">0</span>);
      <span class="pp">println!</span>(<span class="st">&quot;{}&quot;</span>, x);
  }</code></pre></div>
  <p>As of Rust 1.0, the drop flags are actually not-so-secretly stashed in a hidden field of any type that implements Drop. Rust sets the drop flag by overwriting the entire value with a particular bit pattern. This is pretty obviously Not The Fastest and causes a bunch of trouble with optimizing code. It’s legacy from a time when you could do much more complex conditional initialization.</p>
  <p>As such work is currently under way to move the flags out onto the stack frame where they more reasonably belong. Unfortunately, this work will take some time as it requires fairly substantial changes to the compiler.</p>
  <p>Regardless, Rust programs don’t need to worry about uninitialized values on the stack for correctness. Although they might care for performance. Thankfully, Rust makes it easy to take control here! Uninitialized values are there, and you can work with them in Safe Rust, but you’re never in danger.</p>
  </section>
  <section id="sec--unchecked-uninit" class="level2">
  <h2>Unchecked</h2>
  <p>One interesting exception to this rule is working with arrays. Safe Rust doesn’t permit you to partially initialize an array. When you initialize an array, you can either set every value to the same thing with <code>let x = [val; N]</code>, or you can specify each member individually with <code>let x = [val1, val2, val3]</code>. Unfortunately this is pretty rigid, especially if you need to initialize your array in a more incremental or dynamic way.</p>
  <p>Unsafe Rust gives us a powerful tool to handle this problem: <code>mem::uninitialized</code>. This function pretends to return a value when really it does nothing at all. Using it, we can convince Rust that we have initialized a variable, allowing us to do trickier things with conditional and incremental initialization.</p>
  <p>Unfortunately, this opens us up to all kinds of problems. Assignment has a different meaning to Rust based on whether it believes that a variable is initialized or not. If it’s believed uninitialized, then Rust will semantically just memcopy the bits over the uninitialized ones, and do nothing else. However if Rust believes a value to be initialized, it will try to <code>Drop</code> the old value! Since we’ve tricked Rust into believing that the value is initialized, we can no longer safely use normal assignment.</p>
  <p>This is also a problem if you’re working with a raw system allocator, which returns a pointer to uninitialized memory.</p>
  <p>To handle this, we must use the <code>ptr</code> module. In particular, it provides three functions that allow us to assign bytes to a location in memory without dropping the old value: <code>write</code>, <code>copy</code>, and <code>copy_nonoverlapping</code>.</p>
  <ul>
  <li><code>ptr::write(ptr, val)</code> takes a <code>val</code> and moves it into the address pointed to by <code>ptr</code>.</li>
  <li><code>ptr::copy(src, dest, count)</code> copies the bits that <code>count</code> T’s would occupy from src to dest. (this is equivalent to memmove – note that the argument order is reversed!)</li>
  <li><code>ptr::copy_nonoverlapping(src, dest, count)</code> does what <code>copy</code> does, but a little faster on the assumption that the two ranges of memory don’t overlap. (this is equivalent to memcpy – note that the argument order is reversed!)</li>
  </ul>
  <p>It should go without saying that these functions, if misused, will cause serious havoc or just straight up Undefined Behavior. The only things that these functions <em>themselves</em> require is that the locations you want to read and write are allocated. However the ways writing arbitrary bits to arbitrary locations of memory can break things are basically uncountable!</p>
  <p>Putting this all together, we get the following:</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">use</span> std::mem;
  <span class="kw">use</span> std::ptr;
  
  <span class="co">// size of the array is hard-coded but easy to change. This means we can't</span>
  <span class="co">// use [a, b, c] syntax to initialize the array, though!</span>
  <span class="kw">const</span> SIZE: <span class="dt">usize</span> = <span class="dv">10</span>;
  
  <span class="kw">let</span> <span class="kw">mut</span> x: [<span class="dt">Box</span>&lt;<span class="dt">u32</span>&gt;; SIZE];
  
  <span class="kw">unsafe</span> {
      <span class="co">// convince Rust that x is Totally Initialized</span>
      x = mem::uninitialized();
      <span class="kw">for</span> i <span class="kw">in</span> <span class="dv">0.</span>.SIZE {
          <span class="co">// very carefully overwrite each index without reading it</span>
          <span class="co">// NOTE: exception safety is not a concern; Box can't panic</span>
          ptr::write(&amp;<span class="kw">mut</span> x[i], <span class="dt">Box</span>::new(i <span class="kw">as</span> <span class="dt">u32</span>));
      }
  }
  
  <span class="pp">println!</span>(<span class="st">&quot;{:?}&quot;</span>, x);</code></pre></div>
  <p>It’s worth noting that you don’t need to worry about <code>ptr::write</code>-style shenanigans with types which don’t implement <code>Drop</code> or contain <code>Drop</code> types, because Rust knows not to try to drop them. Similarly you should be able to assign to fields of partially initialized structs directly if those fields don’t contain any <code>Drop</code> types.</p>
  <p>However when working with uninitialized memory you need to be ever-vigilant for Rust trying to drop values you make like this before they’re fully initialized. Every control path through that variable’s scope must initialize the value before it ends, if it has a destructor. <em><a href="#sec--unwinding">This includes code panicking</a></em>.</p>
  <p>And that’s about it for working with uninitialized memory! Basically nothing anywhere expects to be handed uninitialized memory, so if you’re going to pass it around at all, be sure to be <em>really</em> careful.</p>
  </section>
  </section>
  <section id="sec--obrm" class="level1">
  <h1>Ownership Based Resource Management</h1>
  <p>OBRM (AKA RAII: Resource Acquisition Is Initialization) is something you’ll interact with a lot in Rust. Especially if you use the standard library.</p>
  <p>Roughly speaking the pattern is as follows: to acquire a resource, you create an object that manages it. To release the resource, you simply destroy the object, and it cleans up the resource for you. The most common “resource” this pattern manages is simply <em>memory</em>. <code>Box</code>, <code>Rc</code>, and basically everything in <code>std::collections</code> is a convenience to enable correctly managing memory. This is particularly important in Rust because we have no pervasive GC to rely on for memory management. Which is the point, really: Rust is about control. However we are not limited to just memory. Pretty much every other system resource like a thread, file, or socket is exposed through this kind of API.</p>
  <section id="sec--constructors" class="level2">
  <h2>Constructors</h2>
  <p>There is exactly one way to create an instance of a user-defined type: name it, and initialize all its fields at once:</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">struct</span> Foo {
      a: <span class="dt">u8</span>,
      b: <span class="dt">u32</span>,
      c: <span class="dt">bool</span>,
  }
  
  <span class="kw">enum</span> Bar {
      X(<span class="dt">u32</span>),
      Y(<span class="dt">bool</span>),
  }
  
  <span class="kw">struct</span> Unit;
  
  <span class="kw">let</span> foo = Foo { a: <span class="dv">0</span>, b: <span class="dv">1</span>, c: <span class="cn">false</span> };
  <span class="kw">let</span> bar = Bar::X(<span class="dv">0</span>);
  <span class="kw">let</span> empty = Unit;</code></pre></div>
  <p>That’s it. Every other way you make an instance of a type is just calling a totally vanilla function that does some stuff and eventually bottoms out to The One True Constructor.</p>
  <p>Unlike C++, Rust does not come with a slew of built-in kinds of constructor. There are no Copy, Default, Assignment, Move, or whatever constructors. The reasons for this are varied, but it largely boils down to Rust’s philosophy of <em>being explicit</em>.</p>
  <p>Move constructors are meaningless in Rust because we don’t enable types to “care” about their location in memory. Every type must be ready for it to be blindly memcopied to somewhere else in memory. This means pure on-the-stack-but- still-movable intrusive linked lists are simply not happening in Rust (safely).</p>
  <p>Assignment and copy constructors similarly don’t exist because move semantics are the only semantics in Rust. At most <code>x = y</code> just moves the bits of y into the x variable. Rust does provide two facilities for providing C++’s copy- oriented semantics: <code>Copy</code> and <code>Clone</code>. Clone is our moral equivalent of a copy constructor, but it’s never implicitly invoked. You have to explicitly call <code>clone</code> on an element you want to be cloned. Copy is a special case of Clone where the implementation is just “copy the bits”. Copy types <em>are</em> implicitly cloned whenever they’re moved, but because of the definition of Copy this just means not treating the old copy as uninitialized – a no-op.</p>
  <p>While Rust provides a <code>Default</code> trait for specifying the moral equivalent of a default constructor, it’s incredibly rare for this trait to be used. This is because variables <a href="#sec--uninitialized">aren’t implicitly initialized</a>. Default is basically only useful for generic programming. In concrete contexts, a type will provide a static <code>new</code> method for any kind of “default” constructor. This has no relation to <code>new</code> in other languages and has no special meaning. It’s just a naming convention.</p>
  <p>TODO: talk about “placement new”?</p>
  </section>
  <section id="sec--destructors" class="level2">
  <h2>Destructors</h2>
  <p>What the language <em>does</em> provide is full-blown automatic destructors through the <code>Drop</code> trait, which provides the following method:</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">fn</span> drop(&amp;<span class="kw">mut</span> <span class="kw">self</span>);</code></pre></div>
  <p>This method gives the type time to somehow finish what it was doing.</p>
  <p><strong>After <code>drop</code> is run, Rust will recursively try to drop all of the fields of <code>self</code>.</strong></p>
  <p>This is a convenience feature so that you don’t have to write “destructor boilerplate” to drop children. If a struct has no special logic for being dropped other than dropping its children, then it means <code>Drop</code> doesn’t need to be implemented at all!</p>
  <p><strong>There is no stable way to prevent this behavior in Rust 1.0.</strong></p>
  <p>Note that taking <code>&amp;mut self</code> means that even if you could suppress recursive Drop, Rust will prevent you from e.g. moving fields out of self. For most types, this is totally fine.</p>
  <p>For instance, a custom implementation of <code>Box</code> might write <code>Drop</code> like this:</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="at">#![</span>feature<span class="at">(</span>alloc<span class="at">,</span> heap_api<span class="at">,</span> drop_in_place<span class="at">,</span> unique<span class="at">)]</span>
  
  <span class="kw">extern</span> <span class="kw">crate</span> alloc;
  
  <span class="kw">use</span> std::ptr::{drop_in_place, Unique};
  <span class="kw">use</span> std::mem;
  
  <span class="kw">use</span> alloc::heap;
  
  <span class="kw">struct</span> <span class="dt">Box</span>&lt;T&gt;{ ptr: Unique&lt;T&gt; }
  
  <span class="kw">impl</span>&lt;T&gt; <span class="bu">Drop</span> <span class="kw">for</span> <span class="dt">Box</span>&lt;T&gt; {
      <span class="kw">fn</span> drop(&amp;<span class="kw">mut</span> <span class="kw">self</span>) {
          <span class="kw">unsafe</span> {
              drop_in_place(*<span class="kw">self</span>.ptr);
              heap::deallocate((*<span class="kw">self</span>.ptr) <span class="kw">as</span> *<span class="kw">mut</span> <span class="dt">u8</span>,
                               mem::size_of::&lt;T&gt;(),
                               mem::align_of::&lt;T&gt;());
          }
      }
  }</code></pre></div>
  <p>and this works fine because when Rust goes to drop the <code>ptr</code> field it just sees a [Unique] that has no actual <code>Drop</code> implementation. Similarly nothing can use-after-free the <code>ptr</code> because when drop exits, it becomes inaccessible.</p>
  <p>However this wouldn’t work:</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="at">#![</span>feature<span class="at">(</span>alloc<span class="at">,</span> heap_api<span class="at">,</span> drop_in_place<span class="at">,</span> unique<span class="at">)]</span>
  
  <span class="kw">extern</span> <span class="kw">crate</span> alloc;
  
  <span class="kw">use</span> std::ptr::{drop_in_place, Unique};
  <span class="kw">use</span> std::mem;
  
  <span class="kw">use</span> alloc::heap;
  
  <span class="kw">struct</span> <span class="dt">Box</span>&lt;T&gt;{ ptr: Unique&lt;T&gt; }
  
  <span class="kw">impl</span>&lt;T&gt; <span class="bu">Drop</span> <span class="kw">for</span> <span class="dt">Box</span>&lt;T&gt; {
      <span class="kw">fn</span> drop(&amp;<span class="kw">mut</span> <span class="kw">self</span>) {
          <span class="kw">unsafe</span> {
              drop_in_place(*<span class="kw">self</span>.ptr);
              heap::deallocate((*<span class="kw">self</span>.ptr) <span class="kw">as</span> *<span class="kw">mut</span> <span class="dt">u8</span>,
                               mem::size_of::&lt;T&gt;(),
                               mem::align_of::&lt;T&gt;());
          }
      }
  }
  
  <span class="kw">struct</span> SuperBox&lt;T&gt; { my_box: <span class="dt">Box</span>&lt;T&gt; }
  
  <span class="kw">impl</span>&lt;T&gt; <span class="bu">Drop</span> <span class="kw">for</span> SuperBox&lt;T&gt; {
      <span class="kw">fn</span> drop(&amp;<span class="kw">mut</span> <span class="kw">self</span>) {
          <span class="kw">unsafe</span> {
              <span class="co">// Hyper-optimized: deallocate the box's contents for it</span>
              <span class="co">// without `drop`ing the contents</span>
              heap::deallocate((*<span class="kw">self</span>.my_box.ptr) <span class="kw">as</span> *<span class="kw">mut</span> <span class="dt">u8</span>,
                               mem::size_of::&lt;T&gt;(),
                               mem::align_of::&lt;T&gt;());
          }
      }
  }</code></pre></div>
  <p>After we deallocate the <code>box</code>’s ptr in SuperBox’s destructor, Rust will happily proceed to tell the box to Drop itself and everything will blow up with use-after-frees and double-frees.</p>
  <p>Note that the recursive drop behavior applies to all structs and enums regardless of whether they implement Drop. Therefore something like</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">struct</span> Boxy&lt;T&gt; {
      data1: <span class="dt">Box</span>&lt;T&gt;,
      data2: <span class="dt">Box</span>&lt;T&gt;,
      info: <span class="dt">u32</span>,
  }</code></pre></div>
  <p>will have its data1 and data2’s fields destructors whenever it “would” be dropped, even though it itself doesn’t implement Drop. We say that such a type <em>needs Drop</em>, even though it is not itself Drop.</p>
  <p>Similarly,</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">enum</span> Link {
      Next(<span class="dt">Box</span>&lt;Link&gt;),
      <span class="cn">None</span>,
  }</code></pre></div>
  <p>will have its inner Box field dropped if and only if an instance stores the Next variant.</p>
  <p>In general this works really nicely because you don’t need to worry about adding/removing drops when you refactor your data layout. Still there’s certainly many valid usecases for needing to do trickier things with destructors.</p>
  <p>The classic safe solution to overriding recursive drop and allowing moving out of Self during <code>drop</code> is to use an Option:</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="at">#![</span>feature<span class="at">(</span>alloc<span class="at">,</span> heap_api<span class="at">,</span> drop_in_place<span class="at">,</span> unique<span class="at">)]</span>
  
  <span class="kw">extern</span> <span class="kw">crate</span> alloc;
  
  <span class="kw">use</span> std::ptr::{drop_in_place, Unique};
  <span class="kw">use</span> std::mem;
  
  <span class="kw">use</span> alloc::heap;
  
  <span class="kw">struct</span> <span class="dt">Box</span>&lt;T&gt;{ ptr: Unique&lt;T&gt; }
  
  <span class="kw">impl</span>&lt;T&gt; <span class="bu">Drop</span> <span class="kw">for</span> <span class="dt">Box</span>&lt;T&gt; {
      <span class="kw">fn</span> drop(&amp;<span class="kw">mut</span> <span class="kw">self</span>) {
          <span class="kw">unsafe</span> {
              drop_in_place(*<span class="kw">self</span>.ptr);
              heap::deallocate((*<span class="kw">self</span>.ptr) <span class="kw">as</span> *<span class="kw">mut</span> <span class="dt">u8</span>,
                               mem::size_of::&lt;T&gt;(),
                               mem::align_of::&lt;T&gt;());
          }
      }
  }
  
  <span class="kw">struct</span> SuperBox&lt;T&gt; { my_box: <span class="dt">Option</span>&lt;<span class="dt">Box</span>&lt;T&gt;&gt; }
  
  <span class="kw">impl</span>&lt;T&gt; <span class="bu">Drop</span> <span class="kw">for</span> SuperBox&lt;T&gt; {
      <span class="kw">fn</span> drop(&amp;<span class="kw">mut</span> <span class="kw">self</span>) {
          <span class="kw">unsafe</span> {
              <span class="co">// Hyper-optimized: deallocate the box's contents for it</span>
              <span class="co">// without `drop`ing the contents. Need to set the `box`</span>
              <span class="co">// field as `None` to prevent Rust from trying to Drop it.</span>
              <span class="kw">let</span> my_box = <span class="kw">self</span>.my_box.take().unwrap();
              heap::deallocate((*my_box.ptr) <span class="kw">as</span> *<span class="kw">mut</span> <span class="dt">u8</span>,
                               mem::size_of::&lt;T&gt;(),
                               mem::align_of::&lt;T&gt;());
              mem::forget(my_box);
          }
      }
  }</code></pre></div>
  <p>However this has fairly odd semantics: you’re saying that a field that <em>should</em> always be Some <em>may</em> be None, just because that happens in the destructor. Of course this conversely makes a lot of sense: you can call arbitrary methods on self during the destructor, and this should prevent you from ever doing so after deinitializing the field. Not that it will prevent you from producing any other arbitrarily invalid state in there.</p>
  <p>On balance this is an ok choice. Certainly what you should reach for by default. However, in the future we expect there to be a first-class way to announce that a field shouldn’t be automatically dropped.</p>
  </section>
  <section id="sec--leaking" class="level2">
  <h2>Leaking</h2>
  <p>Ownership-based resource management is intended to simplify composition. You acquire resources when you create the object, and you release the resources when it gets destroyed. Since destruction is handled for you, it means you can’t forget to release the resources, and it happens as soon as possible! Surely this is perfect and all of our problems are solved.</p>
  <p>Everything is terrible and we have new and exotic problems to try to solve.</p>
  <p>Many people like to believe that Rust eliminates resource leaks. In practice, this is basically true. You would be surprised to see a Safe Rust program leak resources in an uncontrolled way.</p>
  <p>However from a theoretical perspective this is absolutely not the case, no matter how you look at it. In the strictest sense, “leaking” is so abstract as to be unpreventable. It’s quite trivial to initialize a collection at the start of a program, fill it with tons of objects with destructors, and then enter an infinite event loop that never refers to it. The collection will sit around uselessly, holding on to its precious resources until the program terminates (at which point all those resources would have been reclaimed by the OS anyway).</p>
  <p>We may consider a more restricted form of leak: failing to drop a value that is unreachable. Rust also doesn’t prevent this. In fact Rust <em>has a function for doing this</em>: <code>mem::forget</code>. This function consumes the value it is passed <em>and then doesn’t run its destructor</em>.</p>
  <p>In the past <code>mem::forget</code> was marked as unsafe as a sort of lint against using it, since failing to call a destructor is generally not a well-behaved thing to do (though useful for some special unsafe code). However this was generally determined to be an untenable stance to take: there are many ways to fail to call a destructor in safe code. The most famous example is creating a cycle of reference-counted pointers using interior mutability.</p>
  <p>It is reasonable for safe code to assume that destructor leaks do not happen, as any program that leaks destructors is probably wrong. However <em>unsafe</em> code cannot rely on destructors to be run in order to be safe. For most types this doesn’t matter: if you leak the destructor then the type is by definition inaccessible, so it doesn’t matter, right? For instance, if you leak a <code>Box&lt;u8&gt;</code> then you waste some memory but that’s hardly going to violate memory-safety.</p>
  <p>However where we must be careful with destructor leaks are <em>proxy</em> types. These are types which manage access to a distinct object, but don’t actually own it. Proxy objects are quite rare. Proxy objects you’ll need to care about are even rarer. However we’ll focus on three interesting examples in the standard library:</p>
  <ul>
  <li><code>vec::Drain</code></li>
  <li><code>Rc</code></li>
  <li><code>thread::scoped::JoinGuard</code></li>
  </ul>
  <section id="drain" class="level4">
  <h4>Drain</h4>
  <p><code>drain</code> is a collections API that moves data out of the container without consuming the container. This enables us to reuse the allocation of a <code>Vec</code> after claiming ownership over all of its contents. It produces an iterator (Drain) that returns the contents of the Vec by-value.</p>
  <p>Now, consider Drain in the middle of iteration: some values have been moved out, and others haven’t. This means that part of the Vec is now full of logically uninitialized data! We could backshift all the elements in the Vec every time we remove a value, but this would have pretty catastrophic performance consequences.</p>
  <p>Instead, we would like Drain to fix the Vec’s backing storage when it is dropped. It should run itself to completion, backshift any elements that weren’t removed (drain supports subranges), and then fix Vec’s <code>len</code>. It’s even unwinding-safe! Easy!</p>
  <p>Now consider the following:</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">let</span> <span class="kw">mut</span> vec = <span class="pp">vec!</span>[<span class="dt">Box</span>::new(<span class="dv">0</span>); <span class="dv">4</span>];
  
  {
      <span class="co">// start draining, vec can no longer be accessed</span>
      <span class="kw">let</span> <span class="kw">mut</span> drainer = vec.drain(..);
  
      <span class="co">// pull out two elements and immediately drop them</span>
      drainer.next();
      drainer.next();
  
      <span class="co">// get rid of drainer, but don't call its destructor</span>
      mem::forget(drainer);
  }
  
  <span class="co">// Oops, vec[0] was dropped, we're reading a pointer into free'd memory!</span>
  <span class="pp">println!</span>(<span class="st">&quot;{}&quot;</span>, vec[<span class="dv">0</span>]);</code></pre></div>
  <p>This is pretty clearly Not Good. Unfortunately, we’re kind of stuck between a rock and a hard place: maintaining consistent state at every step has an enormous cost (and would negate any benefits of the API). Failing to maintain consistent state gives us Undefined Behavior in safe code (making the API unsound).</p>
  <p>So what can we do? Well, we can pick a trivially consistent state: set the Vec’s len to be 0 when we start the iteration, and fix it up if necessary in the destructor. That way, if everything executes like normal we get the desired behavior with minimal overhead. But if someone has the <em>audacity</em> to mem::forget us in the middle of the iteration, all that does is <em>leak even more</em> (and possibly leave the Vec in an unexpected but otherwise consistent state). Since we’ve accepted that mem::forget is safe, this is definitely safe. We call leaks causing more leaks a <em>leak amplification</em>.</p>
  </section>
  <section id="rc" class="level4">
  <h4>Rc</h4>
  <p>Rc is an interesting case because at first glance it doesn’t appear to be a proxy value at all. After all, it manages the data it points to, and dropping all the Rcs for a value will drop that value. Leaking an Rc doesn’t seem like it would be particularly dangerous. It will leave the refcount permanently incremented and prevent the data from being freed or dropped, but that seems just like Box, right?</p>
  <p>Nope.</p>
  <p>Let’s consider a simplified implementation of Rc:</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">struct</span> Rc&lt;T&gt; {
      ptr: *<span class="kw">mut</span> RcBox&lt;T&gt;,
  }
  
  <span class="kw">struct</span> RcBox&lt;T&gt; {
      data: T,
      ref_count: <span class="dt">usize</span>,
  }
  
  <span class="kw">impl</span>&lt;T&gt; Rc&lt;T&gt; {
      <span class="kw">fn</span> new(data: T) -&gt; <span class="kw">Self</span> {
          <span class="kw">unsafe</span> {
              <span class="co">// Wouldn't it be nice if heap::allocate worked like this?</span>
              <span class="kw">let</span> ptr = heap::allocate::&lt;RcBox&lt;T&gt;&gt;();
              ptr::write(ptr, RcBox {
                  data: data,
                  ref_count: <span class="dv">1</span>,
              });
              Rc { ptr: ptr }
          }
      }
  
      <span class="kw">fn</span> clone(&amp;<span class="kw">self</span>) -&gt; <span class="kw">Self</span> {
          <span class="kw">unsafe</span> {
              (*<span class="kw">self</span>.ptr).ref_count += <span class="dv">1</span>;
          }
          Rc { ptr: <span class="kw">self</span>.ptr }
      }
  }
  
  <span class="kw">impl</span>&lt;T&gt; <span class="bu">Drop</span> <span class="kw">for</span> Rc&lt;T&gt; {
      <span class="kw">fn</span> drop(&amp;<span class="kw">mut</span> <span class="kw">self</span>) {
          <span class="kw">unsafe</span> {
              (*<span class="kw">self</span>.ptr).ref_count -= <span class="dv">1</span>;
              <span class="kw">if</span> (*<span class="kw">self</span>.ptr).ref_count == <span class="dv">0</span> {
                  <span class="co">// drop the data and then free it</span>
                  ptr::read(<span class="kw">self</span>.ptr);
                  heap::deallocate(<span class="kw">self</span>.ptr);
              }
          }
      }
  }</code></pre></div>
  <p>This code contains an implicit and subtle assumption: <code>ref_count</code> can fit in a <code>usize</code>, because there can’t be more than <code>usize::MAX</code> Rcs in memory. However this itself assumes that the <code>ref_count</code> accurately reflects the number of Rcs in memory, which we know is false with <code>mem::forget</code>. Using <code>mem::forget</code> we can overflow the <code>ref_count</code>, and then get it down to 0 with outstanding Rcs. Then we can happily use-after-free the inner data. Bad Bad Not Good.</p>
  <p>This can be solved by just checking the <code>ref_count</code> and doing <em>something</em>. The standard library’s stance is to just abort, because your program has become horribly degenerate. Also <em>oh my gosh</em> it’s such a ridiculous corner case.</p>
  </section>
  <section id="threadscopedjoinguard" class="level4">
  <h4>thread::scoped::JoinGuard</h4>
  <p>The thread::scoped API intends to allow threads to be spawned that reference data on their parent’s stack without any synchronization over that data by ensuring the parent joins the thread before any of the shared data goes out of scope.</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">pub</span> <span class="kw">fn</span> scoped&lt;<span class="ot">'a</span>, F&gt;(f: F) -&gt; JoinGuard&lt;<span class="ot">'a</span>&gt;
      <span class="kw">where</span> F: <span class="bu">FnOnce</span>() + <span class="bu">Send</span> + <span class="ot">'a</span></code></pre></div>
  <p>Here <code>f</code> is some closure for the other thread to execute. Saying that <code>F: Send +'a</code> is saying that it closes over data that lives for <code>'a</code>, and it either owns that data or the data was Sync (implying <code>&amp;data</code> is Send).</p>
  <p>Because JoinGuard has a lifetime, it keeps all the data it closes over borrowed in the parent thread. This means the JoinGuard can’t outlive the data that the other thread is working on. When the JoinGuard <em>does</em> get dropped it blocks the parent thread, ensuring the child terminates before any of the closed-over data goes out of scope in the parent.</p>
  <p>Usage looked like:</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">let</span> <span class="kw">mut</span> data = [<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">5</span>, <span class="dv">6</span>, <span class="dv">7</span>, <span class="dv">8</span>, <span class="dv">9</span>, <span class="dv">10</span>];
  {
      <span class="kw">let</span> guards = <span class="pp">vec!</span>[];
      <span class="kw">for</span> x <span class="kw">in</span> &amp;<span class="kw">mut</span> data {
          <span class="co">// Move the mutable reference into the closure, and execute</span>
          <span class="co">// it on a different thread. The closure has a lifetime bound</span>
          <span class="co">// by the lifetime of the mutable reference `x` we store in it.</span>
          <span class="co">// The guard that is returned is in turn assigned the lifetime</span>
          <span class="co">// of the closure, so it also mutably borrows `data` as `x` did.</span>
          <span class="co">// This means we cannot access `data` until the guard goes away.</span>
          <span class="kw">let</span> guard = thread::scoped(<span class="kw">move</span> || {
              *x *= <span class="dv">2</span>;
          });
          <span class="co">// store the thread's guard for later</span>
          guards.push(guard);
      }
      <span class="co">// All guards are dropped here, forcing the threads to join</span>
      <span class="co">// (this thread blocks here until the others terminate).</span>
      <span class="co">// Once the threads join, the borrow expires and the data becomes</span>
      <span class="co">// accessible again in this thread.</span>
  }
  <span class="co">// data is definitely mutated here.</span></code></pre></div>
  <p>In principle, this totally works! Rust’s ownership system perfectly ensures it! …except it relies on a destructor being called to be safe.</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">let</span> <span class="kw">mut</span> data = <span class="dt">Box</span>::new(<span class="dv">0</span>);
  {
      <span class="kw">let</span> guard = thread::scoped(|| {
          <span class="co">// This is at best a data race. At worst, it's also a use-after-free.</span>
          *data += <span class="dv">1</span>;
      });
      <span class="co">// Because the guard is forgotten, expiring the loan without blocking this</span>
      <span class="co">// thread.</span>
      mem::forget(guard);
  }
  <span class="co">// So the Box is dropped here while the scoped thread may or may not be trying</span>
  <span class="co">// to access it.</span></code></pre></div>
  <p>Dang. Here the destructor running was pretty fundamental to the API, and it had to be scrapped in favor of a completely different design.</p>
  </section>
  </section>
  </section>
  <section id="sec--unwinding" class="level1">
  <h1>Unwinding</h1>
  <p>Rust has a <em>tiered</em> error-handling scheme:</p>
  <ul>
  <li>If something might reasonably be absent, Option is used.</li>
  <li>If something goes wrong and can reasonably be handled, Result is used.</li>
  <li>If something goes wrong and cannot reasonably be handled, the thread panics.</li>
  <li>If something catastrophic happens, the program aborts.</li>
  </ul>
  <p>Option and Result are overwhelmingly preferred in most situations, especially since they can be promoted into a panic or abort at the API user’s discretion. Panics cause the thread to halt normal execution and unwind its stack, calling destructors as if every function instantly returned.</p>
  <p>As of 1.0, Rust is of two minds when it comes to panics. In the long-long-ago, Rust was much more like Erlang. Like Erlang, Rust had lightweight tasks, and tasks were intended to kill themselves with a panic when they reached an untenable state. Unlike an exception in Java or C++, a panic could not be caught at any time. Panics could only be caught by the owner of the task, at which point they had to be handled or <em>that</em> task would itself panic.</p>
  <p>Unwinding was important to this story because if a task’s destructors weren’t called, it would cause memory and other system resources to leak. Since tasks were expected to die during normal execution, this would make Rust very poor for long-running systems!</p>
  <p>As the Rust we know today came to be, this style of programming grew out of fashion in the push for less-and-less abstraction. Light-weight tasks were killed in the name of heavy-weight OS threads. Still, on stable Rust as of 1.0 panics can only be caught by the parent thread. This means catching a panic requires spinning up an entire OS thread! This unfortunately stands in conflict to Rust’s philosophy of zero-cost abstractions.</p>
  <p>There is an unstable API called <code>catch_panic</code> that enables catching a panic without spawning a thread. Still, we would encourage you to only do this sparingly. In particular, Rust’s current unwinding implementation is heavily optimized for the “doesn’t unwind” case. If a program doesn’t unwind, there should be no runtime cost for the program being <em>ready</em> to unwind. As a consequence, actually unwinding will be more expensive than in e.g. Java. Don’t build your programs to unwind under normal circumstances. Ideally, you should only panic for programming errors or <em>extreme</em> problems.</p>
  <p>Rust’s unwinding strategy is not specified to be fundamentally compatible with any other language’s unwinding. As such, unwinding into Rust from another language, or unwinding into another language from Rust is Undefined Behavior. You must <em>absolutely</em> catch any panics at the FFI boundary! What you do at that point is up to you, but <em>something</em> must be done. If you fail to do this, at best, your application will crash and burn. At worst, your application <em>won’t</em> crash and burn, and will proceed with completely clobbered state.</p>
  <section id="sec--exception-safety" class="level2">
  <h2>Exception Safety</h2>
  <p>Although programs should use unwinding sparingly, there’s a lot of code that <em>can</em> panic. If you unwrap a None, index out of bounds, or divide by 0, your program will panic. On debug builds, every arithmetic operation can panic if it overflows. Unless you are very careful and tightly control what code runs, pretty much everything can unwind, and you need to be ready for it.</p>
  <p>Being ready for unwinding is often referred to as <em>exception safety</em> in the broader programming world. In Rust, there are two levels of exception safety that one may concern themselves with:</p>
  <ul>
  <li><p>In unsafe code, we <em>must</em> be exception safe to the point of not violating memory safety. We’ll call this <em>minimal</em> exception safety.</p></li>
  <li><p>In safe code, it is <em>good</em> to be exception safe to the point of your program doing the right thing. We’ll call this <em>maximal</em> exception safety.</p></li>
  </ul>
  <p>As is the case in many places in Rust, Unsafe code must be ready to deal with bad Safe code when it comes to unwinding. Code that transiently creates unsound states must be careful that a panic does not cause that state to be used. Generally this means ensuring that only non-panicking code is run while these states exist, or making a guard that cleans up the state in the case of a panic. This does not necessarily mean that the state a panic witnesses is a fully coherent state. We need only guarantee that it’s a <em>safe</em> state.</p>
  <p>Most Unsafe code is leaf-like, and therefore fairly easy to make exception-safe. It controls all the code that runs, and most of that code can’t panic. However it is not uncommon for Unsafe code to work with arrays of temporarily uninitialized data while repeatedly invoking caller-provided code. Such code needs to be careful and consider exception safety.</p>
  <section id="vecpush_all" class="level4">
  <h4>Vec::push_all</h4>
  <p><code>Vec::push_all</code> is a temporary hack to get extending a Vec by a slice reliably efficient without specialization. Here’s a simple implementation:</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">impl</span>&lt;T: <span class="bu">Clone</span>&gt; <span class="dt">Vec</span>&lt;T&gt; {
      <span class="kw">fn</span> push_all(&amp;<span class="kw">mut</span> <span class="kw">self</span>, to_push: &amp;[T]) {
          <span class="kw">self</span>.reserve(to_push.len());
          <span class="kw">unsafe</span> {
              <span class="co">// can't overflow because we just reserved this</span>
              <span class="kw">self</span>.set_len(<span class="kw">self</span>.len() + to_push.len());
  
              <span class="kw">for</span> (i, x) <span class="kw">in</span> to_push.iter().enumerate() {
                  <span class="kw">self</span>.ptr().offset(i <span class="kw">as</span> <span class="dt">isize</span>).write(x.clone());
              }
          }
      }
  }</code></pre></div>
  <p>We bypass <code>push</code> in order to avoid redundant capacity and <code>len</code> checks on the Vec that we definitely know has capacity. The logic is totally correct, except there’s a subtle problem with our code: it’s not exception-safe! <code>set_len</code>, <code>offset</code>, and <code>write</code> are all fine; <code>clone</code> is the panic bomb we over-looked.</p>
  <p>Clone is completely out of our control, and is totally free to panic. If it does, our function will exit early with the length of the Vec set too large. If the Vec is looked at or dropped, uninitialized memory will be read!</p>
  <p>The fix in this case is fairly simple. If we want to guarantee that the values we <em>did</em> clone are dropped, we can set the <code>len</code> every loop iteration. If we just want to guarantee that uninitialized memory can’t be observed, we can set the <code>len</code> after the loop.</p>
  </section>
  <section id="binaryheapsift_up" class="level4">
  <h4>BinaryHeap::sift_up</h4>
  <p>Bubbling an element up a heap is a bit more complicated than extending a Vec. The pseudocode is as follows:</p>
  <pre class="text"><code>bubble_up(heap, index):
      while index != 0 &amp;&amp; heap[index] &lt; heap[parent(index)]:
          heap.swap(index, parent(index))
          index = parent(index)
  </code></pre>
  <p>A literal transcription of this code to Rust is totally fine, but has an annoying performance characteristic: the <code>self</code> element is swapped over and over again uselessly. We would rather have the following:</p>
  <pre class="text"><code>bubble_up(heap, index):
      let elem = heap[index]
      while index != 0 &amp;&amp; element &lt; heap[parent(index)]:
          heap[index] = heap[parent(index)]
          index = parent(index)
      heap[index] = elem</code></pre>
  <p>This code ensures that each element is copied as little as possible (it is in fact necessary that elem be copied twice in general). However it now exposes some exception safety trouble! At all times, there exists two copies of one value. If we panic in this function something will be double-dropped. Unfortunately, we also don’t have full control of the code: that comparison is user-defined!</p>
  <p>Unlike Vec, the fix isn’t as easy here. One option is to break the user-defined code and the unsafe code into two separate phases:</p>
  <pre class="text"><code>bubble_up(heap, index):
      let end_index = index;
      while end_index != 0 &amp;&amp; heap[end_index] &lt; heap[parent(end_index)]:
          end_index = parent(end_index)
  
      let elem = heap[index]
      while index != end_index:
          heap[index] = heap[parent(index)]
          index = parent(index)
      heap[index] = elem</code></pre>
  <p>If the user-defined code blows up, that’s no problem anymore, because we haven’t actually touched the state of the heap yet. Once we do start messing with the heap, we’re working with only data and functions that we trust, so there’s no concern of panics.</p>
  <p>Perhaps you’re not happy with this design. Surely it’s cheating! And we have to do the complex heap traversal <em>twice</em>! Alright, let’s bite the bullet. Let’s intermix untrusted and unsafe code <em>for reals</em>.</p>
  <p>If Rust had <code>try</code> and <code>finally</code> like in Java, we could do the following:</p>
  <pre class="text"><code>bubble_up(heap, index):
      let elem = heap[index]
      try:
          while index != 0 &amp;&amp; element &lt; heap[parent(index)]:
              heap[index] = heap[parent(index)]
              index = parent(index)
      finally:
          heap[index] = elem</code></pre>
  <p>The basic idea is simple: if the comparison panics, we just toss the loose element in the logically uninitialized index and bail out. Anyone who observes the heap will see a potentially <em>inconsistent</em> heap, but at least it won’t cause any double-drops! If the algorithm terminates normally, then this operation happens to coincide precisely with the how we finish up regardless.</p>
  <p>Sadly, Rust has no such construct, so we’re going to need to roll our own! The way to do this is to store the algorithm’s state in a separate struct with a destructor for the “finally” logic. Whether we panic or not, that destructor will run and clean up after us.</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">struct</span> Hole&lt;<span class="ot">'a</span>, T: <span class="ot">'a</span>&gt; {
      data: &amp;<span class="ot">'a</span> <span class="kw">mut</span> [T],
      <span class="co">/// `elt` is always `Some` from new until drop.</span>
      elt: <span class="dt">Option</span>&lt;T&gt;,
      pos: <span class="dt">usize</span>,
  }
  
  <span class="kw">impl</span>&lt;<span class="ot">'a</span>, T&gt; Hole&lt;<span class="ot">'a</span>, T&gt; {
      <span class="kw">fn</span> new(data: &amp;<span class="ot">'a</span> <span class="kw">mut</span> [T], pos: <span class="dt">usize</span>) -&gt; <span class="kw">Self</span> {
          <span class="kw">unsafe</span> {
              <span class="kw">let</span> elt = ptr::read(&amp;data[pos]);
              Hole {
                  data: data,
                  elt: <span class="cn">Some</span>(elt),
                  pos: pos,
              }
          }
      }
  
      <span class="kw">fn</span> pos(&amp;<span class="kw">self</span>) -&gt; <span class="dt">usize</span> { <span class="kw">self</span>.pos }
  
      <span class="kw">fn</span> removed(&amp;<span class="kw">self</span>) -&gt; &amp;T { <span class="kw">self</span>.elt.as_ref().unwrap() }
  
      <span class="kw">unsafe</span> <span class="kw">fn</span> get(&amp;<span class="kw">self</span>, index: <span class="dt">usize</span>) -&gt; &amp;T { &amp;<span class="kw">self</span>.data[index] }
  
      <span class="kw">unsafe</span> <span class="kw">fn</span> move_to(&amp;<span class="kw">mut</span> <span class="kw">self</span>, index: <span class="dt">usize</span>) {
          <span class="kw">let</span> index_ptr: *<span class="kw">const</span> _ = &amp;<span class="kw">self</span>.data[index];
          <span class="kw">let</span> hole_ptr = &amp;<span class="kw">mut</span> <span class="kw">self</span>.data[<span class="kw">self</span>.pos];
          ptr::copy_nonoverlapping(index_ptr, hole_ptr, <span class="dv">1</span>);
          <span class="kw">self</span>.pos = index;
      }
  }
  
  <span class="kw">impl</span>&lt;<span class="ot">'a</span>, T&gt; <span class="bu">Drop</span> <span class="kw">for</span> Hole&lt;<span class="ot">'a</span>, T&gt; {
      <span class="kw">fn</span> drop(&amp;<span class="kw">mut</span> <span class="kw">self</span>) {
          <span class="co">// fill the hole again</span>
          <span class="kw">unsafe</span> {
              <span class="kw">let</span> pos = <span class="kw">self</span>.pos;
              ptr::write(&amp;<span class="kw">mut</span> <span class="kw">self</span>.data[pos], <span class="kw">self</span>.elt.take().unwrap());
          }
      }
  }
  
  <span class="kw">impl</span>&lt;T: <span class="bu">Ord</span>&gt; BinaryHeap&lt;T&gt; {
      <span class="kw">fn</span> sift_up(&amp;<span class="kw">mut</span> <span class="kw">self</span>, pos: <span class="dt">usize</span>) {
          <span class="kw">unsafe</span> {
              <span class="co">// Take out the value at `pos` and create a hole.</span>
              <span class="kw">let</span> <span class="kw">mut</span> hole = Hole::new(&amp;<span class="kw">mut</span> <span class="kw">self</span>.data, pos);
  
              <span class="kw">while</span> hole.pos() != <span class="dv">0</span> {
                  <span class="kw">let</span> parent = parent(hole.pos());
                  <span class="kw">if</span> hole.removed() &lt;= hole.get(parent) { <span class="kw">break</span> }
                  hole.move_to(parent);
              }
              <span class="co">// Hole will be unconditionally filled here; panic or not!</span>
          }
      }
  }</code></pre></div>
  </section>
  </section>
  <section id="sec--poisoning" class="level2">
  <h2>Poisoning</h2>
  <p>Although all unsafe code <em>must</em> ensure it has minimal exception safety, not all types ensure <em>maximal</em> exception safety. Even if the type does, your code may ascribe additional meaning to it. For instance, an integer is certainly exception-safe, but has no semantics on its own. It’s possible that code that panics could fail to correctly update the integer, producing an inconsistent program state.</p>
  <p>This is <em>usually</em> fine, because anything that witnesses an exception is about to get destroyed. For instance, if you send a Vec to another thread and that thread panics, it doesn’t matter if the Vec is in a weird state. It will be dropped and go away forever. However some types are especially good at smuggling values across the panic boundary.</p>
  <p>These types may choose to explicitly <em>poison</em> themselves if they witness a panic. Poisoning doesn’t entail anything in particular. Generally it just means preventing normal usage from proceeding. The most notable example of this is the standard library’s Mutex type. A Mutex will poison itself if one of its MutexGuards (the thing it returns when a lock is obtained) is dropped during a panic. Any future attempts to lock the Mutex will return an <code>Err</code> or panic.</p>
  <p>Mutex poisons not for true safety in the sense that Rust normally cares about. It poisons as a safety-guard against blindly using the data that comes out of a Mutex that has witnessed a panic while locked. The data in such a Mutex was likely in the middle of being modified, and as such may be in an inconsistent or incomplete state. It is important to note that one cannot violate memory safety with such a type if it is correctly written. After all, it must be minimally exception-safe!</p>
  <p>However if the Mutex contained, say, a BinaryHeap that does not actually have the heap property, it’s unlikely that any code that uses it will do what the author intended. As such, the program should not proceed normally. Still, if you’re double-plus-sure that you can do <em>something</em> with the value, the Mutex exposes a method to get the lock anyway. It <em>is</em> safe, after all. Just maybe nonsense.</p>
  </section>
  </section>
  <section id="sec--concurrency" class="level1">
  <h1>Concurrency</h1>
  <p>Rust as a language doesn’t <em>really</em> have an opinion on how to do concurrency or parallelism. The standard library exposes OS threads and blocking sys-calls because everyone has those, and they’re uniform enough that you can provide an abstraction over them in a relatively uncontroversial way. Message passing, green threads, and async APIs are all diverse enough that any abstraction over them tends to involve trade-offs that we weren’t willing to commit to for 1.0.</p>
  <p>However the way Rust models concurrency makes it relatively easy to design your own concurrency paradigm as a library and have everyone else’s code Just Work with yours. Just require the right lifetimes and Send and Sync where appropriate and you’re off to the races. Or rather, off to the… not… having… races.</p>
  <section id="sec--races" class="level2">
  <h2>Races</h2>
  <p>Safe Rust guarantees an absence of data races, which are defined as:</p>
  <ul>
  <li>two or more threads concurrently accessing a location of memory</li>
  <li>one of them is a write</li>
  <li>one of them is unsynchronized</li>
  </ul>
  <p>A data race has Undefined Behavior, and is therefore impossible to perform in Safe Rust. Data races are <em>mostly</em> prevented through rust’s ownership system: it’s impossible to alias a mutable reference, so it’s impossible to perform a data race. Interior mutability makes this more complicated, which is largely why we have the Send and Sync traits (see below).</p>
  <p><strong>However Rust does not prevent general race conditions.</strong></p>
  <p>This is pretty fundamentally impossible, and probably honestly undesirable. Your hardware is racy, your OS is racy, the other programs on your computer are racy, and the world this all runs in is racy. Any system that could genuinely claim to prevent <em>all</em> race conditions would be pretty awful to use, if not just incorrect.</p>
  <p>So it’s perfectly “fine” for a Safe Rust program to get deadlocked or do something incredibly stupid with incorrect synchronization. Obviously such a program isn’t very good, but Rust can only hold your hand so far. Still, a race condition can’t violate memory safety in a Rust program on its own. Only in conjunction with some other unsafe code can a race condition actually violate memory safety. For instance:</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">use</span> std::thread;
  <span class="kw">use</span> std::sync::atomic::{AtomicUsize, Ordering};
  <span class="kw">use</span> std::sync::Arc;
  
  <span class="kw">let</span> data = <span class="pp">vec!</span>[<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>];
  <span class="co">// Arc so that the memory the AtomicUsize is stored in still exists for</span>
  <span class="co">// the other thread to increment, even if we completely finish executing</span>
  <span class="co">// before it. Rust won't compile the program without it, because of the</span>
  <span class="co">// lifetime requirements of thread::spawn!</span>
  <span class="kw">let</span> idx = Arc::new(AtomicUsize::new(<span class="dv">0</span>));
  <span class="kw">let</span> other_idx = idx.clone();
  
  <span class="co">// `move` captures other_idx by-value, moving it into this thread</span>
  thread::spawn(<span class="kw">move</span> || {
      <span class="co">// It's ok to mutate idx because this value</span>
      <span class="co">// is an atomic, so it can't cause a Data Race.</span>
      other_idx.fetch_add(<span class="dv">10</span>, Ordering::SeqCst);
  });
  
  <span class="co">// Index with the value loaded from the atomic. This is safe because we</span>
  <span class="co">// read the atomic memory only once, and then pass a copy of that value</span>
  <span class="co">// to the Vec's indexing implementation. This indexing will be correctly</span>
  <span class="co">// bounds checked, and there's no chance of the value getting changed</span>
  <span class="co">// in the middle. However our program may panic if the thread we spawned</span>
  <span class="co">// managed to increment before this ran. A race condition because correct</span>
  <span class="co">// program execution (panicking is rarely correct) depends on order of</span>
  <span class="co">// thread execution.</span>
  <span class="pp">println!</span>(<span class="st">&quot;{}&quot;</span>, data[idx.load(Ordering::SeqCst)]);</code></pre></div>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">use</span> std::thread;
  <span class="kw">use</span> std::sync::atomic::{AtomicUsize, Ordering};
  <span class="kw">use</span> std::sync::Arc;
  
  <span class="kw">let</span> data = <span class="pp">vec!</span>[<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>];
  
  <span class="kw">let</span> idx = Arc::new(AtomicUsize::new(<span class="dv">0</span>));
  <span class="kw">let</span> other_idx = idx.clone();
  
  <span class="co">// `move` captures other_idx by-value, moving it into this thread</span>
  thread::spawn(<span class="kw">move</span> || {
      <span class="co">// It's ok to mutate idx because this value</span>
      <span class="co">// is an atomic, so it can't cause a Data Race.</span>
      other_idx.fetch_add(<span class="dv">10</span>, Ordering::SeqCst);
  });
  
  <span class="kw">if</span> idx.load(Ordering::SeqCst) &lt; data.len() {
      <span class="kw">unsafe</span> {
          <span class="co">// Incorrectly loading the idx after we did the bounds check.</span>
          <span class="co">// It could have changed. This is a race condition, *and dangerous*</span>
          <span class="co">// because we decided to do `get_unchecked`, which is `unsafe`.</span>
          <span class="pp">println!</span>(<span class="st">&quot;{}&quot;</span>, data.get_unchecked(idx.load(Ordering::SeqCst)));
      }
  }</code></pre></div>
  </section>
  <section id="sec--send-and-sync" class="level2">
  <h2>Send and Sync</h2>
  <p>Not everything obeys inherited mutability, though. Some types allow you to multiply alias a location in memory while mutating it. Unless these types use synchronization to manage this access, they are absolutely not thread safe. Rust captures this through the <code>Send</code> and <code>Sync</code> traits.</p>
  <ul>
  <li>A type is Send if it is safe to send it to another thread.</li>
  <li>A type is Sync if it is safe to share between threads (<code>&amp;T</code> is Send).</li>
  </ul>
  <p>Send and Sync are fundamental to Rust’s concurrency story. As such, a substantial amount of special tooling exists to make them work right. First and foremost, they’re [unsafe traits]. This means that they are unsafe to implement, and other unsafe code can assume that they are correctly implemented. Since they’re <em>marker traits</em> (they have no associated items like methods), correctly implemented simply means that they have the intrinsic properties an implementor should have. Incorrectly implementing Send or Sync can cause Undefined Behavior.</p>
  <p>Send and Sync are also automatically derived traits. This means that, unlike every other trait, if a type is composed entirely of Send or Sync types, then it is Send or Sync. Almost all primitives are Send and Sync, and as a consequence pretty much all types you’ll ever interact with are Send and Sync.</p>
  <p>Major exceptions include:</p>
  <ul>
  <li>raw pointers are neither Send nor Sync (because they have no safety guards).</li>
  <li><code>UnsafeCell</code> isn’t Sync (and therefore <code>Cell</code> and <code>RefCell</code> aren’t).</li>
  <li><code>Rc</code> isn’t Send or Sync (because the refcount is shared and unsynchronized).</li>
  </ul>
  <p><code>Rc</code> and <code>UnsafeCell</code> are very fundamentally not thread-safe: they enable unsynchronized shared mutable state. However raw pointers are, strictly speaking, marked as thread-unsafe as more of a <em>lint</em>. Doing anything useful with a raw pointer requires dereferencing it, which is already unsafe. In that sense, one could argue that it would be “fine” for them to be marked as thread safe.</p>
  <p>However it’s important that they aren’t thread safe to prevent types that contain them from being automatically marked as thread safe. These types have non-trivial untracked ownership, and it’s unlikely that their author was necessarily thinking hard about thread safety. In the case of Rc, we have a nice example of a type that contains a <code>*mut</code> that is definitely not thread safe.</p>
  <p>Types that aren’t automatically derived can simply implement them if desired:</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">struct</span> MyBox(*<span class="kw">mut</span> <span class="dt">u8</span>);
  
  <span class="kw">unsafe</span> <span class="kw">impl</span> <span class="bu">Send</span> <span class="kw">for</span> MyBox {}
  <span class="kw">unsafe</span> <span class="kw">impl</span> <span class="bu">Sync</span> <span class="kw">for</span> MyBox {}</code></pre></div>
  <p>In the <em>incredibly rare</em> case that a type is inappropriately automatically derived to be Send or Sync, then one can also unimplement Send and Sync:</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="at">#![</span>feature<span class="at">(</span>optin_builtin_traits<span class="at">)]</span>
  
  <span class="co">// I have some magic semantics for some synchronization primitive!</span>
  <span class="kw">struct</span> SpecialThreadToken(<span class="dt">u8</span>);
  
  <span class="kw">impl</span> !<span class="bu">Send</span> <span class="kw">for</span> SpecialThreadToken {}
  <span class="kw">impl</span> !<span class="bu">Sync</span> <span class="kw">for</span> SpecialThreadToken {}</code></pre></div>
  <p>Note that <em>in and of itself</em> it is impossible to incorrectly derive Send and Sync. Only types that are ascribed special meaning by other unsafe code can possible cause trouble by being incorrectly Send or Sync.</p>
  <p>Most uses of raw pointers should be encapsulated behind a sufficient abstraction that Send and Sync can be derived. For instance all of Rust’s standard collections are Send and Sync (when they contain Send and Sync types) in spite of their pervasive use of raw pointers to manage allocations and complex ownership. Similarly, most iterators into these collections are Send and Sync because they largely behave like an <code>&amp;</code> or <code>&amp;mut</code> into the collection.</p>
  <p>TODO: better explain what can or can’t be Send or Sync. Sufficient to appeal only to data races?</p>
  </section>
  <section id="sec--atomics" class="level2">
  <h2>Atomics</h2>
  <p>Rust pretty blatantly just inherits C11’s memory model for atomics. This is not due to this model being particularly excellent or easy to understand. Indeed, this model is quite complex and known to have <a href="http://plv.mpi-sws.org/c11comp/popl15.pdf">several flaws</a>. Rather, it is a pragmatic concession to the fact that <em>everyone</em> is pretty bad at modeling atomics. At very least, we can benefit from existing tooling and research around C.</p>
  <p>Trying to fully explain the model in this book is fairly hopeless. It’s defined in terms of madness-inducing causality graphs that require a full book to properly understand in a practical way. If you want all the nitty-gritty details, you should check out <a href="http://www.open-std.org/jtc1/sc22/wg14/www/standards.html#9899">C’s specification (Section 7.17)</a>. Still, we’ll try to cover the basics and some of the problems Rust developers face.</p>
  <p>The C11 memory model is fundamentally about trying to bridge the gap between the semantics we want, the optimizations compilers want, and the inconsistent chaos our hardware wants. <em>We</em> would like to just write programs and have them do exactly what we said but, you know, fast. Wouldn’t that be great?</p>
  <section id="compiler-reordering" class="level3">
  <h3>Compiler Reordering</h3>
  <p>Compilers fundamentally want to be able to do all sorts of crazy transformations to reduce data dependencies and eliminate dead code. In particular, they may radically change the actual order of events, or make events never occur! If we write something like</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust">x = <span class="dv">1</span>;
  y = <span class="dv">3</span>;
  x = <span class="dv">2</span>;</code></pre></div>
  <p>The compiler may conclude that it would be best if your program did</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust">x = <span class="dv">2</span>;
  y = <span class="dv">3</span>;</code></pre></div>
  <p>This has inverted the order of events and completely eliminated one event. From a single-threaded perspective this is completely unobservable: after all the statements have executed we are in exactly the same state. But if our program is multi-threaded, we may have been relying on <code>x</code> to actually be assigned to 1 before <code>y</code> was assigned. We would like the compiler to be able to make these kinds of optimizations, because they can seriously improve performance. On the other hand, we’d also like to be able to depend on our program <em>doing the thing we said</em>.</p>
  </section>
  <section id="hardware-reordering" class="level3">
  <h3>Hardware Reordering</h3>
  <p>On the other hand, even if the compiler totally understood what we wanted and respected our wishes, our hardware might instead get us in trouble. Trouble comes from CPUs in the form of memory hierarchies. There is indeed a global shared memory space somewhere in your hardware, but from the perspective of each CPU core it is <em>so very far away</em> and <em>so very slow</em>. Each CPU would rather work with its local cache of the data and only go through all the anguish of talking to shared memory only when it doesn’t actually have that memory in cache.</p>
  <p>After all, that’s the whole point of the cache, right? If every read from the cache had to run back to shared memory to double check that it hadn’t changed, what would the point be? The end result is that the hardware doesn’t guarantee that events that occur in the same order on <em>one</em> thread, occur in the same order on <em>another</em> thread. To guarantee this, we must issue special instructions to the CPU telling it to be a bit less smart.</p>
  <p>For instance, say we convince the compiler to emit this logic:</p>
  <pre class="text"><code>initial state: x = 0, y = 1
  
  THREAD 1        THREAD2
  y = 3;          if x == 1 {
  x = 1;              y *= 2;
                  }</code></pre>
  <p>Ideally this program has 2 possible final states:</p>
  <ul>
  <li><code>y = 3</code>: (thread 2 did the check before thread 1 completed)</li>
  <li><code>y = 6</code>: (thread 2 did the check after thread 1 completed)</li>
  </ul>
  <p>However there’s a third potential state that the hardware enables:</p>
  <ul>
  <li><code>y = 2</code>: (thread 2 saw <code>x = 1</code>, but not <code>y = 3</code>, and then overwrote <code>y = 3</code>)</li>
  </ul>
  <p>It’s worth noting that different kinds of CPU provide different guarantees. It is common to separate hardware into two categories: strongly-ordered and weakly- ordered. Most notably x86/64 provides strong ordering guarantees, while ARM provides weak ordering guarantees. This has two consequences for concurrent programming:</p>
  <ul>
  <li><p>Asking for stronger guarantees on strongly-ordered hardware may be cheap or even free because they already provide strong guarantees unconditionally. Weaker guarantees may only yield performance wins on weakly-ordered hardware.</p></li>
  <li><p>Asking for guarantees that are too weak on strongly-ordered hardware is more likely to <em>happen</em> to work, even though your program is strictly incorrect. If possible, concurrent algorithms should be tested on weakly-ordered hardware.</p></li>
  </ul>
  </section>
  <section id="data-accesses" class="level3">
  <h3>Data Accesses</h3>
  <p>The C11 memory model attempts to bridge the gap by allowing us to talk about the <em>causality</em> of our program. Generally, this is by establishing a <em>happens before</em> relationship between parts of the program and the threads that are running them. This gives the hardware and compiler room to optimize the program more aggressively where a strict happens-before relationship isn’t established, but forces them to be more careful where one is established. The way we communicate these relationships are through <em>data accesses</em> and <em>atomic accesses</em>.</p>
  <p>Data accesses are the bread-and-butter of the programming world. They are fundamentally unsynchronized and compilers are free to aggressively optimize them. In particular, data accesses are free to be reordered by the compiler on the assumption that the program is single-threaded. The hardware is also free to propagate the changes made in data accesses to other threads as lazily and inconsistently as it wants. Most critically, data accesses are how data races happen. Data accesses are very friendly to the hardware and compiler, but as we’ve seen they offer <em>awful</em> semantics to try to write synchronized code with. Actually, that’s too weak.</p>
  <p><strong>It is literally impossible to write correct synchronized code using only data accesses.</strong></p>
  <p>Atomic accesses are how we tell the hardware and compiler that our program is multi-threaded. Each atomic access can be marked with an <em>ordering</em> that specifies what kind of relationship it establishes with other accesses. In practice, this boils down to telling the compiler and hardware certain things they <em>can’t</em> do. For the compiler, this largely revolves around re-ordering of instructions. For the hardware, this largely revolves around how writes are propagated to other threads. The set of orderings Rust exposes are:</p>
  <ul>
  <li>Sequentially Consistent (SeqCst)</li>
  <li>Release</li>
  <li>Acquire</li>
  <li>Relaxed</li>
  </ul>
  <p>(Note: We explicitly do not expose the C11 <em>consume</em> ordering)</p>
  <p>TODO: negative reasoning vs positive reasoning? TODO: “can’t forget to synchronize”</p>
  </section>
  <section id="sequentially-consistent" class="level3">
  <h3>Sequentially Consistent</h3>
  <p>Sequentially Consistent is the most powerful of all, implying the restrictions of all other orderings. Intuitively, a sequentially consistent operation cannot be reordered: all accesses on one thread that happen before and after a SeqCst access stay before and after it. A data-race-free program that uses only sequentially consistent atomics and data accesses has the very nice property that there is a single global execution of the program’s instructions that all threads agree on. This execution is also particularly nice to reason about: it’s just an interleaving of each thread’s individual executions. This does not hold if you start using the weaker atomic orderings.</p>
  <p>The relative developer-friendliness of sequential consistency doesn’t come for free. Even on strongly-ordered platforms sequential consistency involves emitting memory fences.</p>
  <p>In practice, sequential consistency is rarely necessary for program correctness. However sequential consistency is definitely the right choice if you’re not confident about the other memory orders. Having your program run a bit slower than it needs to is certainly better than it running incorrectly! It’s also mechanically trivial to downgrade atomic operations to have a weaker consistency later on. Just change <code>SeqCst</code> to <code>Relaxed</code> and you’re done! Of course, proving that this transformation is <em>correct</em> is a whole other matter.</p>
  </section>
  <section id="acquire-release" class="level3">
  <h3>Acquire-Release</h3>
  <p>Acquire and Release are largely intended to be paired. Their names hint at their use case: they’re perfectly suited for acquiring and releasing locks, and ensuring that critical sections don’t overlap.</p>
  <p>Intuitively, an acquire access ensures that every access after it stays after it. However operations that occur before an acquire are free to be reordered to occur after it. Similarly, a release access ensures that every access before it stays before it. However operations that occur after a release are free to be reordered to occur before it.</p>
  <p>When thread A releases a location in memory and then thread B subsequently acquires <em>the same</em> location in memory, causality is established. Every write that happened before A’s release will be observed by B after its release. However no causality is established with any other threads. Similarly, no causality is established if A and B access <em>different</em> locations in memory.</p>
  <p>Basic use of release-acquire is therefore simple: you acquire a location of memory to begin the critical section, and then release that location to end it. For instance, a simple spinlock might look like:</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">use</span> std::sync::Arc;
  <span class="kw">use</span> std::sync::atomic::{AtomicBool, Ordering};
  <span class="kw">use</span> std::thread;
  
  <span class="kw">fn</span> main() {
      <span class="kw">let</span> lock = Arc::new(AtomicBool::new(<span class="cn">false</span>)); <span class="co">// value answers &quot;am I locked?&quot;</span>
  
      <span class="co">// ... distribute lock to threads somehow ...</span>
  
      <span class="co">// Try to acquire the lock by setting it to true</span>
      <span class="kw">while</span> lock.compare_and_swap(<span class="cn">false</span>, <span class="cn">true</span>, Ordering::Acquire) { }
      <span class="co">// broke out of the loop, so we successfully acquired the lock!</span>
  
      <span class="co">// ... scary data accesses ...</span>
  
      <span class="co">// ok we're done, release the lock</span>
      lock.store(<span class="cn">false</span>, Ordering::Release);
  }</code></pre></div>
  <p>On strongly-ordered platforms most accesses have release or acquire semantics, making release and acquire often totally free. This is not the case on weakly-ordered platforms.</p>
  </section>
  <section id="relaxed" class="level3">
  <h3>Relaxed</h3>
  <p>Relaxed accesses are the absolute weakest. They can be freely re-ordered and provide no happens-before relationship. Still, relaxed operations are still atomic. That is, they don’t count as data accesses and any read-modify-write operations done to them occur atomically. Relaxed operations are appropriate for things that you definitely want to happen, but don’t particularly otherwise care about. For instance, incrementing a counter can be safely done by multiple threads using a relaxed <code>fetch_add</code> if you’re not using the counter to synchronize any other accesses.</p>
  <p>There’s rarely a benefit in making an operation relaxed on strongly-ordered platforms, since they usually provide release-acquire semantics anyway. However relaxed operations can be cheaper on weakly-ordered platforms.</p>
  </section>
  </section>
  </section>
  <section id="sec--vec" class="level1">
  <h1>Implementing Vec</h1>
  <p>To bring everything together, we’re going to write <code>std::Vec</code> from scratch. Because all the best tools for writing unsafe code are unstable, this project will only work on nightly (as of Rust 1.9.0). With the exception of the allocator API, much of the unstable code we’ll use is expected to be stabilized in a similar form as it is today.</p>
  <p>However we will generally try to avoid unstable code where possible. In particular we won’t use any intrinsics that could make a code a little bit nicer or efficient because intrinsics are permanently unstable. Although many intrinsics <em>do</em> become stabilized elsewhere (<code>std::ptr</code> and <code>str::mem</code> consist of many intrinsics).</p>
  <p>Ultimately this means our implementation may not take advantage of all possible optimizations, though it will be by no means <em>naive</em>. We will definitely get into the weeds over nitty-gritty details, even when the problem doesn’t <em>really</em> merit it.</p>
  <p>You wanted advanced. We’re gonna go advanced.</p>
  <section id="sec--vec-layout" class="level2">
  <h2>Layout</h2>
  <p>First off, we need to come up with the struct layout. A Vec has three parts: a pointer to the allocation, the size of the allocation, and the number of elements that have been initialized.</p>
  <p>Naively, this means we just want this design:</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">pub</span> <span class="kw">struct</span> <span class="dt">Vec</span>&lt;T&gt; {
      ptr: *<span class="kw">mut</span> T,
      cap: <span class="dt">usize</span>,
      len: <span class="dt">usize</span>,
  }</code></pre></div>
  <p>And indeed this would compile. Unfortunately, it would be incorrect. First, the compiler will give us too strict variance. So a <code>&amp;Vec&lt;&amp;'static str&gt;</code> couldn’t be used where an <code>&amp;Vec&lt;&amp;'a str&gt;</code> was expected. More importantly, it will give incorrect ownership information to the drop checker, as it will conservatively assume we don’t own any values of type <code>T</code>. See <a href="#sec--ownership">the chapter on ownership and lifetimes</a> for all the details on variance and drop check.</p>
  <p>As we saw in the ownership chapter, we should use <code>Unique&lt;T&gt;</code> in place of <code>*mut T</code> when we have a raw pointer to an allocation we own. Unique is unstable, so we’d like to not use it if possible, though.</p>
  <p>As a recap, Unique is a wrapper around a raw pointer that declares that:</p>
  <ul>
  <li>We are variant over <code>T</code></li>
  <li>We may own a value of type <code>T</code> (for drop check)</li>
  <li>We are Send/Sync if <code>T</code> is Send/Sync</li>
  <li>We deref to <code>*mut T</code> (so it largely acts like a <code>*mut</code> in our code)</li>
  <li>Our pointer is never null (so <code>Option&lt;Vec&lt;T&gt;&gt;</code> is null-pointer-optimized)</li>
  </ul>
  <p>We can implement all of the above requirements except for the last one in stable Rust:</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">use</span> std::marker::PhantomData;
  <span class="kw">use</span> std::ops::Deref;
  <span class="kw">use</span> std::mem;
  
  <span class="kw">struct</span> Unique&lt;T&gt; {
      ptr: *<span class="kw">const</span> T,              <span class="co">// *const for variance</span>
      _marker: PhantomData&lt;T&gt;,    <span class="co">// For the drop checker</span>
  }
  
  <span class="co">// Deriving Send and Sync is safe because we are the Unique owners</span>
  <span class="co">// of this data. It's like Unique&lt;T&gt; is &quot;just&quot; T.</span>
  <span class="kw">unsafe</span> <span class="kw">impl</span>&lt;T: <span class="bu">Send</span>&gt; <span class="bu">Send</span> <span class="kw">for</span> Unique&lt;T&gt; {}
  <span class="kw">unsafe</span> <span class="kw">impl</span>&lt;T: <span class="bu">Sync</span>&gt; <span class="bu">Sync</span> <span class="kw">for</span> Unique&lt;T&gt; {}
  
  <span class="kw">impl</span>&lt;T&gt; Unique&lt;T&gt; {
      <span class="kw">pub</span> <span class="kw">fn</span> new(ptr: *<span class="kw">mut</span> T) -&gt; <span class="kw">Self</span> {
          Unique { ptr: ptr, _marker: PhantomData }
      }
  }
  
  <span class="kw">impl</span>&lt;T&gt; Deref <span class="kw">for</span> Unique&lt;T&gt; {
      <span class="kw">type</span> Target = *<span class="kw">mut</span> T;
      <span class="kw">fn</span> deref(&amp;<span class="kw">self</span>) -&gt; &amp;*<span class="kw">mut</span> T {
          <span class="co">// There's no way to cast the *const to a *mut</span>
          <span class="co">// while also taking a reference. So we just</span>
          <span class="co">// transmute it since it's all &quot;just pointers&quot;.</span>
          <span class="kw">unsafe</span> { mem::transmute(&amp;<span class="kw">self</span>.ptr) }
      }
  }</code></pre></div>
  <p>Unfortunately the mechanism for stating that your value is non-zero is unstable and unlikely to be stabilized soon. As such we’re just going to take the hit and use std’s Unique:</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="at">#![</span>feature<span class="at">(</span>unique<span class="at">)]</span>
  
  <span class="kw">use</span> std::ptr::{Unique, <span class="kw">self</span>};
  
  <span class="kw">pub</span> <span class="kw">struct</span> <span class="dt">Vec</span>&lt;T&gt; {
      ptr: Unique&lt;T&gt;,
      cap: <span class="dt">usize</span>,
      len: <span class="dt">usize</span>,
  }</code></pre></div>
  <p>If you don’t care about the null-pointer optimization, then you can use the stable code. However we will be designing the rest of the code around enabling the optimization. In particular, <code>Unique::new</code> is unsafe to call, because putting <code>null</code> inside of it is Undefined Behavior. Our stable Unique doesn’t need <code>new</code> to be unsafe because it doesn’t make any interesting guarantees about its contents.</p>
  </section>
  <section id="sec--vec-alloc" class="level2">
  <h2>Allocating</h2>
  <p>Using Unique throws a wrench in an important feature of Vec (and indeed all of the std collections): an empty Vec doesn’t actually allocate at all. So if we can’t allocate, but also can’t put a null pointer in <code>ptr</code>, what do we do in <code>Vec::new</code>? Well, we just put some other garbage in there!</p>
  <p>This is perfectly fine because we already have <code>cap == 0</code> as our sentinel for no allocation. We don’t even need to handle it specially in almost any code because we usually need to check if <code>cap &gt; len</code> or <code>len &gt; 0</code> anyway. The traditional Rust value to put here is <code>0x01</code>. The standard library actually exposes this as <code>alloc::heap::EMPTY</code>. There are quite a few places where we’ll want to use <code>heap::EMPTY</code> because there’s no real allocation to talk about but <code>null</code> would make the compiler do bad things.</p>
  <p>All of the <code>heap</code> API is totally unstable under the <code>heap_api</code> feature, though. We could trivially define <code>heap::EMPTY</code> ourselves, but we’ll want the rest of the <code>heap</code> API anyway, so let’s just get that dependency over with.</p>
  <p>So:</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="at">#![</span>feature<span class="at">(</span>alloc<span class="at">,</span> heap_api<span class="at">)]</span>
  
  <span class="kw">use</span> std::mem;
  
  <span class="kw">use</span> alloc::heap::EMPTY;
  
  <span class="kw">impl</span>&lt;T&gt; <span class="dt">Vec</span>&lt;T&gt; {
      <span class="kw">fn</span> new() -&gt; <span class="kw">Self</span> {
          <span class="pp">assert!</span>(mem::size_of::&lt;T&gt;() != <span class="dv">0</span>, <span class="st">&quot;We're not ready to handle ZSTs&quot;</span>);
          <span class="kw">unsafe</span> {
              <span class="co">// need to cast EMPTY to the actual ptr type we want, let</span>
              <span class="co">// inference handle it.</span>
              <span class="dt">Vec</span> { ptr: Unique::new(heap::EMPTY <span class="kw">as</span> *<span class="kw">mut</span> _), len: <span class="dv">0</span>, cap: <span class="dv">0</span> }
          }
      }
  }</code></pre></div>
  <p>I slipped in that assert there because zero-sized types will require some special handling throughout our code, and I want to defer the issue for now. Without this assert, some of our early drafts will do some Very Bad Things.</p>
  <p>Next we need to figure out what to actually do when we <em>do</em> want space. For that, we’ll need to use the rest of the heap APIs. These basically allow us to talk directly to Rust’s allocator (jemalloc by default).</p>
  <p>We’ll also need a way to handle out-of-memory (OOM) conditions. The standard library calls the <code>abort</code> intrinsic, which just calls an illegal instruction to crash the whole program. The reason we abort and don’t panic is because unwinding can cause allocations to happen, and that seems like a bad thing to do when your allocator just came back with “hey I don’t have any more memory”.</p>
  <p>Of course, this is a bit silly since most platforms don’t actually run out of memory in a conventional way. Your operating system will probably kill the application by another means if you legitimately start using up all the memory. The most likely way we’ll trigger OOM is by just asking for ludicrous quantities of memory at once (e.g. half the theoretical address space). As such it’s <em>probably</em> fine to panic and nothing bad will happen. Still, we’re trying to be like the standard library as much as possible, so we’ll just kill the whole program.</p>
  <p>We said we don’t want to use intrinsics, so doing exactly what <code>std</code> does is out. Instead, we’ll call <code>std::process::exit</code> with some random number.</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">fn</span> oom() {
      ::std::process::exit(-<span class="dv">9999</span>);
  }</code></pre></div>
  <p>Okay, now we can write growing. Roughly, we want to have this logic:</p>
  <pre class="text"><code>if cap == 0:
      allocate()
      cap = 1
  else:
      reallocate()
      cap *= 2</code></pre>
  <p>But Rust’s only supported allocator API is so low level that we’ll need to do a fair bit of extra work. We also need to guard against some special conditions that can occur with really large allocations or empty allocations.</p>
  <p>In particular, <code>ptr::offset</code> will cause us a lot of trouble, because it has the semantics of LLVM’s GEP inbounds instruction. If you’re fortunate enough to not have dealt with this instruction, here’s the basic story with GEP: alias analysis, alias analysis, alias analysis. It’s super important to an optimizing compiler to be able to reason about data dependencies and aliasing.</p>
  <p>As a simple example, consider the following fragment of code:</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust">*x *= <span class="dv">7</span>;
  *y *= <span class="dv">3</span>;</code></pre></div>
  <p>If the compiler can prove that <code>x</code> and <code>y</code> point to different locations in memory, the two operations can in theory be executed in parallel (by e.g. loading them into different registers and working on them independently). However the compiler can’t do this in general because if x and y point to the same location in memory, the operations need to be done to the same value, and they can’t just be merged afterwards.</p>
  <p>When you use GEP inbounds, you are specifically telling LLVM that the offsets you’re about to do are within the bounds of a single “allocated” entity. The ultimate payoff being that LLVM can assume that if two pointers are known to point to two disjoint objects, all the offsets of those pointers are <em>also</em> known to not alias (because you won’t just end up in some random place in memory). LLVM is heavily optimized to work with GEP offsets, and inbounds offsets are the best of all, so it’s important that we use them as much as possible.</p>
  <p>So that’s what GEP’s about, how can it cause us trouble?</p>
  <p>The first problem is that we index into arrays with unsigned integers, but GEP (and as a consequence <code>ptr::offset</code>) takes a signed integer. This means that half of the seemingly valid indices into an array will overflow GEP and actually go in the wrong direction! As such we must limit all allocations to <code>isize::MAX</code> elements. This actually means we only need to worry about byte-sized objects, because e.g. <code>&gt; isize::MAX</code> <code>u16</code>s will truly exhaust all of the system’s memory. However in order to avoid subtle corner cases where someone reinterprets some array of <code>&lt; isize::MAX</code> objects as bytes, std limits all allocations to <code>isize::MAX</code> bytes.</p>
  <p>On all 64-bit targets that Rust currently supports we’re artificially limited to significantly less than all 64 bits of the address space (modern x64 platforms only expose 48-bit addressing), so we can rely on just running out of memory first. However on 32-bit targets, particularly those with extensions to use more of the address space (PAE x86 or x32), it’s theoretically possible to successfully allocate more than <code>isize::MAX</code> bytes of memory.</p>
  <p>However since this is a tutorial, we’re not going to be particularly optimal here, and just unconditionally check, rather than use clever platform-specific <code>cfg</code>s.</p>
  <p>The other corner-case we need to worry about is empty allocations. There will be two kinds of empty allocations we need to worry about: <code>cap = 0</code> for all T, and <code>cap &gt; 0</code> for zero-sized types.</p>
  <p>These cases are tricky because they come down to what LLVM means by “allocated”. LLVM’s notion of an allocation is significantly more abstract than how we usually use it. Because LLVM needs to work with different languages’ semantics and custom allocators, it can’t really intimately understand allocation. Instead, the main idea behind allocation is “doesn’t overlap with other stuff”. That is, heap allocations, stack allocations, and globals don’t randomly overlap. Yep, it’s about alias analysis. As such, Rust can technically play a bit fast and loose with the notion of an allocation as long as it’s <em>consistent</em>.</p>
  <p>Getting back to the empty allocation case, there are a couple of places where we want to offset by 0 as a consequence of generic code. The question is then: is it consistent to do so? For zero-sized types, we have concluded that it is indeed consistent to do a GEP inbounds offset by an arbitrary number of elements. This is a runtime no-op because every element takes up no space, and it’s fine to pretend that there’s infinite zero-sized types allocated at <code>0x01</code>. No allocator will ever allocate that address, because they won’t allocate <code>0x00</code> and they generally allocate to some minimal alignment higher than a byte. Also generally the whole first page of memory is protected from being allocated anyway (a whole 4k, on many platforms).</p>
  <p>However what about for positive-sized types? That one’s a bit trickier. In principle, you can argue that offsetting by 0 gives LLVM no information: either there’s an element before the address or after it, but it can’t know which. However we’ve chosen to conservatively assume that it may do bad things. As such we will guard against this case explicitly.</p>
  <p><em>Phew</em></p>
  <p>Ok with all the nonsense out of the way, let’s actually allocate some memory:</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">fn</span> grow(&amp;<span class="kw">mut</span> <span class="kw">self</span>) {
      <span class="co">// this is all pretty delicate, so let's say it's all unsafe</span>
      <span class="kw">unsafe</span> {
          <span class="co">// current API requires us to specify size and alignment manually.</span>
          <span class="kw">let</span> align = mem::align_of::&lt;T&gt;();
          <span class="kw">let</span> elem_size = mem::size_of::&lt;T&gt;();
  
          <span class="kw">let</span> (new_cap, ptr) = <span class="kw">if</span> <span class="kw">self</span>.cap == <span class="dv">0</span> {
              <span class="kw">let</span> ptr = heap::allocate(elem_size, align);
              (<span class="dv">1</span>, ptr)
          } <span class="kw">else</span> {
              <span class="co">// as an invariant, we can assume that `self.cap &lt; isize::MAX`,</span>
              <span class="co">// so this doesn't need to be checked.</span>
              <span class="kw">let</span> new_cap = <span class="kw">self</span>.cap * <span class="dv">2</span>;
              <span class="co">// Similarly this can't overflow due to previously allocating this</span>
              <span class="kw">let</span> old_num_bytes = <span class="kw">self</span>.cap * elem_size;
  
              <span class="co">// check that the new allocation doesn't exceed `isize::MAX` at all</span>
              <span class="co">// regardless of the actual size of the capacity. This combines the</span>
              <span class="co">// `new_cap &lt;= isize::MAX` and `new_num_bytes &lt;= usize::MAX` checks</span>
              <span class="co">// we need to make. We lose the ability to allocate e.g. 2/3rds of</span>
              <span class="co">// the address space with a single Vec of i16's on 32-bit though.</span>
              <span class="co">// Alas, poor Yorick -- I knew him, Horatio.</span>
              <span class="pp">assert!</span>(old_num_bytes &lt;= (::std::<span class="dt">isize</span>::MAX <span class="kw">as</span> <span class="dt">usize</span>) / <span class="dv">2</span>,
                      <span class="st">&quot;capacity overflow&quot;</span>);
  
              <span class="kw">let</span> new_num_bytes = old_num_bytes * <span class="dv">2</span>;
              <span class="kw">let</span> ptr = heap::reallocate(*<span class="kw">self</span>.ptr <span class="kw">as</span> *<span class="kw">mut</span> _,
                                          old_num_bytes,
                                          new_num_bytes,
                                          align);
              (new_cap, ptr)
          };
  
          <span class="co">// If allocate or reallocate fail, we'll get `null` back</span>
          <span class="kw">if</span> ptr.is_null() { oom(); }
  
          <span class="kw">self</span>.ptr = Unique::new(ptr <span class="kw">as</span> *<span class="kw">mut</span> _);
          <span class="kw">self</span>.cap = new_cap;
      }
  }</code></pre></div>
  <p>Nothing particularly tricky here. Just computing sizes and alignments and doing some careful multiplication checks.</p>
  </section>
  <section id="sec--vec-push-pop" class="level2">
  <h2>Push and Pop</h2>
  <p>Alright. We can initialize. We can allocate. Let’s actually implement some functionality! Let’s start with <code>push</code>. All it needs to do is check if we’re full to grow, unconditionally write to the next index, and then increment our length.</p>
  <p>To do the write we have to be careful not to evaluate the memory we want to write to. At worst, it’s truly uninitialized memory from the allocator. At best it’s the bits of some old value we popped off. Either way, we can’t just index to the memory and dereference it, because that will evaluate the memory as a valid instance of T. Worse, <code>foo[idx] = x</code> will try to call <code>drop</code> on the old value of <code>foo[idx]</code>!</p>
  <p>The correct way to do this is with <code>ptr::write</code>, which just blindly overwrites the target address with the bits of the value we provide. No evaluation involved.</p>
  <p>For <code>push</code>, if the old len (before push was called) is 0, then we want to write to the 0th index. So we should offset by the old len.</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">pub</span> <span class="kw">fn</span> push(&amp;<span class="kw">mut</span> <span class="kw">self</span>, elem: T) {
      <span class="kw">if</span> <span class="kw">self</span>.len == <span class="kw">self</span>.cap { <span class="kw">self</span>.grow(); }
  
      <span class="kw">unsafe</span> {
          ptr::write(<span class="kw">self</span>.ptr.offset(<span class="kw">self</span>.len <span class="kw">as</span> <span class="dt">isize</span>), elem);
      }
  
      <span class="co">// Can't fail, we'll OOM first.</span>
      <span class="kw">self</span>.len += <span class="dv">1</span>;
  }</code></pre></div>
  <p>Easy! How about <code>pop</code>? Although this time the index we want to access is initialized, Rust won’t just let us dereference the location of memory to move the value out, because that would leave the memory uninitialized! For this we need <code>ptr::read</code>, which just copies out the bits from the target address and interprets it as a value of type T. This will leave the memory at this address logically uninitialized, even though there is in fact a perfectly good instance of T there.</p>
  <p>For <code>pop</code>, if the old len is 1, we want to read out of the 0th index. So we should offset by the new len.</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">pub</span> <span class="kw">fn</span> pop(&amp;<span class="kw">mut</span> <span class="kw">self</span>) -&gt; <span class="dt">Option</span>&lt;T&gt; {
      <span class="kw">if</span> <span class="kw">self</span>.len == <span class="dv">0</span> {
          <span class="cn">None</span>
      } <span class="kw">else</span> {
          <span class="kw">self</span>.len -= <span class="dv">1</span>;
          <span class="kw">unsafe</span> {
              <span class="cn">Some</span>(ptr::read(<span class="kw">self</span>.ptr.offset(<span class="kw">self</span>.len <span class="kw">as</span> <span class="dt">isize</span>)))
          }
      }
  }</code></pre></div>
  </section>
  <section id="sec--vec-dealloc" class="level2">
  <h2>Deallocating</h2>
  <p>Next we should implement Drop so that we don’t massively leak tons of resources. The easiest way is to just call <code>pop</code> until it yields None, and then deallocate our buffer. Note that calling <code>pop</code> is unneeded if <code>T: !Drop</code>. In theory we can ask Rust if <code>T</code> <code>needs_drop</code> and omit the calls to <code>pop</code>. However in practice LLVM is <em>really</em> good at removing simple side-effect free code like this, so I wouldn’t bother unless you notice it’s not being stripped (in this case it is).</p>
  <p>We must not call <code>heap::deallocate</code> when <code>self.cap == 0</code>, as in this case we haven’t actually allocated any memory.</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">impl</span>&lt;T&gt; <span class="bu">Drop</span> <span class="kw">for</span> <span class="dt">Vec</span>&lt;T&gt; {
      <span class="kw">fn</span> drop(&amp;<span class="kw">mut</span> <span class="kw">self</span>) {
          <span class="kw">if</span> <span class="kw">self</span>.cap != <span class="dv">0</span> {
              <span class="kw">while</span> <span class="kw">let</span> <span class="cn">Some</span>(_) = <span class="kw">self</span>.pop() { }
  
              <span class="kw">let</span> align = mem::align_of::&lt;T&gt;();
              <span class="kw">let</span> elem_size = mem::size_of::&lt;T&gt;();
              <span class="kw">let</span> num_bytes = elem_size * <span class="kw">self</span>.cap;
              <span class="kw">unsafe</span> {
                  heap::deallocate(*<span class="kw">self</span>.ptr <span class="kw">as</span> *<span class="kw">mut</span> _, num_bytes, align);
              }
          }
      }
  }</code></pre></div>
  </section>
  <section id="sec--vec-deref" class="level2">
  <h2>Deref</h2>
  <p>Alright! We’ve got a decent minimal stack implemented. We can push, we can pop, and we can clean up after ourselves. However there’s a whole mess of functionality we’d reasonably want. In particular, we have a proper array, but none of the slice functionality. That’s actually pretty easy to solve: we can implement <code>Deref&lt;Target=[T]&gt;</code>. This will magically make our Vec coerce to, and behave like, a slice in all sorts of conditions.</p>
  <p>All we need is <code>slice::from_raw_parts</code>. It will correctly handle empty slices for us. Later once we set up zero-sized type support it will also Just Work for those too.</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">use</span> std::ops::Deref;
  
  <span class="kw">impl</span>&lt;T&gt; Deref <span class="kw">for</span> <span class="dt">Vec</span>&lt;T&gt; {
      <span class="kw">type</span> Target = [T];
      <span class="kw">fn</span> deref(&amp;<span class="kw">self</span>) -&gt; &amp;[T] {
          <span class="kw">unsafe</span> {
              ::std::slice::from_raw_parts(*<span class="kw">self</span>.ptr, <span class="kw">self</span>.len)
          }
      }
  }</code></pre></div>
  <p>And let’s do DerefMut too:</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">use</span> std::ops::DerefMut;
  
  <span class="kw">impl</span>&lt;T&gt; DerefMut <span class="kw">for</span> <span class="dt">Vec</span>&lt;T&gt; {
      <span class="kw">fn</span> deref_mut(&amp;<span class="kw">mut</span> <span class="kw">self</span>) -&gt; &amp;<span class="kw">mut</span> [T] {
          <span class="kw">unsafe</span> {
              ::std::slice::from_raw_parts_mut(*<span class="kw">self</span>.ptr, <span class="kw">self</span>.len)
          }
      }
  }</code></pre></div>
  <p>Now we have <code>len</code>, <code>first</code>, <code>last</code>, indexing, slicing, sorting, <code>iter</code>, <code>iter_mut</code>, and all other sorts of bells and whistles provided by slice. Sweet!</p>
  </section>
  <section id="sec--vec-insert-remove" class="level2">
  <h2>Insert and Remove</h2>
  <p>Something <em>not</em> provided by slice is <code>insert</code> and <code>remove</code>, so let’s do those next.</p>
  <p>Insert needs to shift all the elements at the target index to the right by one. To do this we need to use <code>ptr::copy</code>, which is our version of C’s <code>memmove</code>. This copies some chunk of memory from one location to another, correctly handling the case where the source and destination overlap (which will definitely happen here).</p>
  <p>If we insert at index <code>i</code>, we want to shift the <code>[i .. len]</code> to <code>[i+1 .. len+1]</code> using the old len.</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">pub</span> <span class="kw">fn</span> insert(&amp;<span class="kw">mut</span> <span class="kw">self</span>, index: <span class="dt">usize</span>, elem: T) {
      <span class="co">// Note: `&lt;=` because it's valid to insert after everything</span>
      <span class="co">// which would be equivalent to push.</span>
      <span class="pp">assert!</span>(index &lt;= <span class="kw">self</span>.len, <span class="st">&quot;index out of bounds&quot;</span>);
      <span class="kw">if</span> <span class="kw">self</span>.cap == <span class="kw">self</span>.len { <span class="kw">self</span>.grow(); }
  
      <span class="kw">unsafe</span> {
          <span class="kw">if</span> index &lt; <span class="kw">self</span>.len {
              <span class="co">// ptr::copy(src, dest, len): &quot;copy from source to dest len elems&quot;</span>
              ptr::copy(<span class="kw">self</span>.ptr.offset(index <span class="kw">as</span> <span class="dt">isize</span>),
                        <span class="kw">self</span>.ptr.offset(index <span class="kw">as</span> <span class="dt">isize</span> + <span class="dv">1</span>),
                        <span class="kw">self</span>.len - index);
          }
          ptr::write(<span class="kw">self</span>.ptr.offset(index <span class="kw">as</span> <span class="dt">isize</span>), elem);
          <span class="kw">self</span>.len += <span class="dv">1</span>;
      }
  }</code></pre></div>
  <p>Remove behaves in the opposite manner. We need to shift all the elements from <code>[i+1 .. len + 1]</code> to <code>[i .. len]</code> using the <em>new</em> len.</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">pub</span> <span class="kw">fn</span> remove(&amp;<span class="kw">mut</span> <span class="kw">self</span>, index: <span class="dt">usize</span>) -&gt; T {
      <span class="co">// Note: `&lt;` because it's *not* valid to remove after everything</span>
      <span class="pp">assert!</span>(index &lt; <span class="kw">self</span>.len, <span class="st">&quot;index out of bounds&quot;</span>);
      <span class="kw">unsafe</span> {
          <span class="kw">self</span>.len -= <span class="dv">1</span>;
          <span class="kw">let</span> result = ptr::read(<span class="kw">self</span>.ptr.offset(index <span class="kw">as</span> <span class="dt">isize</span>));
          ptr::copy(<span class="kw">self</span>.ptr.offset(index <span class="kw">as</span> <span class="dt">isize</span> + <span class="dv">1</span>),
                    <span class="kw">self</span>.ptr.offset(index <span class="kw">as</span> <span class="dt">isize</span>),
                    <span class="kw">self</span>.len - index);
          result
      }
  }</code></pre></div>
  </section>
  <section id="sec--vec-into-iter" class="level2">
  <h2>IntoIter</h2>
  <p>Let’s move on to writing iterators. <code>iter</code> and <code>iter_mut</code> have already been written for us thanks to The Magic of Deref. However there’s two interesting iterators that Vec provides that slices can’t: <code>into_iter</code> and <code>drain</code>.</p>
  <p>IntoIter consumes the Vec by-value, and can consequently yield its elements by-value. In order to enable this, IntoIter needs to take control of Vec’s allocation.</p>
  <p>IntoIter needs to be DoubleEnded as well, to enable reading from both ends. Reading from the back could just be implemented as calling <code>pop</code>, but reading from the front is harder. We could call <code>remove(0)</code> but that would be insanely expensive. Instead we’re going to just use ptr::read to copy values out of either end of the Vec without mutating the buffer at all.</p>
  <p>To do this we’re going to use a very common C idiom for array iteration. We’ll make two pointers; one that points to the start of the array, and one that points to one-element past the end. When we want an element from one end, we’ll read out the value pointed to at that end and move the pointer over by one. When the two pointers are equal, we know we’re done.</p>
  <p>Note that the order of read and offset are reversed for <code>next</code> and <code>next_back</code> For <code>next_back</code> the pointer is always after the element it wants to read next, while for <code>next</code> the pointer is always at the element it wants to read next. To see why this is, consider the case where every element but one has been yielded.</p>
  <p>The array looks like this:</p>
  <pre class="text"><code>          S  E
  [X, X, X, O, X, X, X]</code></pre>
  <p>If E pointed directly at the element it wanted to yield next, it would be indistinguishable from the case where there are no more elements to yield.</p>
  <p>Although we don’t actually care about it during iteration, we also need to hold onto the Vec’s allocation information in order to free it once IntoIter is dropped.</p>
  <p>So we’re going to use the following struct:</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">struct</span> IntoIter&lt;T&gt; {
      buf: Unique&lt;T&gt;,
      cap: <span class="dt">usize</span>,
      start: *<span class="kw">const</span> T,
      end: *<span class="kw">const</span> T,
  }</code></pre></div>
  <p>And this is what we end up with for initialization:</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">impl</span>&lt;T&gt; <span class="dt">Vec</span>&lt;T&gt; {
      <span class="kw">fn</span> into_iter(<span class="kw">self</span>) -&gt; IntoIter&lt;T&gt; {
          <span class="co">// Can't destructure Vec since it's Drop</span>
          <span class="kw">let</span> ptr = <span class="kw">self</span>.ptr;
          <span class="kw">let</span> cap = <span class="kw">self</span>.cap;
          <span class="kw">let</span> len = <span class="kw">self</span>.len;
  
          <span class="co">// Make sure not to drop Vec since that will free the buffer</span>
          mem::forget(<span class="kw">self</span>);
  
          <span class="kw">unsafe</span> {
              IntoIter {
                  buf: ptr,
                  cap: cap,
                  start: *ptr,
                  end: <span class="kw">if</span> cap == <span class="dv">0</span> {
                      <span class="co">// can't offset off this pointer, it's not allocated!</span>
                      *ptr
                  } <span class="kw">else</span> {
                      ptr.offset(len <span class="kw">as</span> <span class="dt">isize</span>)
                  }
              }
          }
      }
  }</code></pre></div>
  <p>Here’s iterating forward:</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">impl</span>&lt;T&gt; <span class="bu">Iterator</span> <span class="kw">for</span> IntoIter&lt;T&gt; {
      <span class="kw">type</span> Item = T;
      <span class="kw">fn</span> next(&amp;<span class="kw">mut</span> <span class="kw">self</span>) -&gt; <span class="dt">Option</span>&lt;T&gt; {
          <span class="kw">if</span> <span class="kw">self</span>.start == <span class="kw">self</span>.end {
              <span class="cn">None</span>
          } <span class="kw">else</span> {
              <span class="kw">unsafe</span> {
                  <span class="kw">let</span> result = ptr::read(<span class="kw">self</span>.start);
                  <span class="kw">self</span>.start = <span class="kw">self</span>.start.offset(<span class="dv">1</span>);
                  <span class="cn">Some</span>(result)
              }
          }
      }
  
      <span class="kw">fn</span> size_hint(&amp;<span class="kw">self</span>) -&gt; (<span class="dt">usize</span>, <span class="dt">Option</span>&lt;<span class="dt">usize</span>&gt;) {
          <span class="kw">let</span> len = (<span class="kw">self</span>.end <span class="kw">as</span> <span class="dt">usize</span> - <span class="kw">self</span>.start <span class="kw">as</span> <span class="dt">usize</span>)
                    / mem::size_of::&lt;T&gt;();
          (len, <span class="cn">Some</span>(len))
      }
  }</code></pre></div>
  <p>And here’s iterating backwards.</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">impl</span>&lt;T&gt; <span class="bu">DoubleEndedIterator</span> <span class="kw">for</span> IntoIter&lt;T&gt; {
      <span class="kw">fn</span> next_back(&amp;<span class="kw">mut</span> <span class="kw">self</span>) -&gt; <span class="dt">Option</span>&lt;T&gt; {
          <span class="kw">if</span> <span class="kw">self</span>.start == <span class="kw">self</span>.end {
              <span class="cn">None</span>
          } <span class="kw">else</span> {
              <span class="kw">unsafe</span> {
                  <span class="kw">self</span>.end = <span class="kw">self</span>.end.offset(-<span class="dv">1</span>);
                  <span class="cn">Some</span>(ptr::read(<span class="kw">self</span>.end))
              }
          }
      }
  }</code></pre></div>
  <p>Because IntoIter takes ownership of its allocation, it needs to implement Drop to free it. However it also wants to implement Drop to drop any elements it contains that weren’t yielded.</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">impl</span>&lt;T&gt; <span class="bu">Drop</span> <span class="kw">for</span> IntoIter&lt;T&gt; {
      <span class="kw">fn</span> drop(&amp;<span class="kw">mut</span> <span class="kw">self</span>) {
          <span class="kw">if</span> <span class="kw">self</span>.cap != <span class="dv">0</span> {
              <span class="co">// drop any remaining elements</span>
              <span class="kw">for</span> _ <span class="kw">in</span> &amp;<span class="kw">mut</span> *<span class="kw">self</span> {}
  
              <span class="kw">let</span> align = mem::align_of::&lt;T&gt;();
              <span class="kw">let</span> elem_size = mem::size_of::&lt;T&gt;();
              <span class="kw">let</span> num_bytes = elem_size * <span class="kw">self</span>.cap;
              <span class="kw">unsafe</span> {
                  heap::deallocate(*<span class="kw">self</span>.buf <span class="kw">as</span> *<span class="kw">mut</span> _, num_bytes, align);
              }
          }
      }
  }</code></pre></div>
  </section>
  <section id="sec--vec-raw" class="level2">
  <h2>RawVec</h2>
  <p>We’ve actually reached an interesting situation here: we’ve duplicated the logic for specifying a buffer and freeing its memory in Vec and IntoIter. Now that we’ve implemented it and identified <em>actual</em> logic duplication, this is a good time to perform some logic compression.</p>
  <p>We’re going to abstract out the <code>(ptr, cap)</code> pair and give them the logic for allocating, growing, and freeing:</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">struct</span> RawVec&lt;T&gt; {
      ptr: Unique&lt;T&gt;,
      cap: <span class="dt">usize</span>,
  }
  
  <span class="kw">impl</span>&lt;T&gt; RawVec&lt;T&gt; {
      <span class="kw">fn</span> new() -&gt; <span class="kw">Self</span> {
          <span class="pp">assert!</span>(mem::size_of::&lt;T&gt;() != <span class="dv">0</span>, <span class="st">&quot;TODO: implement ZST support&quot;</span>);
          <span class="kw">unsafe</span> {
              RawVec { ptr: Unique::new(heap::EMPTY <span class="kw">as</span> *<span class="kw">mut</span> T), cap: <span class="dv">0</span> }
          }
      }
  
      <span class="co">// unchanged from Vec</span>
      <span class="kw">fn</span> grow(&amp;<span class="kw">mut</span> <span class="kw">self</span>) {
          <span class="kw">unsafe</span> {
              <span class="kw">let</span> align = mem::align_of::&lt;T&gt;();
              <span class="kw">let</span> elem_size = mem::size_of::&lt;T&gt;();
  
              <span class="kw">let</span> (new_cap, ptr) = <span class="kw">if</span> <span class="kw">self</span>.cap == <span class="dv">0</span> {
                  <span class="kw">let</span> ptr = heap::allocate(elem_size, align);
                  (<span class="dv">1</span>, ptr)
              } <span class="kw">else</span> {
                  <span class="kw">let</span> new_cap = <span class="dv">2</span> * <span class="kw">self</span>.cap;
                  <span class="kw">let</span> ptr = heap::reallocate(*<span class="kw">self</span>.ptr <span class="kw">as</span> *<span class="kw">mut</span> _,
                                              <span class="kw">self</span>.cap * elem_size,
                                              new_cap * elem_size,
                                              align);
                  (new_cap, ptr)
              };
  
              <span class="co">// If allocate or reallocate fail, we'll get `null` back</span>
              <span class="kw">if</span> ptr.is_null() { oom() }
  
              <span class="kw">self</span>.ptr = Unique::new(ptr <span class="kw">as</span> *<span class="kw">mut</span> _);
              <span class="kw">self</span>.cap = new_cap;
          }
      }
  }
  
  
  <span class="kw">impl</span>&lt;T&gt; <span class="bu">Drop</span> <span class="kw">for</span> RawVec&lt;T&gt; {
      <span class="kw">fn</span> drop(&amp;<span class="kw">mut</span> <span class="kw">self</span>) {
          <span class="kw">if</span> <span class="kw">self</span>.cap != <span class="dv">0</span> {
              <span class="kw">let</span> align = mem::align_of::&lt;T&gt;();
              <span class="kw">let</span> elem_size = mem::size_of::&lt;T&gt;();
              <span class="kw">let</span> num_bytes = elem_size * <span class="kw">self</span>.cap;
              <span class="kw">unsafe</span> {
                  heap::deallocate(*<span class="kw">self</span>.ptr <span class="kw">as</span> *<span class="kw">mut</span> _, num_bytes, align);
              }
          }
      }
  }</code></pre></div>
  <p>And change Vec as follows:</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">pub</span> <span class="kw">struct</span> <span class="dt">Vec</span>&lt;T&gt; {
      buf: RawVec&lt;T&gt;,
      len: <span class="dt">usize</span>,
  }
  
  <span class="kw">impl</span>&lt;T&gt; <span class="dt">Vec</span>&lt;T&gt; {
      <span class="kw">fn</span> ptr(&amp;<span class="kw">self</span>) -&gt; *<span class="kw">mut</span> T { *<span class="kw">self</span>.buf.ptr }
  
      <span class="kw">fn</span> cap(&amp;<span class="kw">self</span>) -&gt; <span class="dt">usize</span> { <span class="kw">self</span>.buf.cap }
  
      <span class="kw">pub</span> <span class="kw">fn</span> new() -&gt; <span class="kw">Self</span> {
          <span class="dt">Vec</span> { buf: RawVec::new(), len: <span class="dv">0</span> }
      }
  
      <span class="co">// push/pop/insert/remove largely unchanged:</span>
      <span class="co">// * `self.ptr -&gt; self.ptr()`</span>
      <span class="co">// * `self.cap -&gt; self.cap()`</span>
      <span class="co">// * `self.grow -&gt; self.buf.grow()`</span>
  }
  
  <span class="kw">impl</span>&lt;T&gt; <span class="bu">Drop</span> <span class="kw">for</span> <span class="dt">Vec</span>&lt;T&gt; {
      <span class="kw">fn</span> drop(&amp;<span class="kw">mut</span> <span class="kw">self</span>) {
          <span class="kw">while</span> <span class="kw">let</span> <span class="cn">Some</span>(_) = <span class="kw">self</span>.pop() {}
          <span class="co">// deallocation is handled by RawVec</span>
      }
  }</code></pre></div>
  <p>And finally we can really simplify IntoIter:</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">struct</span> IntoIter&lt;T&gt; {
      _buf: RawVec&lt;T&gt;, <span class="co">// we don't actually care about this. Just need it to live.</span>
      start: *<span class="kw">const</span> T,
      end: *<span class="kw">const</span> T,
  }
  
  <span class="co">// next and next_back literally unchanged since they never referred to the buf</span>
  
  <span class="kw">impl</span>&lt;T&gt; <span class="bu">Drop</span> <span class="kw">for</span> IntoIter&lt;T&gt; {
      <span class="kw">fn</span> drop(&amp;<span class="kw">mut</span> <span class="kw">self</span>) {
          <span class="co">// only need to ensure all our elements are read;</span>
          <span class="co">// buffer will clean itself up afterwards.</span>
          <span class="kw">for</span> _ <span class="kw">in</span> &amp;<span class="kw">mut</span> *<span class="kw">self</span> {}
      }
  }
  
  <span class="kw">impl</span>&lt;T&gt; <span class="dt">Vec</span>&lt;T&gt; {
      <span class="kw">pub</span> <span class="kw">fn</span> into_iter(<span class="kw">self</span>) -&gt; IntoIter&lt;T&gt; {
          <span class="kw">unsafe</span> {
              <span class="co">// need to use ptr::read to unsafely move the buf out since it's</span>
              <span class="co">// not Copy, and Vec implements Drop (so we can't destructure it).</span>
              <span class="kw">let</span> buf = ptr::read(&amp;<span class="kw">self</span>.buf);
              <span class="kw">let</span> len = <span class="kw">self</span>.len;
              mem::forget(<span class="kw">self</span>);
  
              IntoIter {
                  start: *buf.ptr,
                  end: buf.ptr.offset(len <span class="kw">as</span> <span class="dt">isize</span>),
                  _buf: buf,
              }
          }
      }
  }</code></pre></div>
  <p>Much better.</p>
  </section>
  <section id="sec--vec-drain" class="level2">
  <h2>Drain</h2>
  <p>Let’s move on to Drain. Drain is largely the same as IntoIter, except that instead of consuming the Vec, it borrows the Vec and leaves its allocation untouched. For now we’ll only implement the “basic” full-range version.</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">use</span> std::marker::PhantomData;
  
  <span class="kw">struct</span> Drain&lt;<span class="ot">'a</span>, T: <span class="ot">'a</span>&gt; {
      <span class="co">// Need to bound the lifetime here, so we do it with `&amp;'a mut Vec&lt;T&gt;`</span>
      <span class="co">// because that's semantically what we contain. We're &quot;just&quot; calling</span>
      <span class="co">// `pop()` and `remove(0)`.</span>
      vec: PhantomData&lt;&amp;<span class="ot">'a</span> <span class="kw">mut</span> <span class="dt">Vec</span>&lt;T&gt;&gt;
      start: *<span class="kw">const</span> T,
      end: *<span class="kw">const</span> T,
  }
  
  <span class="kw">impl</span>&lt;<span class="ot">'a</span>, T&gt; <span class="bu">Iterator</span> <span class="kw">for</span> Drain&lt;<span class="ot">'a</span>, T&gt; {
      <span class="kw">type</span> Item = T;
      <span class="kw">fn</span> next(&amp;<span class="kw">mut</span> <span class="kw">self</span>) -&gt; <span class="dt">Option</span>&lt;T&gt; {
          <span class="kw">if</span> <span class="kw">self</span>.start == <span class="kw">self</span>.end {
              <span class="cn">None</span></code></pre></div>
  <p>– wait, this is seeming familiar. Let’s do some more compression. Both IntoIter and Drain have the exact same structure, let’s just factor it out.</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">struct</span> RawValIter&lt;T&gt; {
      start: *<span class="kw">const</span> T,
      end: *<span class="kw">const</span> T,
  }
  
  <span class="kw">impl</span>&lt;T&gt; RawValIter&lt;T&gt; {
      <span class="co">// unsafe to construct because it has no associated lifetimes.</span>
      <span class="co">// This is necessary to store a RawValIter in the same struct as</span>
      <span class="co">// its actual allocation. OK since it's a private implementation</span>
      <span class="co">// detail.</span>
      <span class="kw">unsafe</span> <span class="kw">fn</span> new(slice: &amp;[T]) -&gt; <span class="kw">Self</span> {
          RawValIter {
              start: slice.as_ptr(),
              end: <span class="kw">if</span> slice.len() == <span class="dv">0</span> {
                  <span class="co">// if `len = 0`, then this is not actually allocated memory.</span>
                  <span class="co">// Need to avoid offsetting because that will give wrong</span>
                  <span class="co">// information to LLVM via GEP.</span>
                  slice.as_ptr()
              } <span class="kw">else</span> {
                  slice.as_ptr().offset(slice.len() <span class="kw">as</span> <span class="dt">isize</span>)
              }
          }
      }
  }
  
  <span class="co">// Iterator and DoubleEndedIterator impls identical to IntoIter.</span></code></pre></div>
  <p>And IntoIter becomes the following:</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">pub</span> <span class="kw">struct</span> IntoIter&lt;T&gt; {
      _buf: RawVec&lt;T&gt;, <span class="co">// we don't actually care about this. Just need it to live.</span>
      iter: RawValIter&lt;T&gt;,
  }
  
  <span class="kw">impl</span>&lt;T&gt; <span class="bu">Iterator</span> <span class="kw">for</span> IntoIter&lt;T&gt; {
      <span class="kw">type</span> Item = T;
      <span class="kw">fn</span> next(&amp;<span class="kw">mut</span> <span class="kw">self</span>) -&gt; <span class="dt">Option</span>&lt;T&gt; { <span class="kw">self</span>.iter.next() }
      <span class="kw">fn</span> size_hint(&amp;<span class="kw">self</span>) -&gt; (<span class="dt">usize</span>, <span class="dt">Option</span>&lt;<span class="dt">usize</span>&gt;) { <span class="kw">self</span>.iter.size_hint() }
  }
  
  <span class="kw">impl</span>&lt;T&gt; <span class="bu">DoubleEndedIterator</span> <span class="kw">for</span> IntoIter&lt;T&gt; {
      <span class="kw">fn</span> next_back(&amp;<span class="kw">mut</span> <span class="kw">self</span>) -&gt; <span class="dt">Option</span>&lt;T&gt; { <span class="kw">self</span>.iter.next_back() }
  }
  
  <span class="kw">impl</span>&lt;T&gt; <span class="bu">Drop</span> <span class="kw">for</span> IntoIter&lt;T&gt; {
      <span class="kw">fn</span> drop(&amp;<span class="kw">mut</span> <span class="kw">self</span>) {
          <span class="kw">for</span> _ <span class="kw">in</span> &amp;<span class="kw">mut</span> <span class="kw">self</span>.iter {}
      }
  }
  
  <span class="kw">impl</span>&lt;T&gt; <span class="dt">Vec</span>&lt;T&gt; {
      <span class="kw">pub</span> <span class="kw">fn</span> into_iter(<span class="kw">self</span>) -&gt; IntoIter&lt;T&gt; {
          <span class="kw">unsafe</span> {
              <span class="kw">let</span> iter = RawValIter::new(&amp;<span class="kw">self</span>);
  
              <span class="kw">let</span> buf = ptr::read(&amp;<span class="kw">self</span>.buf);
              mem::forget(<span class="kw">self</span>);
  
              IntoIter {
                  iter: iter,
                  _buf: buf,
              }
          }
      }
  }</code></pre></div>
  <p>Note that I’ve left a few quirks in this design to make upgrading Drain to work with arbitrary subranges a bit easier. In particular we <em>could</em> have RawValIter drain itself on drop, but that won’t work right for a more complex Drain. We also take a slice to simplify Drain initialization.</p>
  <p>Alright, now Drain is really easy:</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">use</span> std::marker::PhantomData;
  
  <span class="kw">pub</span> <span class="kw">struct</span> Drain&lt;<span class="ot">'a</span>, T: <span class="ot">'a</span>&gt; {
      vec: PhantomData&lt;&amp;<span class="ot">'a</span> <span class="kw">mut</span> <span class="dt">Vec</span>&lt;T&gt;&gt;,
      iter: RawValIter&lt;T&gt;,
  }
  
  <span class="kw">impl</span>&lt;<span class="ot">'a</span>, T&gt; <span class="bu">Iterator</span> <span class="kw">for</span> Drain&lt;<span class="ot">'a</span>, T&gt; {
      <span class="kw">type</span> Item = T;
      <span class="kw">fn</span> next(&amp;<span class="kw">mut</span> <span class="kw">self</span>) -&gt; <span class="dt">Option</span>&lt;T&gt; { <span class="kw">self</span>.iter.next() }
      <span class="kw">fn</span> size_hint(&amp;<span class="kw">self</span>) -&gt; (<span class="dt">usize</span>, <span class="dt">Option</span>&lt;<span class="dt">usize</span>&gt;) { <span class="kw">self</span>.iter.size_hint() }
  }
  
  <span class="kw">impl</span>&lt;<span class="ot">'a</span>, T&gt; <span class="bu">DoubleEndedIterator</span> <span class="kw">for</span> Drain&lt;<span class="ot">'a</span>, T&gt; {
      <span class="kw">fn</span> next_back(&amp;<span class="kw">mut</span> <span class="kw">self</span>) -&gt; <span class="dt">Option</span>&lt;T&gt; { <span class="kw">self</span>.iter.next_back() }
  }
  
  <span class="kw">impl</span>&lt;<span class="ot">'a</span>, T&gt; <span class="bu">Drop</span> <span class="kw">for</span> Drain&lt;<span class="ot">'a</span>, T&gt; {
      <span class="kw">fn</span> drop(&amp;<span class="kw">mut</span> <span class="kw">self</span>) {
          <span class="kw">for</span> _ <span class="kw">in</span> &amp;<span class="kw">mut</span> <span class="kw">self</span>.iter {}
      }
  }
  
  <span class="kw">impl</span>&lt;T&gt; <span class="dt">Vec</span>&lt;T&gt; {
      <span class="kw">pub</span> <span class="kw">fn</span> drain(&amp;<span class="kw">mut</span> <span class="kw">self</span>) -&gt; Drain&lt;T&gt; {
          <span class="kw">unsafe</span> {
              <span class="kw">let</span> iter = RawValIter::new(&amp;<span class="kw">self</span>);
  
              <span class="co">// this is a mem::forget safety thing. If Drain is forgotten, we just</span>
              <span class="co">// leak the whole Vec's contents. Also we need to do this *eventually*</span>
              <span class="co">// anyway, so why not do it now?</span>
              <span class="kw">self</span>.len = <span class="dv">0</span>;
  
              Drain {
                  iter: iter,
                  vec: PhantomData,
              }
          }
      }
  }</code></pre></div>
  <p>For more details on the <code>mem::forget</code> problem, see the <a href="#sec--leaking">section on leaks</a>.</p>
  </section>
  <section id="sec--vec-zsts" class="level2">
  <h2>Handling Zero-Sized Types</h2>
  <p>It’s time. We’re going to fight the specter that is zero-sized types. Safe Rust <em>never</em> needs to care about this, but Vec is very intensive on raw pointers and raw allocations, which are exactly the two things that care about zero-sized types. We need to be careful of two things:</p>
  <ul>
  <li>The raw allocator API has undefined behavior if you pass in 0 for an allocation size.</li>
  <li>raw pointer offsets are no-ops for zero-sized types, which will break our C-style pointer iterator.</li>
  </ul>
  <p>Thankfully we abstracted out pointer-iterators and allocating handling into RawValIter and RawVec respectively. How mysteriously convenient.</p>
  <section id="allocating-zero-sized-types" class="level4">
  <h4>Allocating Zero-Sized Types</h4>
  <p>So if the allocator API doesn’t support zero-sized allocations, what on earth do we store as our allocation? Why, <code>heap::EMPTY</code> of course! Almost every operation with a ZST is a no-op since ZSTs have exactly one value, and therefore no state needs to be considered to store or load them. This actually extends to <code>ptr::read</code> and <code>ptr::write</code>: they won’t actually look at the pointer at all. As such we never need to change the pointer.</p>
  <p>Note however that our previous reliance on running out of memory before overflow is no longer valid with zero-sized types. We must explicitly guard against capacity overflow for zero-sized types.</p>
  <p>Due to our current architecture, all this means is writing 3 guards, one in each method of RawVec.</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">impl</span>&lt;T&gt; RawVec&lt;T&gt; {
      <span class="kw">fn</span> new() -&gt; <span class="kw">Self</span> {
          <span class="kw">unsafe</span> {
              <span class="co">// !0 is usize::MAX. This branch should be stripped at compile time.</span>
              <span class="kw">let</span> cap = <span class="kw">if</span> mem::size_of::&lt;T&gt;() == <span class="dv">0</span> { !<span class="dv">0</span> } <span class="kw">else</span> { <span class="dv">0</span> };
  
              <span class="co">// heap::EMPTY doubles as &quot;unallocated&quot; and &quot;zero-sized allocation&quot;</span>
              RawVec { ptr: Unique::new(heap::EMPTY <span class="kw">as</span> *<span class="kw">mut</span> T), cap: cap }
          }
      }
  
      <span class="kw">fn</span> grow(&amp;<span class="kw">mut</span> <span class="kw">self</span>) {
          <span class="kw">unsafe</span> {
              <span class="kw">let</span> elem_size = mem::size_of::&lt;T&gt;();
  
              <span class="co">// since we set the capacity to usize::MAX when elem_size is</span>
              <span class="co">// 0, getting to here necessarily means the Vec is overfull.</span>
              <span class="pp">assert!</span>(elem_size != <span class="dv">0</span>, <span class="st">&quot;capacity overflow&quot;</span>);
  
              <span class="kw">let</span> align = mem::align_of::&lt;T&gt;();
  
              <span class="kw">let</span> (new_cap, ptr) = <span class="kw">if</span> <span class="kw">self</span>.cap == <span class="dv">0</span> {
                  <span class="kw">let</span> ptr = heap::allocate(elem_size, align);
                  (<span class="dv">1</span>, ptr)
              } <span class="kw">else</span> {
                  <span class="kw">let</span> new_cap = <span class="dv">2</span> * <span class="kw">self</span>.cap;
                  <span class="kw">let</span> ptr = heap::reallocate(*<span class="kw">self</span>.ptr <span class="kw">as</span> *<span class="kw">mut</span> _,
                                              <span class="kw">self</span>.cap * elem_size,
                                              new_cap * elem_size,
                                              align);
                  (new_cap, ptr)
              };
  
              <span class="co">// If allocate or reallocate fail, we'll get `null` back</span>
              <span class="kw">if</span> ptr.is_null() { oom() }
  
              <span class="kw">self</span>.ptr = Unique::new(ptr <span class="kw">as</span> *<span class="kw">mut</span> _);
              <span class="kw">self</span>.cap = new_cap;
          }
      }
  }
  
  <span class="kw">impl</span>&lt;T&gt; <span class="bu">Drop</span> <span class="kw">for</span> RawVec&lt;T&gt; {
      <span class="kw">fn</span> drop(&amp;<span class="kw">mut</span> <span class="kw">self</span>) {
          <span class="kw">let</span> elem_size = mem::size_of::&lt;T&gt;();
  
          <span class="co">// don't free zero-sized allocations, as they were never allocated.</span>
          <span class="kw">if</span> <span class="kw">self</span>.cap != <span class="dv">0</span> &amp;&amp; elem_size != <span class="dv">0</span> {
              <span class="kw">let</span> align = mem::align_of::&lt;T&gt;();
  
              <span class="kw">let</span> num_bytes = elem_size * <span class="kw">self</span>.cap;
              <span class="kw">unsafe</span> {
                  heap::deallocate(*<span class="kw">self</span>.ptr <span class="kw">as</span> *<span class="kw">mut</span> _, num_bytes, align);
              }
          }
      }
  }</code></pre></div>
  <p>That’s it. We support pushing and popping zero-sized types now. Our iterators (that aren’t provided by slice Deref) are still busted, though.</p>
  </section>
  <section id="iterating-zero-sized-types" class="level4">
  <h4>Iterating Zero-Sized Types</h4>
  <p>Zero-sized offsets are no-ops. This means that our current design will always initialize <code>start</code> and <code>end</code> as the same value, and our iterators will yield nothing. The current solution to this is to cast the pointers to integers, increment, and then cast them back:</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">impl</span>&lt;T&gt; RawValIter&lt;T&gt; {
      <span class="kw">unsafe</span> <span class="kw">fn</span> new(slice: &amp;[T]) -&gt; <span class="kw">Self</span> {
          RawValIter {
              start: slice.as_ptr(),
              end: <span class="kw">if</span> mem::size_of::&lt;T&gt;() == <span class="dv">0</span> {
                  ((slice.as_ptr() <span class="kw">as</span> <span class="dt">usize</span>) + slice.len()) <span class="kw">as</span> *<span class="kw">const</span> _
              } <span class="kw">else</span> <span class="kw">if</span> slice.len() == <span class="dv">0</span> {
                  slice.as_ptr()
              } <span class="kw">else</span> {
                  slice.as_ptr().offset(slice.len() <span class="kw">as</span> <span class="dt">isize</span>)
              }
          }
      }
  }</code></pre></div>
  <p>Now we have a different bug. Instead of our iterators not running at all, our iterators now run <em>forever</em>. We need to do the same trick in our iterator impls. Also, our size_hint computation code will divide by 0 for ZSTs. Since we’ll basically be treating the two pointers as if they point to bytes, we’ll just map size 0 to divide by 1.</p>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="kw">impl</span>&lt;T&gt; <span class="bu">Iterator</span> <span class="kw">for</span> RawValIter&lt;T&gt; {
      <span class="kw">type</span> Item = T;
      <span class="kw">fn</span> next(&amp;<span class="kw">mut</span> <span class="kw">self</span>) -&gt; <span class="dt">Option</span>&lt;T&gt; {
          <span class="kw">if</span> <span class="kw">self</span>.start == <span class="kw">self</span>.end {
              <span class="cn">None</span>
          } <span class="kw">else</span> {
              <span class="kw">unsafe</span> {
                  <span class="kw">let</span> result = ptr::read(<span class="kw">self</span>.start);
                  <span class="kw">self</span>.start = <span class="kw">if</span> mem::size_of::&lt;T&gt;() == <span class="dv">0</span> {
                      (<span class="kw">self</span>.start <span class="kw">as</span> <span class="dt">usize</span> + <span class="dv">1</span>) <span class="kw">as</span> *<span class="kw">const</span> _
                  } <span class="kw">else</span> {
                      <span class="kw">self</span>.start.offset(<span class="dv">1</span>)
                  };
                  <span class="cn">Some</span>(result)
              }
          }
      }
  
      <span class="kw">fn</span> size_hint(&amp;<span class="kw">self</span>) -&gt; (<span class="dt">usize</span>, <span class="dt">Option</span>&lt;<span class="dt">usize</span>&gt;) {
          <span class="kw">let</span> elem_size = mem::size_of::&lt;T&gt;();
          <span class="kw">let</span> len = (<span class="kw">self</span>.end <span class="kw">as</span> <span class="dt">usize</span> - <span class="kw">self</span>.start <span class="kw">as</span> <span class="dt">usize</span>)
                    / <span class="kw">if</span> elem_size == <span class="dv">0</span> { <span class="dv">1</span> } <span class="kw">else</span> { elem_size };
          (len, <span class="cn">Some</span>(len))
      }
  }
  
  <span class="kw">impl</span>&lt;T&gt; <span class="bu">DoubleEndedIterator</span> <span class="kw">for</span> RawValIter&lt;T&gt; {
      <span class="kw">fn</span> next_back(&amp;<span class="kw">mut</span> <span class="kw">self</span>) -&gt; <span class="dt">Option</span>&lt;T&gt; {
          <span class="kw">if</span> <span class="kw">self</span>.start == <span class="kw">self</span>.end {
              <span class="cn">None</span>
          } <span class="kw">else</span> {
              <span class="kw">unsafe</span> {
                  <span class="kw">self</span>.end = <span class="kw">if</span> mem::size_of::&lt;T&gt;() == <span class="dv">0</span> {
                      (<span class="kw">self</span>.end <span class="kw">as</span> <span class="dt">usize</span> - <span class="dv">1</span>) <span class="kw">as</span> *<span class="kw">const</span> _
                  } <span class="kw">else</span> {
                      <span class="kw">self</span>.end.offset(-<span class="dv">1</span>)
                  };
                  <span class="cn">Some</span>(ptr::read(<span class="kw">self</span>.end))
              }
          }
      }
  }</code></pre></div>
  <p>And that’s it. Iteration works!</p>
  </section>
  </section>
  <section id="sec--vec-final" class="level2">
  <h2>Final Code</h2>
  <div class="sourceCode"><pre class="sourceCode rust"><code class="sourceCode rust"><span class="at">#![</span>feature<span class="at">(</span>unique<span class="at">)]</span>
  <span class="at">#![</span>feature<span class="at">(</span>alloc<span class="at">,</span> heap_api<span class="at">)]</span>
  
  <span class="kw">extern</span> <span class="kw">crate</span> alloc;
  
  <span class="kw">use</span> std::ptr::{Unique, <span class="kw">self</span>};
  <span class="kw">use</span> std::mem;
  <span class="kw">use</span> std::ops::{Deref, DerefMut};
  <span class="kw">use</span> std::marker::PhantomData;
  
  <span class="kw">use</span> alloc::heap;
  
  <span class="kw">struct</span> RawVec&lt;T&gt; {
      ptr: Unique&lt;T&gt;,
      cap: <span class="dt">usize</span>,
  }
  
  <span class="kw">impl</span>&lt;T&gt; RawVec&lt;T&gt; {
      <span class="kw">fn</span> new() -&gt; <span class="kw">Self</span> {
          <span class="kw">unsafe</span> {
              <span class="co">// !0 is usize::MAX. This branch should be stripped at compile time.</span>
              <span class="kw">let</span> cap = <span class="kw">if</span> mem::size_of::&lt;T&gt;() == <span class="dv">0</span> { !<span class="dv">0</span> } <span class="kw">else</span> { <span class="dv">0</span> };
  
              <span class="co">// heap::EMPTY doubles as &quot;unallocated&quot; and &quot;zero-sized allocation&quot;</span>
              RawVec { ptr: Unique::new(heap::EMPTY <span class="kw">as</span> *<span class="kw">mut</span> T), cap: cap }
          }
      }
  
      <span class="kw">fn</span> grow(&amp;<span class="kw">mut</span> <span class="kw">self</span>) {
          <span class="kw">unsafe</span> {
              <span class="kw">let</span> elem_size = mem::size_of::&lt;T&gt;();
  
              <span class="co">// since we set the capacity to usize::MAX when elem_size is</span>
              <span class="co">// 0, getting to here necessarily means the Vec is overfull.</span>
              <span class="pp">assert!</span>(elem_size != <span class="dv">0</span>, <span class="st">&quot;capacity overflow&quot;</span>);
  
              <span class="kw">let</span> align = mem::align_of::&lt;T&gt;();
  
              <span class="kw">let</span> (new_cap, ptr) = <span class="kw">if</span> <span class="kw">self</span>.cap == <span class="dv">0</span> {
                  <span class="kw">let</span> ptr = heap::allocate(elem_size, align);
                  (<span class="dv">1</span>, ptr)
              } <span class="kw">else</span> {
                  <span class="kw">let</span> new_cap = <span class="dv">2</span> * <span class="kw">self</span>.cap;
                  <span class="kw">let</span> ptr = heap::reallocate(*<span class="kw">self</span>.ptr <span class="kw">as</span> *<span class="kw">mut</span> _,
                                              <span class="kw">self</span>.cap * elem_size,
                                              new_cap * elem_size,
                                              align);
                  (new_cap, ptr)
              };
  
              <span class="co">// If allocate or reallocate fail, we'll get `null` back</span>
              <span class="kw">if</span> ptr.is_null() { oom() }
  
              <span class="kw">self</span>.ptr = Unique::new(ptr <span class="kw">as</span> *<span class="kw">mut</span> _);
              <span class="kw">self</span>.cap = new_cap;
          }
      }
  }
  
  <span class="kw">impl</span>&lt;T&gt; <span class="bu">Drop</span> <span class="kw">for</span> RawVec&lt;T&gt; {
      <span class="kw">fn</span> drop(&amp;<span class="kw">mut</span> <span class="kw">self</span>) {
          <span class="kw">let</span> elem_size = mem::size_of::&lt;T&gt;();
          <span class="kw">if</span> <span class="kw">self</span>.cap != <span class="dv">0</span> &amp;&amp; elem_size != <span class="dv">0</span> {
              <span class="kw">let</span> align = mem::align_of::&lt;T&gt;();
  
              <span class="kw">let</span> num_bytes = elem_size * <span class="kw">self</span>.cap;
              <span class="kw">unsafe</span> {
                  heap::deallocate(*<span class="kw">self</span>.ptr <span class="kw">as</span> *<span class="kw">mut</span> _, num_bytes, align);
              }
          }
      }
  }
  
  
  
  
  
  <span class="kw">pub</span> <span class="kw">struct</span> <span class="dt">Vec</span>&lt;T&gt; {
      buf: RawVec&lt;T&gt;,
      len: <span class="dt">usize</span>,
  }
  
  <span class="kw">impl</span>&lt;T&gt; <span class="dt">Vec</span>&lt;T&gt; {
      <span class="kw">fn</span> ptr(&amp;<span class="kw">self</span>) -&gt; *<span class="kw">mut</span> T { *<span class="kw">self</span>.buf.ptr }
  
      <span class="kw">fn</span> cap(&amp;<span class="kw">self</span>) -&gt; <span class="dt">usize</span> { <span class="kw">self</span>.buf.cap }
  
      <span class="kw">pub</span> <span class="kw">fn</span> new() -&gt; <span class="kw">Self</span> {
          <span class="dt">Vec</span> { buf: RawVec::new(), len: <span class="dv">0</span> }
      }
      <span class="kw">pub</span> <span class="kw">fn</span> push(&amp;<span class="kw">mut</span> <span class="kw">self</span>, elem: T) {
          <span class="kw">if</span> <span class="kw">self</span>.len == <span class="kw">self</span>.cap() { <span class="kw">self</span>.buf.grow(); }
  
          <span class="kw">unsafe</span> {
              ptr::write(<span class="kw">self</span>.ptr().offset(<span class="kw">self</span>.len <span class="kw">as</span> <span class="dt">isize</span>), elem);
          }
  
          <span class="co">// Can't fail, we'll OOM first.</span>
          <span class="kw">self</span>.len += <span class="dv">1</span>;
      }
  
      <span class="kw">pub</span> <span class="kw">fn</span> pop(&amp;<span class="kw">mut</span> <span class="kw">self</span>) -&gt; <span class="dt">Option</span>&lt;T&gt; {
          <span class="kw">if</span> <span class="kw">self</span>.len == <span class="dv">0</span> {
              <span class="cn">None</span>
          } <span class="kw">else</span> {
              <span class="kw">self</span>.len -= <span class="dv">1</span>;
              <span class="kw">unsafe</span> {
                  <span class="cn">Some</span>(ptr::read(<span class="kw">self</span>.ptr().offset(<span class="kw">self</span>.len <span class="kw">as</span> <span class="dt">isize</span>)))
              }
          }
      }
  
      <span class="kw">pub</span> <span class="kw">fn</span> insert(&amp;<span class="kw">mut</span> <span class="kw">self</span>, index: <span class="dt">usize</span>, elem: T) {
          <span class="pp">assert!</span>(index &lt;= <span class="kw">self</span>.len, <span class="st">&quot;index out of bounds&quot;</span>);
          <span class="kw">if</span> <span class="kw">self</span>.cap() == <span class="kw">self</span>.len { <span class="kw">self</span>.buf.grow(); }
  
          <span class="kw">unsafe</span> {
              <span class="kw">if</span> index &lt; <span class="kw">self</span>.len {
                  ptr::copy(<span class="kw">self</span>.ptr().offset(index <span class="kw">as</span> <span class="dt">isize</span>),
                            <span class="kw">self</span>.ptr().offset(index <span class="kw">as</span> <span class="dt">isize</span> + <span class="dv">1</span>),
                            <span class="kw">self</span>.len - index);
              }
              ptr::write(<span class="kw">self</span>.ptr().offset(index <span class="kw">as</span> <span class="dt">isize</span>), elem);
              <span class="kw">self</span>.len += <span class="dv">1</span>;
          }
      }
  
      <span class="kw">pub</span> <span class="kw">fn</span> remove(&amp;<span class="kw">mut</span> <span class="kw">self</span>, index: <span class="dt">usize</span>) -&gt; T {
          <span class="pp">assert!</span>(index &lt; <span class="kw">self</span>.len, <span class="st">&quot;index out of bounds&quot;</span>);
          <span class="kw">unsafe</span> {
              <span class="kw">self</span>.len -= <span class="dv">1</span>;
              <span class="kw">let</span> result = ptr::read(<span class="kw">self</span>.ptr().offset(index <span class="kw">as</span> <span class="dt">isize</span>));
              ptr::copy(<span class="kw">self</span>.ptr().offset(index <span class="kw">as</span> <span class="dt">isize</span> + <span class="dv">1</span>),
                        <span class="kw">self</span>.ptr().offset(index <span class="kw">as</span> <span class="dt">isize</span>),
                        <span class="kw">self</span>.len - index);
              result
          }
      }
  
      <span class="kw">pub</span> <span class="kw">fn</span> into_iter(<span class="kw">self</span>) -&gt; IntoIter&lt;T&gt; {
          <span class="kw">unsafe</span> {
              <span class="kw">let</span> iter = RawValIter::new(&amp;<span class="kw">self</span>);
              <span class="kw">let</span> buf = ptr::read(&amp;<span class="kw">self</span>.buf);
              mem::forget(<span class="kw">self</span>);
  
              IntoIter {
                  iter: iter,
                  _buf: buf,
              }
          }
      }
  
      <span class="kw">pub</span> <span class="kw">fn</span> drain(&amp;<span class="kw">mut</span> <span class="kw">self</span>) -&gt; Drain&lt;T&gt; {
          <span class="kw">unsafe</span> {
              <span class="kw">let</span> iter = RawValIter::new(&amp;<span class="kw">self</span>);
  
              <span class="co">// this is a mem::forget safety thing. If Drain is forgotten, we just</span>
              <span class="co">// leak the whole Vec's contents. Also we need to do this *eventually*</span>
              <span class="co">// anyway, so why not do it now?</span>
              <span class="kw">self</span>.len = <span class="dv">0</span>;
  
              Drain {
                  iter: iter,
                  vec: PhantomData,
              }
          }
      }
  }
  
  <span class="kw">impl</span>&lt;T&gt; <span class="bu">Drop</span> <span class="kw">for</span> <span class="dt">Vec</span>&lt;T&gt; {
      <span class="kw">fn</span> drop(&amp;<span class="kw">mut</span> <span class="kw">self</span>) {
          <span class="kw">while</span> <span class="kw">let</span> <span class="cn">Some</span>(_) = <span class="kw">self</span>.pop() {}
          <span class="co">// allocation is handled by RawVec</span>
      }
  }
  
  <span class="kw">impl</span>&lt;T&gt; Deref <span class="kw">for</span> <span class="dt">Vec</span>&lt;T&gt; {
      <span class="kw">type</span> Target = [T];
      <span class="kw">fn</span> deref(&amp;<span class="kw">self</span>) -&gt; &amp;[T] {
          <span class="kw">unsafe</span> {
              ::std::slice::from_raw_parts(<span class="kw">self</span>.ptr(), <span class="kw">self</span>.len)
          }
      }
  }
  
  <span class="kw">impl</span>&lt;T&gt; DerefMut <span class="kw">for</span> <span class="dt">Vec</span>&lt;T&gt; {
      <span class="kw">fn</span> deref_mut(&amp;<span class="kw">mut</span> <span class="kw">self</span>) -&gt; &amp;<span class="kw">mut</span> [T] {
          <span class="kw">unsafe</span> {
              ::std::slice::from_raw_parts_mut(<span class="kw">self</span>.ptr(), <span class="kw">self</span>.len)
          }
      }
  }
  
  
  
  
  
  <span class="kw">struct</span> RawValIter&lt;T&gt; {
      start: *<span class="kw">const</span> T,
      end: *<span class="kw">const</span> T,
  }
  
  <span class="kw">impl</span>&lt;T&gt; RawValIter&lt;T&gt; {
      <span class="kw">unsafe</span> <span class="kw">fn</span> new(slice: &amp;[T]) -&gt; <span class="kw">Self</span> {
          RawValIter {
              start: slice.as_ptr(),
              end: <span class="kw">if</span> mem::size_of::&lt;T&gt;() == <span class="dv">0</span> {
                  ((slice.as_ptr() <span class="kw">as</span> <span class="dt">usize</span>) + slice.len()) <span class="kw">as</span> *<span class="kw">const</span> _
              } <span class="kw">else</span> <span class="kw">if</span> slice.len() == <span class="dv">0</span> {
                  slice.as_ptr()
              } <span class="kw">else</span> {
                  slice.as_ptr().offset(slice.len() <span class="kw">as</span> <span class="dt">isize</span>)
              }
          }
      }
  }
  
  <span class="kw">impl</span>&lt;T&gt; <span class="bu">Iterator</span> <span class="kw">for</span> RawValIter&lt;T&gt; {
      <span class="kw">type</span> Item = T;
      <span class="kw">fn</span> next(&amp;<span class="kw">mut</span> <span class="kw">self</span>) -&gt; <span class="dt">Option</span>&lt;T&gt; {
          <span class="kw">if</span> <span class="kw">self</span>.start == <span class="kw">self</span>.end {
              <span class="cn">None</span>
          } <span class="kw">else</span> {
              <span class="kw">unsafe</span> {
                  <span class="kw">let</span> result = ptr::read(<span class="kw">self</span>.start);
                  <span class="kw">self</span>.start = <span class="kw">if</span> mem::size_of::&lt;T&gt;() == <span class="dv">0</span> {
                      (<span class="kw">self</span>.start <span class="kw">as</span> <span class="dt">usize</span> + <span class="dv">1</span>) <span class="kw">as</span> *<span class="kw">const</span> _
                  } <span class="kw">else</span> {
                      <span class="kw">self</span>.start.offset(<span class="dv">1</span>)
                  };
                  <span class="cn">Some</span>(result)
              }
          }
      }
  
      <span class="kw">fn</span> size_hint(&amp;<span class="kw">self</span>) -&gt; (<span class="dt">usize</span>, <span class="dt">Option</span>&lt;<span class="dt">usize</span>&gt;) {
          <span class="kw">let</span> elem_size = mem::size_of::&lt;T&gt;();
          <span class="kw">let</span> len = (<span class="kw">self</span>.end <span class="kw">as</span> <span class="dt">usize</span> - <span class="kw">self</span>.start <span class="kw">as</span> <span class="dt">usize</span>)
                    / <span class="kw">if</span> elem_size == <span class="dv">0</span> { <span class="dv">1</span> } <span class="kw">else</span> { elem_size };
          (len, <span class="cn">Some</span>(len))
      }
  }
  
  <span class="kw">impl</span>&lt;T&gt; <span class="bu">DoubleEndedIterator</span> <span class="kw">for</span> RawValIter&lt;T&gt; {
      <span class="kw">fn</span> next_back(&amp;<span class="kw">mut</span> <span class="kw">self</span>) -&gt; <span class="dt">Option</span>&lt;T&gt; {
          <span class="kw">if</span> <span class="kw">self</span>.start == <span class="kw">self</span>.end {
              <span class="cn">None</span>
          } <span class="kw">else</span> {
              <span class="kw">unsafe</span> {
                  <span class="kw">self</span>.end = <span class="kw">if</span> mem::size_of::&lt;T&gt;() == <span class="dv">0</span> {
                      (<span class="kw">self</span>.end <span class="kw">as</span> <span class="dt">usize</span> - <span class="dv">1</span>) <span class="kw">as</span> *<span class="kw">const</span> _
                  } <span class="kw">else</span> {
                      <span class="kw">self</span>.end.offset(-<span class="dv">1</span>)
                  };
                  <span class="cn">Some</span>(ptr::read(<span class="kw">self</span>.end))
              }
          }
      }
  }
  
  
  
  
  <span class="kw">pub</span> <span class="kw">struct</span> IntoIter&lt;T&gt; {
      _buf: RawVec&lt;T&gt;, <span class="co">// we don't actually care about this. Just need it to live.</span>
      iter: RawValIter&lt;T&gt;,
  }
  
  <span class="kw">impl</span>&lt;T&gt; <span class="bu">Iterator</span> <span class="kw">for</span> IntoIter&lt;T&gt; {
      <span class="kw">type</span> Item = T;
      <span class="kw">fn</span> next(&amp;<span class="kw">mut</span> <span class="kw">self</span>) -&gt; <span class="dt">Option</span>&lt;T&gt; { <span class="kw">self</span>.iter.next() }
      <span class="kw">fn</span> size_hint(&amp;<span class="kw">self</span>) -&gt; (<span class="dt">usize</span>, <span class="dt">Option</span>&lt;<span class="dt">usize</span>&gt;) { <span class="kw">self</span>.iter.size_hint() }
  }
  
  <span class="kw">impl</span>&lt;T&gt; <span class="bu">DoubleEndedIterator</span> <span class="kw">for</span> IntoIter&lt;T&gt; {
      <span class="kw">fn</span> next_back(&amp;<span class="kw">mut</span> <span class="kw">self</span>) -&gt; <span class="dt">Option</span>&lt;T&gt; { <span class="kw">self</span>.iter.next_back() }
  }
  
  <span class="kw">impl</span>&lt;T&gt; <span class="bu">Drop</span> <span class="kw">for</span> IntoIter&lt;T&gt; {
      <span class="kw">fn</span> drop(&amp;<span class="kw">mut</span> <span class="kw">self</span>) {
          <span class="kw">for</span> _ <span class="kw">in</span> &amp;<span class="kw">mut</span> *<span class="kw">self</span> {}
      }
  }
  
  
  
  
  <span class="kw">pub</span> <span class="kw">struct</span> Drain&lt;<span class="ot">'a</span>, T: <span class="ot">'a</span>&gt; {
      vec: PhantomData&lt;&amp;<span class="ot">'a</span> <span class="kw">mut</span> <span class="dt">Vec</span>&lt;T&gt;&gt;,
      iter: RawValIter&lt;T&gt;,
  }
  
  <span class="kw">impl</span>&lt;<span class="ot">'a</span>, T&gt; <span class="bu">Iterator</span> <span class="kw">for</span> Drain&lt;<span class="ot">'a</span>, T&gt; {
      <span class="kw">type</span> Item = T;
      <span class="kw">fn</span> next(&amp;<span class="kw">mut</span> <span class="kw">self</span>) -&gt; <span class="dt">Option</span>&lt;T&gt; { <span class="kw">self</span>.iter.next_back() }
      <span class="kw">fn</span> size_hint(&amp;<span class="kw">self</span>) -&gt; (<span class="dt">usize</span>, <span class="dt">Option</span>&lt;<span class="dt">usize</span>&gt;) { <span class="kw">self</span>.iter.size_hint() }
  }
  
  <span class="kw">impl</span>&lt;<span class="ot">'a</span>, T&gt; <span class="bu">DoubleEndedIterator</span> <span class="kw">for</span> Drain&lt;<span class="ot">'a</span>, T&gt; {
      <span class="kw">fn</span> next_back(&amp;<span class="kw">mut</span> <span class="kw">self</span>) -&gt; <span class="dt">Option</span>&lt;T&gt; { <span class="kw">self</span>.iter.next_back() }
  }
  
  <span class="kw">impl</span>&lt;<span class="ot">'a</span>, T&gt; <span class="bu">Drop</span> <span class="kw">for</span> Drain&lt;<span class="ot">'a</span>, T&gt; {
      <span class="kw">fn</span> drop(&amp;<span class="kw">mut</span> <span class="kw">self</span>) {
          <span class="co">// pre-drain the iter</span>
          <span class="kw">for</span> _ <span class="kw">in</span> &amp;<span class="kw">mut</span> <span class="kw">self</span>.iter {}
      }
  }
  
  <span class="co">/// Abort the process, we're out of memory!</span>
  <span class="co">///</span>
  <span class="co">/// In practice this is probably dead code on most OSes</span>
  <span class="kw">fn</span> oom() {
      ::std::process::exit(-<span class="dv">9999</span>);
  }</code></pre></div>
  </section>
  </section>
  <section id="sec--arc-and-mutex" class="level1">
  <h1>Implementing Arc and Mutex</h1>
  <p>Knowing the theory is all fine and good, but the <em>best</em> way to understand something is to use it. To better understand atomics and interior mutability, we’ll be implementing versions of the standard library’s Arc and Mutex types.</p>
  <p>TODO: ALL OF THIS OMG</p>
  </section>
</article>

</body>
</html>
