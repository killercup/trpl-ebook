% \documentclass[12pt]{article}
\documentclass[a4paper,]{book}

  \usepackage{lmodern}


\usepackage[a4paper]{geometry}

\usepackage{graphicx}

\usepackage{longtable}
\usepackage{booktabs}
\usepackage[htt]{hyphenat}

\usepackage{amssymb}

% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{\usepackage{microtype}}{}

\ifxetex
  \usepackage[setpagesize=false, % page size defined by xetex
              unicode=false, % unicode breaks when used with xetex
              xetex]{hyperref}
\else
  \usepackage[unicode=true]{hyperref}
\fi

% Break URLs in a few more places. (For breaking lines, not functionality!)
% cf. http://tex.stackexchange.com/questions/3033/forcing-linebreaks-in-url
\expandafter\def\expandafter\UrlBreaks\expandafter{\UrlBreaks%  save the current one
  \do\*\do\-\do\~\do\'\do\"\do\-}

\hypersetup{breaklinks=true,
            bookmarks=true,
            pdfauthor={The Rust Team},
            pdftitle={The Rustonomicon},
            colorlinks=false,
            citecolor=blue,
            urlcolor=blue,
            linkcolor=magenta,
            pdfborder={0 0 0}}
\urlstyle{same}  % don't use monospace font for urls

\renewcommand*{\hypertarget}[3][\ar]{%
  \def\ar{#2}%
  \label{#1}%
  #3}

\renewcommand*{\hyperlink}[2]{%
 #2 (\autoref{#1}, page~\pageref{#1})}

\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \else % if luatex or xelatex
  \ifxetex
    \usepackage{mathspec}
    \usepackage{xltxtra,xunicode}
    \usepackage{xeCJK}
    \setCJKmainfont{IPAexMincho}
  \else
    \usepackage{fontspec}
  \fi
  \defaultfontfeatures{Mapping=tex-text,Scale=MatchLowercase}
  \newcommand{\euro}{â‚¬}

  
  
      \setmonofont[Mapping=tex-ansi]{DejaVu Sans Mono}
  
  \fi

\setlength{\emergencystretch}{3em}  % prevent overfull lines

% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{\usepackage{microtype}}{}


\usepackage{xcolor}

  \usepackage{color}
  \usepackage{fancyvrb}
  \newcommand{\VerbBar}{|}
  \newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
  \DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
  % Add ',fontsize=\small' for more characters per line
  \usepackage{framed}
  \definecolor{shadecolor}{RGB}{248,248,248}
  \newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
  \newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{{#1}}}}
  \newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{{#1}}}
  \newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{{#1}}}
  \newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{{#1}}}
  \newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{{#1}}}
  \newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{{#1}}}
  \newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{{#1}}}
  \newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{{#1}}}
  \newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{{#1}}}
  \newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{{#1}}}
  \newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{{#1}}}
  \newcommand{\ImportTok}[1]{{#1}}
  \newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{{#1}}}}
  \newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{{#1}}}}}
  \newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{{#1}}}}}
  \newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{{#1}}}}}
  \newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{{#1}}}
  \newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{{#1}}}
  \newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{{#1}}}
  \newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{{#1}}}}
  \newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{{#1}}}}
  \newcommand{\BuiltInTok}[1]{{#1}}
  \newcommand{\ExtensionTok}[1]{{#1}}
  \newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{{#1}}}}
  \newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{{#1}}}
  \newcommand{\RegionMarkerTok}[1]{{#1}}
  \newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{{#1}}}}}
  \newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{{#1}}}}}
  \newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{{#1}}}
  \newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{{#1}}}}
  \newcommand{\NormalTok}[1]{{#1}}

  \usepackage{fancyvrb}

  % Make links footnotes instead of hotlinks:
  \renewcommand{\href}[2]{#2\footnote{\url{#1}}}

  \VerbatimFootnotes % allows verbatim text in footnotes

\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
\setlength{\emergencystretch}{3em}  % prevent overfull lines

\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{0}

\usepackage[font={footnotesize,sf}]{caption}

% Redefines (sub)paragraphs to behave more like sections
\ifx\paragraph\undefined\else
\let\oldparagraph\paragraph
\renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
\let\oldsubparagraph\subparagraph
\renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

% - - -
% Make it fancy

% Headers and page numbering
\usepackage{fancyhdr}

% Set figure legends and captions to be smaller sized sans serif font
\usepackage[font={footnotesize,sf}]{caption}

% Chapter styling
\usepackage[grey]{quotchap}
\makeatletter
\renewcommand*{\chapnumfont}{%
  \thispagestyle{empty}
  \usefont{T1}{\@defaultcnfont}{b}{n}\fontsize{80}{100}\selectfont% Default: 100/130
  \color{chaptergrey}%
}
\makeatother

% - - -

  \title{The Rustonomicon}
  \author{The Rust Team}
  \date{2016-06-02}

\begin{document}

  \maketitle



{
  \hypersetup{linkcolor=black}
  \setcounter{tocdepth}{2}
  \tableofcontents
  \newpage
}

\chapter{Introduction}\label{introduction}

\subsubsection{The Dark Arts of Advanced and Unsafe Rust
Programming}\label{the-dark-arts-of-advanced-and-unsafe-rust-programming}

\textbf{NOTE: This is a draft document, and may contain serious errors}

\begin{quote}
Instead of the programs I had hoped for, there came only a shuddering
blackness and ineffable loneliness; and I saw at last a fearful truth
which no one had ever dared to breathe before --- the unwhisperable
secret of secrets --- The fact that this language of stone and stridor
is not a sentient perpetuation of Rust as London is of Old London and
Paris of Old Paris, but that it is in fact quite unsafe, its sprawling
body imperfectly embalmed and infested with queer animate things which
have nothing to do with it as it was in compilation.
\end{quote}

This book digs into all the awful details that are necessary to
understand in order to write correct Unsafe Rust programs. Due to the
nature of this problem, it may lead to unleashing untold horrors that
shatter your psyche into a billion infinitesimal fragments of despair.

Should you wish a long and happy career of writing Rust programs, you
should turn back now and forget you ever saw this book. It is not
necessary. However if you intend to write unsafe code -- or just want to
dig into the guts of the language -- this book contains invaluable
information.

Unlike \href{http://doc.rust-lang.org/book/}{The Book} we will be
assuming considerable prior knowledge. In particular, you should be
comfortable with basic systems programming and Rust. If you don't feel
comfortable with these topics, you should consider
\href{http://doc.rust-lang.org/book/}{reading The Book} first. Though we
will not be assuming that you have, and will take care to occasionally
give a refresher on the basics where appropriate. You can skip straight
to this book if you want; just know that we won't be explaining
everything from the ground up.

To be clear, this book goes into deep detail. We're going to dig into
exception-safety, pointer aliasing, memory models, and even some
type-theory. We will also be spending a lot of time talking about the
different kinds of safety and guarantees.

\chapter{Meet Safe and Unsafe}\label{sec--meet-safe-and-unsafe}

Programmers in safe ``high-level'' languages face a fundamental dilemma.
On one hand, it would be \emph{really} great to just say what you want
and not worry about how it's done. On the other hand, that can lead to
unacceptably poor performance. It may be necessary to drop down to less
clear or idiomatic practices to get the performance characteristics you
want. Or maybe you just throw up your hands in disgust and decide to
shell out to an implementation in a less sugary-wonderful \emph{unsafe}
language.

Worse, when you want to talk directly to the operating system, you
\emph{have} to talk to an unsafe language: \emph{C}. C is ever-present
and unavoidable. It's the lingua-franca of the programming world. Even
other safe languages generally expose C interfaces for the world at
large! Regardless of why you're doing it, as soon as your program starts
talking to C it stops being safe.

With that said, Rust is \emph{totally} a safe programming language.

Well, Rust \emph{has} a safe programming language. Let's step back a
bit.

Rust can be thought of as being composed of two programming languages:
\emph{Safe Rust} and \emph{Unsafe Rust}. Safe Rust is For Reals Totally
Safe. Unsafe Rust, unsurprisingly, is \emph{not} For Reals Totally Safe.
In fact, Unsafe Rust lets you do some really crazy unsafe things.

Safe Rust is the \emph{true} Rust programming language. If all you do is
write Safe Rust, you will never have to worry about type-safety or
memory-safety. You will never endure a null or dangling pointer, or any
of that Undefined Behavior nonsense.

\emph{That's totally awesome.}

The standard library also gives you enough utilities out-of-the-box that
you'll be able to write awesome high-performance applications and
libraries in pure idiomatic Safe Rust.

But maybe you want to talk to another language. Maybe you're writing a
low-level abstraction not exposed by the standard library. Maybe you're
\emph{writing} the standard library (which is written entirely in Rust).
Maybe you need to do something the type-system doesn't understand and
just \emph{frob some dang bits}. Maybe you need Unsafe Rust.

Unsafe Rust is exactly like Safe Rust with all the same rules and
semantics. However Unsafe Rust lets you do some \emph{extra} things that
are Definitely Not Safe.

The only things that are different in Unsafe Rust are that you can:

\begin{itemize}
\tightlist
\item
  Dereference raw pointers
\item
  Call \texttt{unsafe} functions (including C functions, intrinsics, and
  the raw allocator)
\item
  Implement \texttt{unsafe} traits
\item
  Mutate statics
\end{itemize}

That's it. The reason these operations are relegated to Unsafe is that
misusing any of these things will cause the ever dreaded Undefined
Behavior. Invoking Undefined Behavior gives the compiler full rights to
do arbitrarily bad things to your program. You definitely \emph{should
not} invoke Undefined Behavior.

Unlike C, Undefined Behavior is pretty limited in scope in Rust. All the
core language cares about is preventing the following things:

\begin{itemize}
\tightlist
\item
  Dereferencing null or dangling pointers
\item
  Reading \protect\hyperlink{sec--uninitialized}{uninitialized memory}
\item
  Breaking the {[}pointer aliasing rules{]}
\item
  Producing invalid primitive values:

  \begin{itemize}
  \tightlist
  \item
    dangling/null references
  \item
    a \texttt{bool} that isn't 0 or 1
  \item
    an undefined \texttt{enum} discriminant
  \item
    a \texttt{char} outside the ranges {[}0x0, 0xD7FF{]} and {[}0xE000,
    0x10FFFF{]}
  \item
    A non-utf8 \texttt{str}
  \end{itemize}
\item
  Unwinding into another language
\item
  Causing a \protect\hyperlink{sec--races}{data race}
\end{itemize}

That's it. That's all the causes of Undefined Behavior baked into Rust.
Of course, unsafe functions and traits are free to declare arbitrary
other constraints that a program must maintain to avoid Undefined
Behavior. However, generally violations of these constraints will just
transitively lead to one of the above problems. Some additional
constraints may also derive from compiler intrinsics that make special
assumptions about how code can be optimized.

Rust is otherwise quite permissive with respect to other dubious
operations. Rust considers it ``safe'' to:

\begin{itemize}
\tightlist
\item
  Deadlock
\item
  Have a \protect\hyperlink{sec--races}{race condition}
\item
  Leak memory
\item
  Fail to call destructors
\item
  Overflow integers
\item
  Abort the program
\item
  Delete the production database
\end{itemize}

However any program that actually manages to do such a thing is
\emph{probably} incorrect. Rust provides lots of tools to make these
things rare, but these problems are considered impractical to
categorically prevent.

\section{How Safe and Unsafe Interact}\label{sec--safe-unsafe-meaning}

So what's the relationship between Safe and Unsafe Rust? How do they
interact?

Rust models the separation between Safe and Unsafe Rust with the
\texttt{unsafe} keyword, which can be thought as a sort of \emph{foreign
function interface} (FFI) between Safe and Unsafe Rust. This is the
magic behind why we can say Safe Rust is a safe language: all the scary
unsafe bits are relegated exclusively to FFI \emph{just like every other
safe language}.

However because one language is a subset of the other, the two can be
cleanly intermixed as long as the boundary between Safe and Unsafe Rust
is denoted with the \texttt{unsafe} keyword. No need to write headers,
initialize runtimes, or any of that other FFI boiler-plate.

There are several places \texttt{unsafe} can appear in Rust today, which
can largely be grouped into two categories:

\begin{itemize}
\tightlist
\item
  There are unchecked contracts here. To declare you understand this, I
  require you to write \texttt{unsafe} elsewhere:

  \begin{itemize}
  \tightlist
  \item
    On functions, \texttt{unsafe} is declaring the function to be unsafe
    to call. Users of the function must check the documentation to
    determine what this means, and then have to write \texttt{unsafe}
    somewhere to identify that they're aware of the danger.
  \item
    On trait declarations, \texttt{unsafe} is declaring that
    \emph{implementing} the trait is an unsafe operation, as it has
    contracts that other unsafe code is free to trust blindly. (More on
    this below.)
  \end{itemize}
\item
  I am declaring that I have, to the best of my knowledge, adhered to
  the unchecked contracts:

  \begin{itemize}
  \tightlist
  \item
    On trait implementations, \texttt{unsafe} is declaring that the
    contract of the \texttt{unsafe} trait has been upheld.
  \item
    On blocks, \texttt{unsafe} is declaring any unsafety from an unsafe
    operation within to be handled, and therefore the parent function is
    safe.
  \end{itemize}
\end{itemize}

There is also \texttt{\#{[}unsafe\_no\_drop\_flag{]}}, which is a
special case that exists for historical reasons and is in the process of
being phased out. See the section on
\protect\hyperlink{sec--drop-flags}{drop flags} for details.

Some examples of unsafe functions:

\begin{itemize}
\tightlist
\item
  \texttt{slice::get\_unchecked} will perform unchecked indexing,
  allowing memory safety to be freely violated.
\item
  every raw pointer to sized type has intrinsic \texttt{offset} method
  that invokes Undefined Behavior if it is not ``in bounds'' as defined
  by LLVM.
\item
  \texttt{mem::transmute} reinterprets some value as having the given
  type, bypassing type safety in arbitrary ways. (see {[}conversions{]}
  for details)
\item
  All FFI functions are \texttt{unsafe} because they can do arbitrary
  things. C being an obvious culprit, but generally any language can do
  something that Rust isn't happy about.
\end{itemize}

As of Rust 1.0 there are exactly two unsafe traits:

\begin{itemize}
\tightlist
\item
  \texttt{Send} is a marker trait (it has no actual API) that promises
  implementors are safe to send (move) to another thread.
\item
  \texttt{Sync} is a marker trait that promises that threads can safely
  share implementors through a shared reference.
\end{itemize}

The need for unsafe traits boils down to the fundamental property of
safe code:

\textbf{No matter how completely awful Safe code is, it can't cause
Undefined Behavior.}

This means that Unsafe Rust, \textbf{the royal vanguard of Undefined
Behavior}, has to be \emph{super paranoid} about generic safe code. To
be clear, Unsafe Rust is totally free to trust specific safe code.
Anything else would degenerate into infinite spirals of paranoid
despair. In particular it's generally regarded as ok to trust the
standard library to be correct. \texttt{std} is effectively an extension
of the language, and you really just have to trust the language. If
\texttt{std} fails to uphold the guarantees it declares, then it's
basically a language bug.

That said, it would be best to minimize \emph{needlessly} relying on
properties of concrete safe code. Bugs happen! Of course, I must
reinforce that this is only a concern for Unsafe code. Safe code can
blindly trust anyone and everyone as far as basic memory-safety is
concerned.

On the other hand, safe traits are free to declare arbitrary contracts,
but because implementing them is safe, unsafe code can't trust those
contracts to actually be upheld. This is different from the concrete
case because \emph{anyone} can randomly implement the interface. There
is something fundamentally different about trusting a particular piece
of code to be correct, and trusting \emph{all the code that will ever be
written} to be correct.

For instance Rust has \texttt{PartialOrd} and \texttt{Ord} traits to try
to differentiate between types which can ``just'' be compared, and those
that actually implement a total ordering. Pretty much every API that
wants to work with data that can be compared wants Ord data. For
instance, a sorted map like BTreeMap \emph{doesn't even make sense} for
partially ordered types. If you claim to implement Ord for a type, but
don't actually provide a proper total ordering, BTreeMap will get
\emph{really confused} and start making a total mess of itself. Data
that is inserted may be impossible to find!

But that's okay. BTreeMap is safe, so it guarantees that even if you
give it a completely garbage Ord implementation, it will still do
something \emph{safe}. You won't start reading uninitialized or
unallocated memory. In fact, BTreeMap manages to not actually lose any
of your data. When the map is dropped, all the destructors will be
successfully called! Hooray!

However BTreeMap is implemented using a modest spoonful of Unsafe Rust
(most collections are). That means that it's not necessarily
\emph{trivially true} that a bad Ord implementation will make BTreeMap
behave safely. BTreeMap must be sure not to rely on Ord \emph{where
safety is at stake}. Ord is provided by safe code, and safety is not
safe code's responsibility to uphold.

But wouldn't it be grand if there was some way for Unsafe to trust some
trait contracts \emph{somewhere}? This is the problem that unsafe traits
tackle: by marking \emph{the trait itself} as unsafe to implement,
unsafe code can trust the implementation to uphold the trait's contract.
Although the trait implementation may be incorrect in arbitrary other
ways.

For instance, given a hypothetical UnsafeOrd trait, this is technically
a valid implementation:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{unsafe} \KeywordTok{impl} \NormalTok{UnsafeOrd }\KeywordTok{for} \NormalTok{MyType \{}
    \KeywordTok{fn} \NormalTok{cmp(&}\KeywordTok{self}\NormalTok{, other: &}\KeywordTok{Self}\NormalTok{) -> Ordering \{}
        \NormalTok{Ordering::Equal}
    \NormalTok{\}}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

But it's probably not the implementation you want.

Rust has traditionally avoided making traits unsafe because it makes
Unsafe pervasive, which is not desirable. The reason Send and Sync are
unsafe is because thread safety is a \emph{fundamental property} that
unsafe code cannot possibly hope to defend against in the same way it
would defend against a bad Ord implementation. The only way to possibly
defend against thread-unsafety would be to \emph{not use threading at
all}. Making every load and store atomic isn't even sufficient, because
it's possible for complex invariants to exist between disjoint locations
in memory. For instance, the pointer and capacity of a Vec must be in
sync.

Even concurrent paradigms that are traditionally regarded as Totally
Safe like message passing implicitly rely on some notion of thread
safety -- are you really message-passing if you pass a pointer? Send and
Sync therefore require some fundamental level of trust that Safe code
can't provide, so they must be unsafe to implement. To help obviate the
pervasive unsafety that this would introduce, Send (resp. Sync) is
automatically derived for all types composed only of Send (resp. Sync)
values. 99\% of types are Send and Sync, and 99\% of those never
actually say it (the remaining 1\% is overwhelmingly synchronization
primitives).

\section{Working with Unsafe}\label{sec--working-with-unsafe}

Rust generally only gives us the tools to talk about Unsafe Rust in a
scoped and binary manner. Unfortunately, reality is significantly more
complicated than that. For instance, consider the following toy
function:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{fn} \NormalTok{index(idx: }\DataTypeTok{usize}\NormalTok{, arr: &[}\DataTypeTok{u8}\NormalTok{]) -> }\DataTypeTok{Option}\NormalTok{<}\DataTypeTok{u8}\NormalTok{> \{}
    \KeywordTok{if} \NormalTok{idx < arr.len() \{}
        \KeywordTok{unsafe} \NormalTok{\{}
            \ConstantTok{Some}\NormalTok{(*arr.get_unchecked(idx))}
        \NormalTok{\}}
    \NormalTok{\} }\KeywordTok{else} \NormalTok{\{}
        \ConstantTok{None}
    \NormalTok{\}}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

Clearly, this function is safe. We check that the index is in bounds,
and if it is, index into the array in an unchecked manner. But even in
such a trivial function, the scope of the unsafe block is questionable.
Consider changing the \texttt{\textless{}} to a \texttt{\textless{}=}:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{fn} \NormalTok{index(idx: }\DataTypeTok{usize}\NormalTok{, arr: &[}\DataTypeTok{u8}\NormalTok{]) -> }\DataTypeTok{Option}\NormalTok{<}\DataTypeTok{u8}\NormalTok{> \{}
    \KeywordTok{if} \NormalTok{idx <= arr.len() \{}
        \KeywordTok{unsafe} \NormalTok{\{}
            \ConstantTok{Some}\NormalTok{(*arr.get_unchecked(idx))}
        \NormalTok{\}}
    \NormalTok{\} }\KeywordTok{else} \NormalTok{\{}
        \ConstantTok{None}
    \NormalTok{\}}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

This program is now unsound, and yet \emph{we only modified safe code}.
This is the fundamental problem of safety: it's non-local. The soundness
of our unsafe operations necessarily depends on the state established by
otherwise ``safe'' operations.

Safety is modular in the sense that opting into unsafety doesn't require
you to consider arbitrary other kinds of badness. For instance, doing an
unchecked index into a slice doesn't mean you suddenly need to worry
about the slice being null or containing uninitialized memory. Nothing
fundamentally changes. However safety \emph{isn't} modular in the sense
that programs are inherently stateful and your unsafe operations may
depend on arbitrary other state.

Trickier than that is when we get into actual statefulness. Consider a
simple implementation of \texttt{Vec}:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{use} \NormalTok{std::ptr;}

\CommentTok{// Note this definition is insufficient. See the section on implementing Vec.}
\KeywordTok{pub} \KeywordTok{struct} \DataTypeTok{Vec}\NormalTok{<T> \{}
    \NormalTok{ptr: *}\KeywordTok{mut} \NormalTok{T,}
    \NormalTok{len: }\DataTypeTok{usize}\NormalTok{,}
    \NormalTok{cap: }\DataTypeTok{usize}\NormalTok{,}
\NormalTok{\}}

\CommentTok{// Note this implementation does not correctly handle zero-sized types.}
\CommentTok{// We currently live in a nice imaginary world of only positive fixed-size}
\CommentTok{// types.}
\KeywordTok{impl}\NormalTok{<T> }\DataTypeTok{Vec}\NormalTok{<T> \{}
    \KeywordTok{pub} \KeywordTok{fn} \NormalTok{push(&}\KeywordTok{mut} \KeywordTok{self}\NormalTok{, elem: T) \{}
        \KeywordTok{if} \KeywordTok{self}\NormalTok{.len == }\KeywordTok{self}\NormalTok{.cap \{}
            \CommentTok{// not important for this example}
            \KeywordTok{self}\NormalTok{.reallocate();}
        \NormalTok{\}}
        \KeywordTok{unsafe} \NormalTok{\{}
            \NormalTok{ptr::write(}\KeywordTok{self}\NormalTok{.ptr.offset(}\KeywordTok{self}\NormalTok{.len }\KeywordTok{as} \DataTypeTok{isize}\NormalTok{), elem);}
            \KeywordTok{self}\NormalTok{.len += }\DecValTok{1}\NormalTok{;}
        \NormalTok{\}}
    \NormalTok{\}}

    \NormalTok{# }\KeywordTok{fn} \NormalTok{reallocate(&}\KeywordTok{mut} \KeywordTok{self}\NormalTok{) \{ \}}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

This code is simple enough to reasonably audit and verify. Now consider
adding the following method:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{fn} \NormalTok{make_room(&}\KeywordTok{mut} \KeywordTok{self}\NormalTok{) \{}
    \CommentTok{// grow the capacity}
    \KeywordTok{self}\NormalTok{.cap += }\DecValTok{1}\NormalTok{;}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

This code is 100\% Safe Rust but it is also completely unsound. Changing
the capacity violates the invariants of Vec (that \texttt{cap} reflects
the allocated space in the Vec). This is not something the rest of Vec
can guard against. It \emph{has} to trust the capacity field because
there's no way to verify it.

\texttt{unsafe} does more than pollute a whole function: it pollutes a
whole \emph{module}. Generally, the only bullet-proof way to limit the
scope of unsafe code is at the module boundary with privacy.

However this works \emph{perfectly}. The existence of
\texttt{make\_room} is \emph{not} a problem for the soundness of Vec
because we didn't mark it as public. Only the module that defines this
function can call it. Also, \texttt{make\_room} directly accesses the
private fields of Vec, so it can only be written in the same module as
Vec.

It is therefore possible for us to write a completely safe abstraction
that relies on complex invariants. This is \emph{critical} to the
relationship between Safe Rust and Unsafe Rust. We have already seen
that Unsafe code must trust \emph{some} Safe code, but can't trust
\emph{generic} Safe code. It can't trust an arbitrary implementor of a
trait or any function that was passed to it to be well-behaved in a way
that safe code doesn't care about.

However if unsafe code couldn't prevent client safe code from messing
with its state in arbitrary ways, safety would be a lost cause.
Thankfully, it \emph{can} prevent arbitrary code from messing with
critical state due to privacy.

Safety lives!

\chapter{Data Layout}\label{sec--data}

Low-level programming cares a lot about data layout. It's a big deal. It
also pervasively influences the rest of the language, so we're going to
start by digging into how data is represented in Rust.

\section{repr(Rust)}\label{sec--repr-rust}

First and foremost, all types have an alignment specified in bytes. The
alignment of a type specifies what addresses are valid to store the
value at. A value of alignment \texttt{n} must only be stored at an
address that is a multiple of \texttt{n}. So alignment 2 means you must
be stored at an even address, and 1 means that you can be stored
anywhere. Alignment is at least 1, and always a power of 2. Most
primitives are generally aligned to their size, although this is
platform-specific behavior. In particular, on x86 \texttt{u64} and
\texttt{f64} may be only aligned to 32 bits.

A type's size must always be a multiple of its alignment. This ensures
that an array of that type may always be indexed by offsetting by a
multiple of its size. Note that the size and alignment of a type may not
be known statically in the case of
\protect\hyperlink{dynamically-sized-types-dsts}{dynamically sized
types}.

Rust gives you the following ways to lay out composite data:

\begin{itemize}
\tightlist
\item
  structs (named product types)
\item
  tuples (anonymous product types)
\item
  arrays (homogeneous product types)
\item
  enums (named sum types -- tagged unions)
\end{itemize}

An enum is said to be \emph{C-like} if none of its variants have
associated data.

Composite structures will have an alignment equal to the maximum of
their fields' alignment. Rust will consequently insert padding where
necessary to ensure that all fields are properly aligned and that the
overall type's size is a multiple of its alignment. For instance:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{struct} \NormalTok{A \{}
    \NormalTok{a: }\DataTypeTok{u8}\NormalTok{,}
    \NormalTok{b: }\DataTypeTok{u32}\NormalTok{,}
    \NormalTok{c: }\DataTypeTok{u16}\NormalTok{,}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

will be 32-bit aligned on an architecture that aligns these primitives
to their respective sizes. The whole struct will therefore have a size
that is a multiple of 32-bits. It will potentially become:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{struct} \NormalTok{A \{}
    \NormalTok{a: }\DataTypeTok{u8}\NormalTok{,}
    \NormalTok{_pad1: [}\DataTypeTok{u8}\NormalTok{; }\DecValTok{3}\NormalTok{], }\CommentTok{// to align `b`}
    \NormalTok{b: }\DataTypeTok{u32}\NormalTok{,}
    \NormalTok{c: }\DataTypeTok{u16}\NormalTok{,}
    \NormalTok{_pad2: [}\DataTypeTok{u8}\NormalTok{; }\DecValTok{2}\NormalTok{], }\CommentTok{// to make overall size multiple of 4}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

There is \emph{no indirection} for these types; all data is stored
within the struct, as you would expect in C. However with the exception
of arrays (which are densely packed and in-order), the layout of data is
not by default specified in Rust. Given the two following struct
definitions:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{struct} \NormalTok{A \{}
    \NormalTok{a: }\DataTypeTok{i32}\NormalTok{,}
    \NormalTok{b: }\DataTypeTok{u64}\NormalTok{,}
\NormalTok{\}}

\KeywordTok{struct} \NormalTok{B \{}
    \NormalTok{a: }\DataTypeTok{i32}\NormalTok{,}
    \NormalTok{b: }\DataTypeTok{u64}\NormalTok{,}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

Rust \emph{does} guarantee that two instances of A have their data laid
out in exactly the same way. However Rust \emph{does not} currently
guarantee that an instance of A has the same field ordering or padding
as an instance of B, though in practice there's no reason why they
wouldn't.

With A and B as written, this point would seem to be pedantic, but
several other features of Rust make it desirable for the language to
play with data layout in complex ways.

For instance, consider this struct:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{struct} \NormalTok{Foo<T, U> \{}
    \NormalTok{count: }\DataTypeTok{u16}\NormalTok{,}
    \NormalTok{data1: T,}
    \NormalTok{data2: U,}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

Now consider the monomorphizations of
\texttt{Foo\textless{}u32,\ u16\textgreater{}} and
\texttt{Foo\textless{}u16,\ u32\textgreater{}}. If Rust lays out the
fields in the order specified, we expect it to pad the values in the
struct to satisfy their alignment requirements. So if Rust didn't
reorder fields, we would expect it to produce the following:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{struct} \NormalTok{Foo<}\DataTypeTok{u16}\NormalTok{, }\DataTypeTok{u32}\NormalTok{> \{}
    \NormalTok{count: }\DataTypeTok{u16}\NormalTok{,}
    \NormalTok{data1: }\DataTypeTok{u16}\NormalTok{,}
    \NormalTok{data2: }\DataTypeTok{u32}\NormalTok{,}
\NormalTok{\}}

\KeywordTok{struct} \NormalTok{Foo<}\DataTypeTok{u32}\NormalTok{, }\DataTypeTok{u16}\NormalTok{> \{}
    \NormalTok{count: }\DataTypeTok{u16}\NormalTok{,}
    \NormalTok{_pad1: }\DataTypeTok{u16}\NormalTok{,}
    \NormalTok{data1: }\DataTypeTok{u32}\NormalTok{,}
    \NormalTok{data2: }\DataTypeTok{u16}\NormalTok{,}
    \NormalTok{_pad2: }\DataTypeTok{u16}\NormalTok{,}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

The latter case quite simply wastes space. An optimal use of space
therefore requires different monomorphizations to have \emph{different
field orderings}.

\textbf{Note: this is a hypothetical optimization that is not yet
implemented in Rust 1.0}

Enums make this consideration even more complicated. Naively, an enum
such as:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{enum} \NormalTok{Foo \{}
    \NormalTok{A(}\DataTypeTok{u32}\NormalTok{),}
    \NormalTok{B(}\DataTypeTok{u64}\NormalTok{),}
    \NormalTok{C(}\DataTypeTok{u8}\NormalTok{),}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

would be laid out as:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{struct} \NormalTok{FooRepr \{}
    \NormalTok{data: }\DataTypeTok{u64}\NormalTok{, }\CommentTok{// this is either a u64, u32, or u8 based on `tag`}
    \NormalTok{tag: }\DataTypeTok{u8}\NormalTok{,   }\CommentTok{// 0 = A, 1 = B, 2 = C}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

And indeed this is approximately how it would be laid out in general
(modulo the size and position of \texttt{tag}).

However there are several cases where such a representation is
inefficient. The classic case of this is Rust's ``null pointer
optimization'': an enum consisting of a single outer unit variant (e.g.
\texttt{None}) and a (potentially nested) non- nullable pointer variant
(e.g. \texttt{\&T}) makes the tag unnecessary, because a null pointer
value can safely be interpreted to mean that the unit variant is chosen
instead. The net result is that, for example,
\texttt{size\_of::\textless{}Option\textless{}\&T\textgreater{}\textgreater{}()\ ==\ size\_of::\textless{}\&T\textgreater{}()}.

There are many types in Rust that are, or contain, non-nullable pointers
such as \texttt{Box\textless{}T\textgreater{}},
\texttt{Vec\textless{}T\textgreater{}}, \texttt{String}, \texttt{\&T},
and \texttt{\&mut\ T}. Similarly, one can imagine nested enums pooling
their tags into a single discriminant, as they are by definition known
to have a limited range of valid values. In principle enums could use
fairly elaborate algorithms to cache bits throughout nested types with
special constrained representations. As such it is \emph{especially}
desirable that we leave enum layout unspecified today.

\section{Exotically Sized Types}\label{sec--exotic-sizes}

Most of the time, we think in terms of types with a fixed, positive
size. This is not always the case, however.

\hypertarget{dynamically-sized-types-dsts}{\subsection{Dynamically Sized
Types (DSTs)}\label{dynamically-sized-types-dsts}}

Rust in fact supports Dynamically Sized Types (DSTs): types without a
statically known size or alignment. On the surface, this is a bit
nonsensical: Rust \emph{must} know the size and alignment of something
in order to correctly work with it! In this regard, DSTs are not normal
types. Due to their lack of a statically known size, these types can
only exist behind some kind of pointer. Any pointer to a DST
consequently becomes a \emph{fat} pointer consisting of the pointer and
the information that ``completes'' them (more on this below).

There are two major DSTs exposed by the language: trait objects, and
slices.

A trait object represents some type that implements the traits it
specifies. The exact original type is \emph{erased} in favor of runtime
reflection with a vtable containing all the information necessary to use
the type. This is the information that completes a trait object: a
pointer to its vtable.

A slice is simply a view into some contiguous storage -- typically an
array or \texttt{Vec}. The information that completes a slice is just
the number of elements it points to.

Structs can actually store a single DST directly as their last field,
but this makes them a DST as well:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// Can't be stored on the stack directly}
\KeywordTok{struct} \NormalTok{Foo \{}
    \NormalTok{info: }\DataTypeTok{u32}\NormalTok{,}
    \NormalTok{data: [}\DataTypeTok{u8}\NormalTok{],}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\textbf{NOTE: \href{https://github.com/rust-lang/rust/issues/26403}{As
of Rust 1.0 struct DSTs are broken if the last field has a variable
position based on its alignment}.}

\subsection{Zero Sized Types (ZSTs)}\label{zero-sized-types-zsts}

Rust actually allows types to be specified that occupy no space:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{struct} \NormalTok{Foo; }\CommentTok{// No fields = no size}

\CommentTok{// All fields have no size = no size}
\KeywordTok{struct} \NormalTok{Baz \{}
    \NormalTok{foo: Foo,}
    \NormalTok{qux: (),      }\CommentTok{// empty tuple has no size}
    \NormalTok{baz: [}\DataTypeTok{u8}\NormalTok{; }\DecValTok{0}\NormalTok{], }\CommentTok{// empty array has no size}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

On their own, Zero Sized Types (ZSTs) are, for obvious reasons, pretty
useless. However as with many curious layout choices in Rust, their
potential is realized in a generic context: Rust largely understands
that any operation that produces or stores a ZST can be reduced to a
no-op. First off, storing it doesn't even make sense -- it doesn't
occupy any space. Also there's only one value of that type, so anything
that loads it can just produce it from the aether -- which is also a
no-op since it doesn't occupy any space.

One of the most extreme example's of this is Sets and Maps. Given a
\texttt{Map\textless{}Key,\ Value\textgreater{}}, it is common to
implement a \texttt{Set\textless{}Key\textgreater{}} as just a thin
wrapper around \texttt{Map\textless{}Key,\ UselessJunk\textgreater{}}.
In many languages, this would necessitate allocating space for
UselessJunk and doing work to store and load UselessJunk only to discard
it. Proving this unnecessary would be a difficult analysis for the
compiler.

However in Rust, we can just say that
\texttt{Set\textless{}Key\textgreater{}\ =\ Map\textless{}Key,\ ()\textgreater{}}.
Now Rust statically knows that every load and store is useless, and no
allocation has any size. The result is that the monomorphized code is
basically a custom implementation of a HashSet with none of the overhead
that HashMap would have to support values.

Safe code need not worry about ZSTs, but \emph{unsafe} code must be
careful about the consequence of types with no size. In particular,
pointer offsets are no-ops, and standard allocators (including jemalloc,
the one used by default in Rust) may return \texttt{nullptr} when a
zero-sized allocation is requested, which is indistinguishable from out
of memory.

\subsection{Empty Types}\label{empty-types}

Rust also enables types to be declared that \emph{cannot even be
instantiated}. These types can only be talked about at the type level,
and never at the value level. Empty types can be declared by specifying
an enum with no variants:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{enum} \NormalTok{Void \{\} }\CommentTok{// No variants = EMPTY}
\end{Highlighting}
\end{Shaded}

Empty types are even more marginal than ZSTs. The primary motivating
example for Void types is type-level unreachability. For instance,
suppose an API needs to return a Result in general, but a specific case
actually is infallible. It's actually possible to communicate this at
the type level by returning a
\texttt{Result\textless{}T,\ Void\textgreater{}}. Consumers of the API
can confidently unwrap such a Result knowing that it's \emph{statically
impossible} for this value to be an \texttt{Err}, as this would require
providing a value of type \texttt{Void}.

In principle, Rust can do some interesting analyses and optimizations
based on this fact. For instance,
\texttt{Result\textless{}T,\ Void\textgreater{}} could be represented as
just \texttt{T}, because the \texttt{Err} case doesn't actually exist.
The following \emph{could} also compile:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{enum} \NormalTok{Void \{\}}

\KeywordTok{let} \NormalTok{res: }\DataTypeTok{Result}\NormalTok{<}\DataTypeTok{u32}\NormalTok{, Void> = }\ConstantTok{Ok}\NormalTok{(}\DecValTok{0}\NormalTok{);}

\CommentTok{// Err doesn't exist anymore, so Ok is actually irrefutable.}
\KeywordTok{let} \ConstantTok{Ok}\NormalTok{(num) = res;}
\end{Highlighting}
\end{Shaded}

But neither of these tricks work today, so all Void types get you is the
ability to be confident that certain situations are statically
impossible.

One final subtle detail about empty types is that raw pointers to them
are actually valid to construct, but dereferencing them is Undefined
Behavior because that doesn't actually make sense. That is, you could
model C's \texttt{void\ *} type with \texttt{*const\ Void}, but this
doesn't necessarily gain anything over using e.g. \texttt{*const\ ()},
which \emph{is} safe to randomly dereference.

\section{Other reprs}\label{sec--other-reprs}

Rust allows you to specify alternative data layout strategies from the
default.

\subsection{repr(C)}\label{reprc}

This is the most important \texttt{repr}. It has fairly simple intent:
do what C does. The order, size, and alignment of fields is exactly what
you would expect from C or C++. Any type you expect to pass through an
FFI boundary should have \texttt{repr(C)}, as C is the lingua-franca of
the programming world. This is also necessary to soundly do more
elaborate tricks with data layout such as reinterpreting values as a
different type.

However, the interaction with Rust's more exotic data layout features
must be kept in mind. Due to its dual purpose as ``for FFI'' and ``for
layout control'', \texttt{repr(C)} can be applied to types that will be
nonsensical or problematic if passed through the FFI boundary.

\begin{itemize}
\item
  ZSTs are still zero-sized, even though this is not a standard behavior
  in C, and is explicitly contrary to the behavior of an empty type in
  C++, which still consumes a byte of space.
\item
  DSTs, tuples, and tagged unions are not a concept in C and as such are
  never FFI safe.
\item
  Tuple structs are like structs with regards to \texttt{repr(C)}, as
  the only difference from a struct is that the fields aren't named.
\item
  \textbf{If the type would have any
  \protect\hyperlink{sec--drop-flags}{drop flags}, they will still be
  added}
\item
  This is equivalent to one of \texttt{repr(u*)} (see the next section)
  for enums. The chosen size is the default enum size for the target
  platform's C ABI. Note that enum representation in C is implementation
  defined, so this is really a ``best guess''. In particular, this may
  be incorrect when the C code of interest is compiled with certain
  flags.
\end{itemize}

\subsection{repr(u8), repr(u16), repr(u32),
repr(u64)}\label{repru8-repru16-repru32-repru64}

These specify the size to make a C-like enum. If the discriminant
overflows the integer it has to fit in, it will produce a compile-time
error. You can manually ask Rust to allow this by setting the
overflowing element to explicitly be 0. However Rust will not allow you
to create an enum where two variants have the same discriminant.

On non-C-like enums, this will inhibit certain optimizations like the
null- pointer optimization.

These reprs have no effect on a struct.

\subsection{repr(packed)}\label{reprpacked}

\texttt{repr(packed)} forces Rust to strip any padding, and only align
the type to a byte. This may improve the memory footprint, but will
likely have other negative side-effects.

In particular, most architectures \emph{strongly} prefer values to be
aligned. This may mean the unaligned loads are penalized (x86), or even
fault (some ARM chips). For simple cases like directly loading or
storing a packed field, the compiler might be able to paper over
alignment issues with shifts and masks. However if you take a reference
to a packed field, it's unlikely that the compiler will be able to emit
code to avoid an unaligned load.

\textbf{\href{https://github.com/rust-lang/rust/issues/27060}{As of Rust
1.0 this can cause undefined behavior.}}

\texttt{repr(packed)} is not to be used lightly. Unless you have extreme
requirements, this should not be used.

This repr is a modifier on \texttt{repr(C)} and \texttt{repr(rust)}.

\hypertarget{sec--ownership}{\chapter{Ownership}\label{sec--ownership}}

Ownership is the breakout feature of Rust. It allows Rust to be
completely memory-safe and efficient, while avoiding garbage collection.
Before getting into the ownership system in detail, we will consider the
motivation of this design.

We will assume that you accept that garbage collection (GC) is not
always an optimal solution, and that it is desirable to manually manage
memory in some contexts. If you do not accept this, might I interest you
in a different language?

Regardless of your feelings on GC, it is pretty clearly a \emph{massive}
boon to making code safe. You never have to worry about things going
away \emph{too soon} (although whether you still wanted to be pointing
at that thing is a different issue\ldots{}). This is a pervasive problem
that C and C++ programs need to deal with. Consider this simple mistake
that all of us who have used a non-GC'd language have made at one point:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{fn} \NormalTok{as_str(data: &}\DataTypeTok{u32}\NormalTok{) -> &}\DataTypeTok{str} \NormalTok{\{}
    \CommentTok{// compute the string}
    \KeywordTok{let} \NormalTok{s = }\PreprocessorTok{format!}\NormalTok{(}\StringTok{"\{\}"}\NormalTok{, data);}

    \CommentTok{// OH NO! We returned a reference to something that}
    \CommentTok{// exists only in this function!}
    \CommentTok{// Dangling pointer! Use after free! Alas!}
    \CommentTok{// (this does not compile in Rust)}
    \NormalTok{&s}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

This is exactly what Rust's ownership system was built to solve. Rust
knows the scope in which the \texttt{\&s} lives, and as such can prevent
it from escaping. However this is a simple case that even a C compiler
could plausibly catch. Things get more complicated as code gets bigger
and pointers get fed through various functions. Eventually, a C compiler
will fall down and won't be able to perform sufficient escape analysis
to prove your code unsound. It will consequently be forced to accept
your program on the assumption that it is correct.

This will never happen to Rust. It's up to the programmer to prove to
the compiler that everything is sound.

Of course, Rust's story around ownership is much more complicated than
just verifying that references don't escape the scope of their referent.
That's because ensuring pointers are always valid is much more
complicated than this. For instance in this code,

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{let} \KeywordTok{mut} \NormalTok{data = }\PreprocessorTok{vec!}\NormalTok{[}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{];}
\CommentTok{// get an internal reference}
\KeywordTok{let} \NormalTok{x = &data[}\DecValTok{0}\NormalTok{];}

\CommentTok{// OH NO! `push` causes the backing storage of `data` to be reallocated.}
\CommentTok{// Dangling pointer! User after free! Alas!}
\CommentTok{// (this does not compile in Rust)}
\NormalTok{data.push(}\DecValTok{4}\NormalTok{);}

\PreprocessorTok{println!}\NormalTok{(}\StringTok{"\{\}"}\NormalTok{, x);}
\end{Highlighting}
\end{Shaded}

naive scope analysis would be insufficient to prevent this bug, because
\texttt{data} does in fact live as long as we needed. However it was
\emph{changed} while we had a reference into it. This is why Rust
requires any references to freeze the referent and its owners.

\section{References}\label{sec--references}

This section gives a high-level view of the memory model that \emph{all}
Rust programs must satisfy to be correct. Safe code is statically
verified to obey this model by the borrow checker. Unsafe code may go
above and beyond the borrow checker while still satisfying this model.
The borrow checker may also be extended to allow more programs to
compile, as long as this more fundamental model is satisfied.

There are two kinds of reference:

\begin{itemize}
\tightlist
\item
  Shared reference: \texttt{\&}
\item
  Mutable reference: \texttt{\&mut}
\end{itemize}

Which obey the following rules:

\begin{itemize}
\tightlist
\item
  A reference cannot outlive its referent
\item
  A mutable reference cannot be aliased
\end{itemize}

That's it. That's the whole model. Of course, we should probably define
what \emph{aliased} means. To define aliasing, we must define the notion
of \emph{paths} and \emph{liveness}.

\textbf{NOTE: The model that follows is generally agreed to be dubious
and have issues. It's ok-ish as an intuitive model, but fails to capture
the desired semantics. We leave this here to be able to use notions
introduced here in later sections. This will be significantly changed in
the future. TODO: do that.}

\subsection{Paths}\label{paths}

If all Rust had were values (no pointers), then every value would be
uniquely owned by a variable or composite structure. From this we
naturally derive a \emph{tree} of ownership. The stack itself is the
root of the tree, with every variable as its direct children. Each
variable's direct children would be their fields (if any), and so on.

From this view, every value in Rust has a unique \emph{path} in the tree
of ownership. Of particular interest are \emph{ancestors} and
\emph{descendants}: if \texttt{x} owns \texttt{y}, then \texttt{x} is an
ancestor of \texttt{y}, and \texttt{y} is a descendant of \texttt{x}.
Note that this is an inclusive relationship: \texttt{x} is a descendant
and ancestor of itself.

We can then define references as simply \emph{names} for paths. When you
create a reference, you're declaring that an ownership path exists to
this address of memory.

Tragically, plenty of data doesn't reside on the stack, and we must also
accommodate this. Globals and thread-locals are simple enough to model
as residing at the bottom of the stack (though we must be careful with
mutable globals). Data on the heap poses a different problem.

If all Rust had on the heap was data uniquely owned by a pointer on the
stack, then we could just treat such a pointer as a struct that owns the
value on the heap. Box, Vec, String, and HashMap, are examples of types
which uniquely own data on the heap.

Unfortunately, data on the heap is not \emph{always} uniquely owned. Rc
for instance introduces a notion of \emph{shared} ownership. Shared
ownership of a value means there is no unique path to it. A value with
no unique path limits what we can do with it.

In general, only shared references can be created to non-unique paths.
However mechanisms which ensure mutual exclusion may establish One True
Owner temporarily, establishing a unique path to that value (and
therefore all its children). If this is done, the value may be mutated.
In particular, a mutable reference can be taken.

The most common way to establish such a path is through \emph{interior
mutability}, in contrast to the \emph{inherited mutability} that
everything in Rust normally uses. Cell, RefCell, Mutex, and RWLock are
all examples of interior mutability types. These types provide exclusive
access through runtime restrictions.

An interesting case of this effect is Rc itself: if an Rc has refcount
1, then it is safe to mutate or even move its internals. Note however
that the refcount itself uses interior mutability.

In order to correctly communicate to the type system that a variable or
field of a struct can have interior mutability, it must be wrapped in an
UnsafeCell. This does not in itself make it safe to perform interior
mutability operations on that value. You still must yourself ensure that
mutual exclusion is upheld.

\subsection{Liveness}\label{liveness}

Note: Liveness is not the same thing as a \emph{lifetime}, which will be
explained in detail in the next section of this chapter.

Roughly, a reference is \emph{live} at some point in a program if it can
be dereferenced. Shared references are always live unless they are
literally unreachable (for instance, they reside in freed or leaked
memory). Mutable references can be reachable but \emph{not} live through
the process of \emph{reborrowing}.

A mutable reference can be reborrowed to either a shared or mutable
reference to one of its descendants. A reborrowed reference will only be
live again once all reborrows derived from it expire. For instance, a
mutable reference can be reborrowed to point to a field of its referent:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{let} \NormalTok{x = &}\KeywordTok{mut} \NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{);}
\NormalTok{\{}
    \CommentTok{// reborrow x to a subfield}
    \KeywordTok{let} \NormalTok{y = &}\KeywordTok{mut} \NormalTok{x.}\DecValTok{0}\NormalTok{;}
    \CommentTok{// y is now live, but x isn't}
    \NormalTok{*y = }\DecValTok{3}\NormalTok{;}
\NormalTok{\}}
\CommentTok{// y goes out of scope, so x is live again}
\NormalTok{*x = (}\DecValTok{5}\NormalTok{, }\DecValTok{7}\NormalTok{);}
\end{Highlighting}
\end{Shaded}

It is also possible to reborrow into \emph{multiple} mutable references,
as long as they are \emph{disjoint}: no reference is an ancestor of
another. Rust explicitly enables this to be done with disjoint struct
fields, because disjointness can be statically proven:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{let} \NormalTok{x = &}\KeywordTok{mut} \NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{);}
\NormalTok{\{}
    \CommentTok{// reborrow x to two disjoint subfields}
    \KeywordTok{let} \NormalTok{y = &}\KeywordTok{mut} \NormalTok{x.}\DecValTok{0}\NormalTok{;}
    \KeywordTok{let} \NormalTok{z = &}\KeywordTok{mut} \NormalTok{x.}\DecValTok{1}\NormalTok{;}

    \CommentTok{// y and z are now live, but x isn't}
    \NormalTok{*y = }\DecValTok{3}\NormalTok{;}
    \NormalTok{*z = }\DecValTok{4}\NormalTok{;}
\NormalTok{\}}
\CommentTok{// y and z go out of scope, so x is live again}
\NormalTok{*x = (}\DecValTok{5}\NormalTok{, }\DecValTok{7}\NormalTok{);}
\end{Highlighting}
\end{Shaded}

However it's often the case that Rust isn't sufficiently smart to prove
that multiple borrows are disjoint. \emph{This does not mean it is
fundamentally illegal to make such a borrow}, just that Rust isn't as
smart as you want.

To simplify things, we can model variables as a fake type of reference:
\emph{owned} references. Owned references have much the same semantics
as mutable references: they can be re-borrowed in a mutable or shared
manner, which makes them no longer live. Live owned references have the
unique property that they can be moved out of (though mutable references
\emph{can} be swapped out of). This power is only given to \emph{live}
owned references because moving its referent would of course invalidate
all outstanding references prematurely.

As a local lint against inappropriate mutation, only variables that are
marked as \texttt{mut} can be borrowed mutably.

It is interesting to note that Box behaves exactly like an owned
reference. It can be moved out of, and Rust understands it sufficiently
to reason about its paths like a normal variable.

\subsection{Aliasing}\label{aliasing}

With liveness and paths defined, we can now properly define
\emph{aliasing}:

\textbf{A mutable reference is aliased if there exists another live
reference to one of its ancestors or descendants.}

(If you prefer, you may also say the two live references alias
\emph{each other}. This has no semantic consequences, but is probably a
more useful notion when verifying the soundness of a construct.)

That's it. Super simple right? Except for the fact that it took us two
pages to define all of the terms in that definition. You know: Super.
Simple.

Actually it's a bit more complicated than that. In addition to
references, Rust has \emph{raw pointers}: \texttt{*const\ T} and
\texttt{*mut\ T}. Raw pointers have no inherent ownership or aliasing
semantics. As a result, Rust makes absolutely no effort to track that
they are used correctly, and they are wildly unsafe.

\textbf{It is an open question to what degree raw pointers have alias
semantics. However it is important for these definitions to be sound
that the existence of a raw pointer does not imply some kind of live
path.}

\section{Lifetimes}\label{sec--lifetimes}

Rust enforces these rules through \emph{lifetimes}. Lifetimes are
effectively just names for scopes somewhere in the program. Each
reference, and anything that contains a reference, is tagged with a
lifetime specifying the scope it's valid for.

Within a function body, Rust generally doesn't let you explicitly name
the lifetimes involved. This is because it's generally not really
necessary to talk about lifetimes in a local context; Rust has all the
information and can work out everything as optimally as possible. Many
anonymous scopes and temporaries that you would otherwise have to write
are often introduced to make your code Just Work.

However once you cross the function boundary, you need to start talking
about lifetimes. Lifetimes are denoted with an apostrophe:
\texttt{\textquotesingle{}a}, \texttt{\textquotesingle{}static}. To dip
our toes with lifetimes, we're going to pretend that we're actually
allowed to label scopes with lifetimes, and desugar the examples from
the start of this chapter.

Originally, our examples made use of \emph{aggressive} sugar -- high
fructose corn syrup even -- around scopes and lifetimes, because writing
everything out explicitly is \emph{extremely noisy}. All Rust code
relies on aggressive inference and elision of ``obvious'' things.

One particularly interesting piece of sugar is that each \texttt{let}
statement implicitly introduces a scope. For the most part, this doesn't
really matter. However it does matter for variables that refer to each
other. As a simple example, let's completely desugar this simple piece
of Rust code:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{let} \NormalTok{x = }\DecValTok{0}\NormalTok{;}
\KeywordTok{let} \NormalTok{y = &x;}
\KeywordTok{let} \NormalTok{z = &y;}
\end{Highlighting}
\end{Shaded}

The borrow checker always tries to minimize the extent of a lifetime, so
it will likely desugar to the following:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// NOTE: `'a: \{` and `&'b x` is not valid syntax!}
\OtherTok{'a}\NormalTok{: \{}
    \KeywordTok{let} \NormalTok{x: }\DataTypeTok{i32} \NormalTok{= }\DecValTok{0}\NormalTok{;}
    \OtherTok{'b}\NormalTok{: \{}
        \CommentTok{// lifetime used is 'b because that's good enough.}
        \KeywordTok{let} \NormalTok{y: &}\OtherTok{'b} \DataTypeTok{i32} \NormalTok{= &}\OtherTok{'b} \NormalTok{x;}
        \OtherTok{'c}\NormalTok{: \{}
            \CommentTok{// ditto on 'c}
            \KeywordTok{let} \NormalTok{z: &}\OtherTok{'c} \NormalTok{&}\OtherTok{'b} \DataTypeTok{i32} \NormalTok{= &}\OtherTok{'c} \NormalTok{y;}
        \NormalTok{\}}
    \NormalTok{\}}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

Wow. That's\ldots{} awful. Let's all take a moment to thank Rust for
making this easier.

Actually passing references to outer scopes will cause Rust to infer a
larger lifetime:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{let} \NormalTok{x = }\DecValTok{0}\NormalTok{;}
\KeywordTok{let} \NormalTok{z;}
\KeywordTok{let} \NormalTok{y = &x;}
\NormalTok{z = y;}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\OtherTok{'a}\NormalTok{: \{}
    \KeywordTok{let} \NormalTok{x: }\DataTypeTok{i32} \NormalTok{= }\DecValTok{0}\NormalTok{;}
    \OtherTok{'b}\NormalTok{: \{}
        \KeywordTok{let} \NormalTok{z: &}\OtherTok{'b} \DataTypeTok{i32}\NormalTok{;}
        \OtherTok{'c}\NormalTok{: \{}
            \CommentTok{// Must use 'b here because this reference is}
            \CommentTok{// being passed to that scope.}
            \KeywordTok{let} \NormalTok{y: &}\OtherTok{'b} \DataTypeTok{i32} \NormalTok{= &}\OtherTok{'b} \NormalTok{x;}
            \NormalTok{z = y;}
        \NormalTok{\}}
    \NormalTok{\}}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\subsection{Example: references that outlive
referents}\label{example-references-that-outlive-referents}

Alright, let's look at some of those examples from before:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{fn} \NormalTok{as_str(data: &}\DataTypeTok{u32}\NormalTok{) -> &}\DataTypeTok{str} \NormalTok{\{}
    \KeywordTok{let} \NormalTok{s = }\PreprocessorTok{format!}\NormalTok{(}\StringTok{"\{\}"}\NormalTok{, data);}
    \NormalTok{&s}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

desugars to:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{fn} \NormalTok{as_str<}\OtherTok{'a}\NormalTok{>(data: &}\OtherTok{'a} \DataTypeTok{u32}\NormalTok{) -> &}\OtherTok{'a} \DataTypeTok{str} \NormalTok{\{}
    \OtherTok{'b}\NormalTok{: \{}
        \KeywordTok{let} \NormalTok{s = }\PreprocessorTok{format!}\NormalTok{(}\StringTok{"\{\}"}\NormalTok{, data);}
        \KeywordTok{return} \NormalTok{&}\OtherTok{'a} \NormalTok{s;}
    \NormalTok{\}}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

This signature of \texttt{as\_str} takes a reference to a u32 with
\emph{some} lifetime, and promises that it can produce a reference to a
str that can live \emph{just as long}. Already we can see why this
signature might be trouble. That basically implies that we're going to
find a str somewhere in the scope the reference to the u32 originated
in, or somewhere \emph{even earlier}. That's a bit of a tall order.

We then proceed to compute the string \texttt{s}, and return a reference
to it. Since the contract of our function says the reference must
outlive \texttt{\textquotesingle{}a}, that's the lifetime we infer for
the reference. Unfortunately, \texttt{s} was defined in the scope
\texttt{\textquotesingle{}b}, so the only way this is sound is if
\texttt{\textquotesingle{}b} contains \texttt{\textquotesingle{}a} --
which is clearly false since \texttt{\textquotesingle{}a} must contain
the function call itself. We have therefore created a reference whose
lifetime outlives its referent, which is \emph{literally} the first
thing we said that references can't do. The compiler rightfully blows up
in our face.

To make this more clear, we can expand the example:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{fn} \NormalTok{as_str<}\OtherTok{'a}\NormalTok{>(data: &}\OtherTok{'a} \DataTypeTok{u32}\NormalTok{) -> &}\OtherTok{'a} \DataTypeTok{str} \NormalTok{\{}
    \OtherTok{'b}\NormalTok{: \{}
        \KeywordTok{let} \NormalTok{s = }\PreprocessorTok{format!}\NormalTok{(}\StringTok{"\{\}"}\NormalTok{, data);}
        \KeywordTok{return} \NormalTok{&}\OtherTok{'a} \NormalTok{s}
    \NormalTok{\}}
\NormalTok{\}}

\KeywordTok{fn} \NormalTok{main() \{}
    \OtherTok{'c}\NormalTok{: \{}
        \KeywordTok{let} \NormalTok{x: }\DataTypeTok{u32} \NormalTok{= }\DecValTok{0}\NormalTok{;}
        \OtherTok{'d}\NormalTok{: \{}
            \CommentTok{// An anonymous scope is introduced because the borrow does not}
            \CommentTok{// need to last for the whole scope x is valid for. The return}
            \CommentTok{// of as_str must find a str somewhere before this function}
            \CommentTok{// call. Obviously not happening.}
            \PreprocessorTok{println!}\NormalTok{(}\StringTok{"\{\}"}\NormalTok{, as_str::<}\OtherTok{'d}\NormalTok{>(&}\OtherTok{'d} \NormalTok{x));}
        \NormalTok{\}}
    \NormalTok{\}}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

Shoot!

Of course, the right way to write this function is as follows:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{fn} \NormalTok{to_string(data: &}\DataTypeTok{u32}\NormalTok{) -> }\DataTypeTok{String} \NormalTok{\{}
    \PreprocessorTok{format!}\NormalTok{(}\StringTok{"\{\}"}\NormalTok{, data)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

We must produce an owned value inside the function to return it! The
only way we could have returned an \texttt{\&\textquotesingle{}a\ str}
would have been if it was in a field of the
\texttt{\&\textquotesingle{}a\ u32}, which is obviously not the case.

(Actually we could have also just returned a string literal, which as a
global can be considered to reside at the bottom of the stack; though
this limits our implementation \emph{just a bit}.)

\hypertarget{example-aliasing-a-mutable-reference}{\subsection{Example:
aliasing a mutable
reference}\label{example-aliasing-a-mutable-reference}}

How about the other example:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{let} \KeywordTok{mut} \NormalTok{data = }\PreprocessorTok{vec!}\NormalTok{[}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{];}
\KeywordTok{let} \NormalTok{x = &data[}\DecValTok{0}\NormalTok{];}
\NormalTok{data.push(}\DecValTok{4}\NormalTok{);}
\PreprocessorTok{println!}\NormalTok{(}\StringTok{"\{\}"}\NormalTok{, x);}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\OtherTok{'a}\NormalTok{: \{}
    \KeywordTok{let} \KeywordTok{mut} \NormalTok{data: }\DataTypeTok{Vec}\NormalTok{<}\DataTypeTok{i32}\NormalTok{> = }\PreprocessorTok{vec!}\NormalTok{[}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{];}
    \OtherTok{'b}\NormalTok{: \{}
        \CommentTok{// 'b is as big as we need this borrow to be}
        \CommentTok{// (just need to get to `println!`)}
        \KeywordTok{let} \NormalTok{x: &}\OtherTok{'b} \DataTypeTok{i32} \NormalTok{= Index::index::<}\OtherTok{'b}\NormalTok{>(&}\OtherTok{'b} \NormalTok{data, }\DecValTok{0}\NormalTok{);}
        \OtherTok{'c}\NormalTok{: \{}
            \CommentTok{// Temporary scope because we don't need the}
            \CommentTok{// &mut to last any longer.}
            \DataTypeTok{Vec}\NormalTok{::push(&}\OtherTok{'c} \KeywordTok{mut} \NormalTok{data, }\DecValTok{4}\NormalTok{);}
        \NormalTok{\}}
        \PreprocessorTok{println!}\NormalTok{(}\StringTok{"\{\}"}\NormalTok{, x);}
    \NormalTok{\}}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

The problem here is a bit more subtle and interesting. We want Rust to
reject this program for the following reason: We have a live shared
reference \texttt{x} to a descendant of \texttt{data} when we try to
take a mutable reference to \texttt{data} to \texttt{push}. This would
create an aliased mutable reference, which would violate the
\emph{second} rule of references.

However this is \emph{not at all} how Rust reasons that this program is
bad. Rust doesn't understand that \texttt{x} is a reference to a subpath
of \texttt{data}. It doesn't understand Vec at all. What it \emph{does}
see is that \texttt{x} has to live for \texttt{\textquotesingle{}b} to
be printed. The signature of \texttt{Index::index} subsequently demands
that the reference we take to \texttt{data} has to survive for
\texttt{\textquotesingle{}b}. When we try to call \texttt{push}, it then
sees us try to make an \texttt{\&\textquotesingle{}c\ mut\ data}. Rust
knows that \texttt{\textquotesingle{}c} is contained within
\texttt{\textquotesingle{}b}, and rejects our program because the
\texttt{\&\textquotesingle{}b\ data} must still be live!

Here we see that the lifetime system is much more coarse than the
reference semantics we're actually interested in preserving. For the
most part, \emph{that's totally ok}, because it keeps us from spending
all day explaining our program to the compiler. However it does mean
that several programs that are totally correct with respect to Rust's
\emph{true} semantics are rejected because lifetimes are too dumb.

\section{Limits of Lifetimes}\label{sec--lifetime-mismatch}

Given the following code:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{struct} \NormalTok{Foo;}

\KeywordTok{impl} \NormalTok{Foo \{}
    \KeywordTok{fn} \NormalTok{mutate_and_share(&}\KeywordTok{mut} \KeywordTok{self}\NormalTok{) -> &}\KeywordTok{Self} \NormalTok{\{ &*}\KeywordTok{self} \NormalTok{\}}
    \KeywordTok{fn} \NormalTok{share(&}\KeywordTok{self}\NormalTok{) \{\}}
\NormalTok{\}}

\KeywordTok{fn} \NormalTok{main() \{}
    \KeywordTok{let} \KeywordTok{mut} \NormalTok{foo = Foo;}
    \KeywordTok{let} \NormalTok{loan = foo.mutate_and_share();}
    \NormalTok{foo.share();}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

One might expect it to compile. We call \texttt{mutate\_and\_share},
which mutably borrows \texttt{foo} temporarily, but then returns only a
shared reference. Therefore we would expect \texttt{foo.share()} to
succeed as \texttt{foo} shouldn't be mutably borrowed.

However when we try to compile it:

\begin{verbatim}
<anon>:11:5: 11:8 error: cannot borrow `foo` as immutable because it is also borrowed 
â†³ as mutable
<anon>:11     foo.share();
              ^~~
<anon>:10:16: 10:19 note: previous borrow of `foo` occurs here; the mutable borrow pre
â†³ vents subsequent moves, borrows, or modification of `foo` until the borrow ends
<anon>:10     let loan = foo.mutate_and_share();
                         ^~~
<anon>:12:2: 12:2 note: previous borrow ends here
<anon>:8 fn main() {
<anon>:9     let mut foo = Foo;
<anon>:10     let loan = foo.mutate_and_share();
<anon>:11     foo.share();
<anon>:12 }
          ^
\end{verbatim}

What happened? Well, we got the exact same reasoning as we did for
\protect\hyperlink{example-aliasing-a-mutable-reference}{Example 2 in
the previous section}. We desugar the program and we get the following:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{struct} \NormalTok{Foo;}

\KeywordTok{impl} \NormalTok{Foo \{}
    \KeywordTok{fn} \NormalTok{mutate_and_share<}\OtherTok{'a}\NormalTok{>(&}\OtherTok{'a} \KeywordTok{mut} \KeywordTok{self}\NormalTok{) -> &}\OtherTok{'a} \KeywordTok{Self} \NormalTok{\{ &}\OtherTok{'a} \NormalTok{*}\KeywordTok{self} \NormalTok{\}}
    \KeywordTok{fn} \NormalTok{share<}\OtherTok{'a}\NormalTok{>(&}\OtherTok{'a} \KeywordTok{self}\NormalTok{) \{\}}
\NormalTok{\}}

\KeywordTok{fn} \NormalTok{main() \{}
    \OtherTok{'b}\NormalTok{: \{}
        \KeywordTok{let} \KeywordTok{mut} \NormalTok{foo: Foo = Foo;}
        \OtherTok{'c}\NormalTok{: \{}
            \KeywordTok{let} \NormalTok{loan: &}\OtherTok{'c} \NormalTok{Foo = Foo::mutate_and_share::<}\OtherTok{'c}\NormalTok{>(&}\OtherTok{'c} \KeywordTok{mut} \NormalTok{foo);}
            \OtherTok{'d}\NormalTok{: \{}
                \NormalTok{Foo::share::<}\OtherTok{'d}\NormalTok{>(&}\OtherTok{'d} \NormalTok{foo);}
            \NormalTok{\}}
        \NormalTok{\}}
    \NormalTok{\}}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

The lifetime system is forced to extend the \texttt{\&mut\ foo} to have
lifetime \texttt{\textquotesingle{}c}, due to the lifetime of
\texttt{loan} and mutate\_and\_share's signature. Then when we try to
call \texttt{share}, and it sees we're trying to alias that
\texttt{\&\textquotesingle{}c\ mut\ foo} and blows up in our face!

This program is clearly correct according to the reference semantics we
actually care about, but the lifetime system is too coarse-grained to
handle that.

TODO: other common problems? SEME regions stuff, mostly?

\section{Lifetime Elision}\label{sec--lifetime-elision}

In order to make common patterns more ergonomic, Rust allows lifetimes
to be \emph{elided} in function signatures.

A \emph{lifetime position} is anywhere you can write a lifetime in a
type:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{&}\OtherTok{'a} \NormalTok{T}
\NormalTok{&}\OtherTok{'a} \KeywordTok{mut} \NormalTok{T}
\NormalTok{T<}\OtherTok{'a}\NormalTok{>}
\end{Highlighting}
\end{Shaded}

Lifetime positions can appear as either ``input'' or ``output'':

\begin{itemize}
\item
  For \texttt{fn} definitions, input refers to the types of the formal
  arguments in the \texttt{fn} definition, while output refers to result
  types. So
  \texttt{fn\ foo(s:\ \&str)\ -\textgreater{}\ (\&str,\ \&str)} has
  elided one lifetime in input position and two lifetimes in output
  position. Note that the input positions of a \texttt{fn} method
  definition do not include the lifetimes that occur in the method's
  \texttt{impl} header (nor lifetimes that occur in the trait header,
  for a default method).
\item
  In the future, it should be possible to elide \texttt{impl} headers in
  the same manner.
\end{itemize}

Elision rules are as follows:

\begin{itemize}
\item
  Each elided lifetime in input position becomes a distinct lifetime
  parameter.
\item
  If there is exactly one input lifetime position (elided or not), that
  lifetime is assigned to \emph{all} elided output lifetimes.
\item
  If there are multiple input lifetime positions, but one of them is
  \texttt{\&self} or \texttt{\&mut\ self}, the lifetime of \texttt{self}
  is assigned to \emph{all} elided output lifetimes.
\item
  Otherwise, it is an error to elide an output lifetime.
\end{itemize}

Examples:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{fn} \NormalTok{print(s: &}\DataTypeTok{str}\NormalTok{);                                      }\CommentTok{// elided}
\KeywordTok{fn} \NormalTok{print<}\OtherTok{'a}\NormalTok{>(s: &}\OtherTok{'a} \DataTypeTok{str}\NormalTok{);                               }\CommentTok{// expanded}

\KeywordTok{fn} \NormalTok{debug(lvl: }\DataTypeTok{uint}\NormalTok{, s: &}\DataTypeTok{str}\NormalTok{);                           }\CommentTok{// elided}
\KeywordTok{fn} \NormalTok{debug<}\OtherTok{'a}\NormalTok{>(lvl: }\DataTypeTok{uint}\NormalTok{, s: &}\OtherTok{'a} \DataTypeTok{str}\NormalTok{);                    }\CommentTok{// expanded}

\KeywordTok{fn} \NormalTok{substr(s: &}\DataTypeTok{str}\NormalTok{, until: }\DataTypeTok{uint}\NormalTok{) -> &}\DataTypeTok{str}\NormalTok{;                }\CommentTok{// elided}
\KeywordTok{fn} \NormalTok{substr<}\OtherTok{'a}\NormalTok{>(s: &}\OtherTok{'a} \DataTypeTok{str}\NormalTok{, until: }\DataTypeTok{uint}\NormalTok{) -> &}\OtherTok{'a} \DataTypeTok{str}\NormalTok{;      }\CommentTok{// expanded}

\KeywordTok{fn} \NormalTok{get_str() -> &}\DataTypeTok{str}\NormalTok{;                                   }\CommentTok{// ILLEGAL}

\KeywordTok{fn} \NormalTok{frob(s: &}\DataTypeTok{str}\NormalTok{, t: &}\DataTypeTok{str}\NormalTok{) -> &}\DataTypeTok{str}\NormalTok{;                      }\CommentTok{// ILLEGAL}

\KeywordTok{fn} \NormalTok{get_mut(&}\KeywordTok{mut} \KeywordTok{self}\NormalTok{) -> &}\KeywordTok{mut} \NormalTok{T;                        }\CommentTok{// elided}
\KeywordTok{fn} \NormalTok{get_mut<}\OtherTok{'a}\NormalTok{>(&}\OtherTok{'a} \KeywordTok{mut} \KeywordTok{self}\NormalTok{) -> &}\OtherTok{'a} \KeywordTok{mut} \NormalTok{T;              }\CommentTok{// expanded}

\KeywordTok{fn} \NormalTok{args<T: ToCStr>(&}\KeywordTok{mut} \KeywordTok{self}\NormalTok{, args: &[T]) -> &}\KeywordTok{mut} \NormalTok{Command                  }\CommentTok{// elided}
\KeywordTok{fn} \NormalTok{args<}\OtherTok{'a}\NormalTok{, }\OtherTok{'b}\NormalTok{, T: ToCStr>(&}\OtherTok{'a} \KeywordTok{mut} \KeywordTok{self}\NormalTok{, args: &}\OtherTok{'b} \NormalTok{[T]) -> &}\OtherTok{'a} \KeywordTok{mut} \NormalTok{Command }\CommentTok{// expanded}

\KeywordTok{fn} \NormalTok{new(buf: &}\KeywordTok{mut} \NormalTok{[}\DataTypeTok{u8}\NormalTok{]) -> BufWriter;                    }\CommentTok{// elided}
\KeywordTok{fn} \NormalTok{new<}\OtherTok{'a}\NormalTok{>(buf: &}\OtherTok{'a} \KeywordTok{mut} \NormalTok{[}\DataTypeTok{u8}\NormalTok{]) -> BufWriter<}\OtherTok{'a}\NormalTok{>          }\CommentTok{// expanded}
\end{Highlighting}
\end{Shaded}

\section{Unbounded Lifetimes}\label{sec--unbounded-lifetimes}

Unsafe code can often end up producing references or lifetimes out of
thin air. Such lifetimes come into the world as \emph{unbounded}. The
most common source of this is dereferencing a raw pointer, which
produces a reference with an unbounded lifetime. Such a lifetime becomes
as big as context demands. This is in fact more powerful than simply
becoming \texttt{\textquotesingle{}static}, because for instance
\texttt{\&\textquotesingle{}static\ \&\textquotesingle{}a\ T} will fail
to typecheck, but the unbound lifetime will perfectly mold into
\texttt{\&\textquotesingle{}a\ \&\textquotesingle{}a\ T} as needed.
However for most intents and purposes, such an unbounded lifetime can be
regarded as \texttt{\textquotesingle{}static}.

Almost no reference is \texttt{\textquotesingle{}static}, so this is
probably wrong. \texttt{transmute} and \texttt{transmute\_copy} are the
two other primary offenders. One should endeavor to bound an unbounded
lifetime as quick as possible, especially across function boundaries.

Given a function, any output lifetimes that don't derive from inputs are
unbounded. For instance:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{fn} \NormalTok{get_str<}\OtherTok{'a}\NormalTok{>() -> &}\OtherTok{'a} \DataTypeTok{str}\NormalTok{;}
\end{Highlighting}
\end{Shaded}

will produce an \texttt{\&str} with an unbounded lifetime. The easiest
way to avoid unbounded lifetimes is to use lifetime elision at the
function boundary. If an output lifetime is elided, then it \emph{must}
be bounded by an input lifetime. Of course it might be bounded by the
\emph{wrong} lifetime, but this will usually just cause a compiler
error, rather than allow memory safety to be trivially violated.

Within a function, bounding lifetimes is more error-prone. The safest
and easiest way to bound a lifetime is to return it from a function with
a bound lifetime. However if this is unacceptable, the reference can be
placed in a location with a specific lifetime. Unfortunately it's
impossible to name all lifetimes involved in a function.

\section{Higher-Rank Trait Bounds}\label{sec--hrtb}

Rust's \texttt{Fn} traits are a little bit magic. For instance, we can
write the following code:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{struct} \NormalTok{Closure<F> \{}
    \NormalTok{data: (}\DataTypeTok{u8}\NormalTok{, }\DataTypeTok{u16}\NormalTok{),}
    \NormalTok{func: F,}
\NormalTok{\}}

\KeywordTok{impl}\NormalTok{<F> Closure<F>}
    \KeywordTok{where} \NormalTok{F: }\BuiltInTok{Fn}\NormalTok{(&(}\DataTypeTok{u8}\NormalTok{, }\DataTypeTok{u16}\NormalTok{)) -> &}\DataTypeTok{u8}\NormalTok{,}
\NormalTok{\{}
    \KeywordTok{fn} \NormalTok{call(&}\KeywordTok{self}\NormalTok{) -> &}\DataTypeTok{u8} \NormalTok{\{}
        \NormalTok{(}\KeywordTok{self}\NormalTok{.func)(&}\KeywordTok{self}\NormalTok{.data)}
    \NormalTok{\}}
\NormalTok{\}}

\KeywordTok{fn} \NormalTok{do_it(data: &(}\DataTypeTok{u8}\NormalTok{, }\DataTypeTok{u16}\NormalTok{)) -> &}\DataTypeTok{u8} \NormalTok{\{ &data.}\DecValTok{0} \NormalTok{\}}

\KeywordTok{fn} \NormalTok{main() \{}
    \KeywordTok{let} \NormalTok{clo = Closure \{ data: (}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{), func: do_it \};}
    \PreprocessorTok{println!}\NormalTok{(}\StringTok{"\{\}"}\NormalTok{, clo.call());}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

If we try to naively desugar this code in the same way that we did in
the lifetimes section, we run into some trouble:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{struct} \NormalTok{Closure<F> \{}
    \NormalTok{data: (}\DataTypeTok{u8}\NormalTok{, }\DataTypeTok{u16}\NormalTok{),}
    \NormalTok{func: F,}
\NormalTok{\}}

\KeywordTok{impl}\NormalTok{<F> Closure<F>}
    \CommentTok{// where F: Fn(&'??? (u8, u16)) -> &'??? u8,}
\NormalTok{\{}
    \KeywordTok{fn} \NormalTok{call<}\OtherTok{'a}\NormalTok{>(&}\OtherTok{'a} \KeywordTok{self}\NormalTok{) -> &}\OtherTok{'a} \DataTypeTok{u8} \NormalTok{\{}
        \NormalTok{(}\KeywordTok{self}\NormalTok{.func)(&}\KeywordTok{self}\NormalTok{.data)}
    \NormalTok{\}}
\NormalTok{\}}

\KeywordTok{fn} \NormalTok{do_it<}\OtherTok{'b}\NormalTok{>(data: &}\OtherTok{'b} \NormalTok{(}\DataTypeTok{u8}\NormalTok{, }\DataTypeTok{u16}\NormalTok{)) -> &}\OtherTok{'b} \DataTypeTok{u8} \NormalTok{\{ &}\OtherTok{'b} \NormalTok{data.}\DecValTok{0} \NormalTok{\}}

\KeywordTok{fn} \NormalTok{main() \{}
    \OtherTok{'x}\NormalTok{: \{}
        \KeywordTok{let} \NormalTok{clo = Closure \{ data: (}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{), func: do_it \};}
        \PreprocessorTok{println!}\NormalTok{(}\StringTok{"\{\}"}\NormalTok{, clo.call());}
    \NormalTok{\}}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

How on earth are we supposed to express the lifetimes on \texttt{F}'s
trait bound? We need to provide some lifetime there, but the lifetime we
care about can't be named until we enter the body of \texttt{call}!
Also, that isn't some fixed lifetime; \texttt{call} works with
\emph{any} lifetime \texttt{\&self} happens to have at that point.

This job requires The Magic of Higher-Rank Trait Bounds (HRTBs). The way
we desugar this is as follows:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{where} \KeywordTok{for}\NormalTok{<}\OtherTok{'a}\NormalTok{> F: }\BuiltInTok{Fn}\NormalTok{(&}\OtherTok{'a} \NormalTok{(}\DataTypeTok{u8}\NormalTok{, }\DataTypeTok{u16}\NormalTok{)) -> &}\OtherTok{'a} \DataTypeTok{u8}\NormalTok{,}
\end{Highlighting}
\end{Shaded}

(Where \texttt{Fn(a,\ b,\ c)\ -\textgreater{}\ d} is itself just sugar
for the unstable \emph{real} \texttt{Fn} trait)

\texttt{for\textless{}\textquotesingle{}a\textgreater{}} can be read as
``for all choices of \texttt{\textquotesingle{}a}'', and basically
produces an \emph{infinite list} of trait bounds that F must satisfy.
Intense. There aren't many places outside of the \texttt{Fn} traits
where we encounter HRTBs, and even for those we have a nice magic sugar
for the common cases.

\section{Subtyping and Variance}\label{sec--subtyping}

Although Rust doesn't have any notion of structural inheritance, it
\emph{does} include subtyping. In Rust, subtyping derives entirely from
lifetimes. Since lifetimes are scopes, we can partially order them based
on the \emph{contains} (outlives) relationship. We can even express this
as a generic bound.

Subtyping on lifetimes is in terms of that relationship: if
\texttt{\textquotesingle{}a:\ \textquotesingle{}b} (``a contains b'' or
``a outlives b''), then \texttt{\textquotesingle{}a} is a subtype of
\texttt{\textquotesingle{}b}. This is a large source of confusion,
because it seems intuitively backwards to many: the bigger scope is a
\emph{subtype} of the smaller scope.

This does in fact make sense, though. The intuitive reason for this is
that if you expect an \texttt{\&\textquotesingle{}a\ u8}, then it's
totally fine for me to hand you an
\texttt{\&\textquotesingle{}static\ u8}, in the same way that if you
expect an Animal in Java, it's totally fine for me to hand you a Cat.
Cats are just Animals \emph{and more}, just as
\texttt{\textquotesingle{}static} is just \texttt{\textquotesingle{}a}
\emph{and more}.

(Note, the subtyping relationship and typed-ness of lifetimes is a
fairly arbitrary construct that some disagree with. However it
simplifies our analysis to treat lifetimes and types uniformly.)

Higher-ranked lifetimes are also subtypes of every concrete lifetime.
This is because taking an arbitrary lifetime is strictly more general
than taking a specific one.

\subsection{Variance}\label{variance}

Variance is where things get a bit complicated.

Variance is a property that \emph{type constructors} have with respect
to their arguments. A type constructor in Rust is a generic type with
unbound arguments. For instance \texttt{Vec} is a type constructor that
takes a \texttt{T} and returns a \texttt{Vec\textless{}T\textgreater{}}.
\texttt{\&} and \texttt{\&mut} are type constructors that take two
inputs: a lifetime, and a type to point to.

A type constructor's \emph{variance} is how the subtyping of its inputs
affects the subtyping of its outputs. There are two kinds of variance in
Rust:

\begin{itemize}
\tightlist
\item
  F is \emph{variant} over \texttt{T} if \texttt{T} being a subtype of
  \texttt{U} implies \texttt{F\textless{}T\textgreater{}} is a subtype
  of \texttt{F\textless{}U\textgreater{}} (subtyping ``passes through'')
\item
  F is \emph{invariant} over \texttt{T} otherwise (no subtyping relation
  can be derived)
\end{itemize}

(For those of you who are familiar with variance from other languages,
what we refer to as ``just'' variance is in fact \emph{covariance}. Rust
has \emph{contravariance} for functions. The future of contravariance is
uncertain and it may be scrapped. For now, \texttt{fn(T)} is
contravariant in \texttt{T}, which is used in matching methods in trait
implementations to the trait definition. Traits don't have inferred
variance, so \texttt{Fn(T)} is invariant in \texttt{T}).

Some important variances:

\begin{itemize}
\tightlist
\item
  \texttt{\&\textquotesingle{}a\ T} is variant over
  \texttt{\textquotesingle{}a} and \texttt{T} (as is \texttt{*const\ T}
  by metaphor)
\item
  \texttt{\&\textquotesingle{}a\ mut\ T} is variant over
  \texttt{\textquotesingle{}a} but invariant over \texttt{T}
\item
  \texttt{Fn(T)\ -\textgreater{}\ U} is invariant over \texttt{T}, but
  variant over \texttt{U}
\item
  \texttt{Box}, \texttt{Vec}, and all other collections are variant over
  the types of their contents
\item
  \texttt{UnsafeCell\textless{}T\textgreater{}},
  \texttt{Cell\textless{}T\textgreater{}},
  \texttt{RefCell\textless{}T\textgreater{}},
  \texttt{Mutex\textless{}T\textgreater{}} and all other interior
  mutability types are invariant over T (as is \texttt{*mut\ T} by
  metaphor)
\end{itemize}

To understand why these variances are correct and desirable, we will
consider several examples.

We have already covered why \texttt{\&\textquotesingle{}a\ T} should be
variant over \texttt{\textquotesingle{}a} when introducing subtyping:
it's desirable to be able to pass longer-lived things where
shorter-lived things are needed.

Similar reasoning applies to why it should be variant over T. It is
reasonable to be able to pass \texttt{\&\&\textquotesingle{}static\ str}
where an \texttt{\&\&\textquotesingle{}a\ str} is expected. The
additional level of indirection does not change the desire to be able to
pass longer lived things where shorted lived things are expected.

However this logic doesn't apply to \texttt{\&mut}. To see why
\texttt{\&mut} should be invariant over T, consider the following code:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{fn} \NormalTok{overwrite<T: }\BuiltInTok{Copy}\NormalTok{>(input: &}\KeywordTok{mut} \NormalTok{T, new: &}\KeywordTok{mut} \NormalTok{T) \{}
    \NormalTok{*input = *new;}
\NormalTok{\}}

\KeywordTok{fn} \NormalTok{main() \{}
    \KeywordTok{let} \KeywordTok{mut} \NormalTok{forever_str: &}\OtherTok{'static} \DataTypeTok{str} \NormalTok{= }\StringTok{"hello"}\NormalTok{;}
    \NormalTok{\{}
        \KeywordTok{let} \NormalTok{string = }\DataTypeTok{String}\NormalTok{::from(}\StringTok{"world"}\NormalTok{);}
        \NormalTok{overwrite(&}\KeywordTok{mut} \NormalTok{forever_str, &}\KeywordTok{mut} \NormalTok{&*string);}
    \NormalTok{\}}
    \CommentTok{// Oops, printing free'd memory}
    \PreprocessorTok{println!}\NormalTok{(}\StringTok{"\{\}"}\NormalTok{, forever_str);}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

The signature of \texttt{overwrite} is clearly valid: it takes mutable
references to two values of the same type, and overwrites one with the
other. If \texttt{\&mut\ T} was variant over T, then
\texttt{\&mut\ \&\textquotesingle{}static\ str} would be a subtype of
\texttt{\&mut\ \&\textquotesingle{}a\ str}, since
\texttt{\&\textquotesingle{}static\ str} is a subtype of
\texttt{\&\textquotesingle{}a\ str}. Therefore the lifetime of
\texttt{forever\_str} would successfully be ``shrunk'' down to the
shorter lifetime of \texttt{string}, and \texttt{overwrite} would be
called successfully. \texttt{string} would subsequently be dropped, and
\texttt{forever\_str} would point to freed memory when we print it!
Therefore \texttt{\&mut} should be invariant.

This is the general theme of variance vs invariance: if variance would
allow you to store a short-lived value into a longer-lived slot, then
you must be invariant.

However it \emph{is} sound for \texttt{\&\textquotesingle{}a\ mut\ T} to
be variant over \texttt{\textquotesingle{}a}. The key difference between
\texttt{\textquotesingle{}a} and T is that \texttt{\textquotesingle{}a}
is a property of the reference itself, while T is something the
reference is borrowing. If you change T's type, then the source still
remembers the original type. However if you change the lifetime's type,
no one but the reference knows this information, so it's fine. Put
another way: \texttt{\&\textquotesingle{}a\ mut\ T} owns
\texttt{\textquotesingle{}a}, but only \emph{borrows} T.

\texttt{Box} and \texttt{Vec} are interesting cases because they're
variant, but you can definitely store values in them! This is where Rust
gets really clever: it's fine for them to be variant because you can
only store values in them \emph{via a mutable reference}! The mutable
reference makes the whole type invariant, and therefore prevents you
from smuggling a short-lived type into them.

Being variant allows \texttt{Box} and \texttt{Vec} to be weakened when
shared immutably. So you can pass a
\texttt{\&Box\textless{}\&\textquotesingle{}static\ str\textgreater{}}
where a
\texttt{\&Box\textless{}\&\textquotesingle{}a\ str\textgreater{}} is
expected.

However what should happen when passing \emph{by-value} is less obvious.
It turns out that, yes, you can use subtyping when passing by-value.
That is, this works:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{fn} \NormalTok{get_box<}\OtherTok{'a}\NormalTok{>(}\DataTypeTok{str}\NormalTok{: &}\OtherTok{'a} \DataTypeTok{str}\NormalTok{) -> }\DataTypeTok{Box}\NormalTok{<&}\OtherTok{'a} \DataTypeTok{str}\NormalTok{> \{}
    \CommentTok{// string literals are `&'static str`s}
    \DataTypeTok{Box}\NormalTok{::new(}\StringTok{"hello"}\NormalTok{)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

Weakening when you pass by-value is fine because there's no one else who
``remembers'' the old lifetime in the Box. The reason a variant
\texttt{\&mut} was trouble was because there's always someone else who
remembers the original subtype: the actual owner.

The invariance of the cell types can be seen as follows: \texttt{\&} is
like an \texttt{\&mut} for a cell, because you can still store values in
them through an \texttt{\&}. Therefore cells must be invariant to avoid
lifetime smuggling.

\texttt{Fn} is the most subtle case because it has mixed variance. To
see why \texttt{Fn(T)\ -\textgreater{}\ U} should be invariant over T,
consider the following function signature:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// 'a is derived from some parent scope}
\KeywordTok{fn} \NormalTok{foo(&}\OtherTok{'a} \DataTypeTok{str}\NormalTok{) -> }\DataTypeTok{usize}\NormalTok{;}
\end{Highlighting}
\end{Shaded}

This signature claims that it can handle any \texttt{\&str} that lives
at least as long as \texttt{\textquotesingle{}a}. Now if this signature
was variant over \texttt{\&\textquotesingle{}a\ str}, that would mean

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{fn} \NormalTok{foo(&}\OtherTok{'static} \DataTypeTok{str}\NormalTok{) -> }\DataTypeTok{usize}\NormalTok{;}
\end{Highlighting}
\end{Shaded}

could be provided in its place, as it would be a subtype. However this
function has a stronger requirement: it says that it can only handle
\texttt{\&\textquotesingle{}static\ str}s, and nothing else. Giving
\texttt{\&\textquotesingle{}a\ str}s to it would be unsound, as it's
free to assume that what it's given lives forever. Therefore functions
are not variant over their arguments.

To see why \texttt{Fn(T)\ -\textgreater{}\ U} should be variant over U,
consider the following function signature:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{// 'a is derived from some parent scope}
\KeywordTok{fn} \NormalTok{foo(}\DataTypeTok{usize}\NormalTok{) -> &}\OtherTok{'a} \DataTypeTok{str}\NormalTok{;}
\end{Highlighting}
\end{Shaded}

This signature claims that it will return something that outlives
\texttt{\textquotesingle{}a}. It is therefore completely reasonable to
provide

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{fn} \NormalTok{foo(}\DataTypeTok{usize}\NormalTok{) -> &}\OtherTok{'static} \DataTypeTok{str}\NormalTok{;}
\end{Highlighting}
\end{Shaded}

in its place. Therefore functions are variant over their return type.

\texttt{*const} has the exact same semantics as \texttt{\&}, so variance
follows. \texttt{*mut} on the other hand can dereference to an
\texttt{\&mut} whether shared or not, so it is marked as invariant just
like cells.

This is all well and good for the types the standard library provides,
but how is variance determined for type that \emph{you} define? A
struct, informally speaking, inherits the variance of its fields. If a
struct \texttt{Foo} has a generic argument \texttt{A} that is used in a
field \texttt{a}, then Foo's variance over \texttt{A} is exactly
\texttt{a}'s variance. However this is complicated if \texttt{A} is used
in multiple fields.

\begin{itemize}
\tightlist
\item
  If all uses of A are variant, then Foo is variant over A
\item
  Otherwise, Foo is invariant over A
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{use} \NormalTok{std::cell::Cell;}

\KeywordTok{struct} \NormalTok{Foo<}\OtherTok{'a}\NormalTok{, }\OtherTok{'b}\NormalTok{, A: }\OtherTok{'a}\NormalTok{, B: }\OtherTok{'b}\NormalTok{, C, D, E, F, G, H> \{}
    \NormalTok{a: &}\OtherTok{'a} \NormalTok{A,     }\CommentTok{// variant over 'a and A}
    \NormalTok{b: &}\OtherTok{'b} \KeywordTok{mut} \NormalTok{B, }\CommentTok{// variant over 'b and invariant over B}
    \NormalTok{c: *}\KeywordTok{const} \NormalTok{C,  }\CommentTok{// variant over C}
    \NormalTok{d: *}\KeywordTok{mut} \NormalTok{D,    }\CommentTok{// invariant over D}
    \NormalTok{e: }\DataTypeTok{Vec}\NormalTok{<E>,    }\CommentTok{// variant over E}
    \NormalTok{f: Cell<F>,   }\CommentTok{// invariant over F}
    \NormalTok{g: G,         }\CommentTok{// variant over G}
    \NormalTok{h1: H,        }\CommentTok{// would also be variant over H except...}
    \NormalTok{h2: Cell<H>,  }\CommentTok{// invariant over H, because invariance wins}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\section{Drop Check}\label{sec--dropck}

We have seen how lifetimes provide us some fairly simple rules for
ensuring that we never read dangling references. However up to this
point we have only ever interacted with the \emph{outlives} relationship
in an inclusive manner. That is, when we talked about
\texttt{\textquotesingle{}a:\ \textquotesingle{}b}, it was ok for
\texttt{\textquotesingle{}a} to live \emph{exactly} as long as
\texttt{\textquotesingle{}b}. At first glance, this seems to be a
meaningless distinction. Nothing ever gets dropped at the same time as
another, right? This is why we used the following desugaring of
\texttt{let} statements:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{let} \NormalTok{x;}
\KeywordTok{let} \NormalTok{y;}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{\{}
    \KeywordTok{let} \NormalTok{x;}
    \NormalTok{\{}
        \KeywordTok{let} \NormalTok{y;}
    \NormalTok{\}}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

Each creates its own scope, clearly establishing that one drops before
the other. However, what if we do the following?

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{let} \NormalTok{(x, y) = (}\PreprocessorTok{vec!}\NormalTok{[], }\PreprocessorTok{vec!}\NormalTok{[]);}
\end{Highlighting}
\end{Shaded}

Does either value strictly outlive the other? The answer is in fact
\emph{no}, neither value strictly outlives the other. Of course, one of
x or y will be dropped before the other, but the actual order is not
specified. Tuples aren't special in this regard; composite structures
just don't guarantee their destruction order as of Rust 1.0.

We \emph{could} specify this for the fields of built-in composites like
tuples and structs. However, what about something like Vec? Vec has to
manually drop its elements via pure-library code. In general, anything
that implements Drop has a chance to fiddle with its innards during its
final death knell. Therefore the compiler can't sufficiently reason
about the actual destruction order of the contents of any type that
implements Drop.

So why do we care? We care because if the type system isn't careful, it
could accidentally make dangling pointers. Consider the following simple
program:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{struct} \NormalTok{Inspector<}\OtherTok{'a}\NormalTok{>(&}\OtherTok{'a} \DataTypeTok{u8}\NormalTok{);}

\KeywordTok{fn} \NormalTok{main() \{}
    \KeywordTok{let} \NormalTok{(inspector, days);}
    \NormalTok{days = }\DataTypeTok{Box}\NormalTok{::new(}\DecValTok{1}\NormalTok{);}
    \NormalTok{inspector = Inspector(&days);}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

This program is totally sound and compiles today. The fact that
\texttt{days} does not \emph{strictly} outlive \texttt{inspector}
doesn't matter. As long as the \texttt{inspector} is alive, so is days.

However if we add a destructor, the program will no longer compile!

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{struct} \NormalTok{Inspector<}\OtherTok{'a}\NormalTok{>(&}\OtherTok{'a} \DataTypeTok{u8}\NormalTok{);}

\KeywordTok{impl}\NormalTok{<}\OtherTok{'a}\NormalTok{> }\BuiltInTok{Drop} \KeywordTok{for} \NormalTok{Inspector<}\OtherTok{'a}\NormalTok{> \{}
    \KeywordTok{fn} \NormalTok{drop(&}\KeywordTok{mut} \KeywordTok{self}\NormalTok{) \{}
        \PreprocessorTok{println!}\NormalTok{(}\StringTok{"I was only \{\} days from retirement!"}\NormalTok{, }\KeywordTok{self}\NormalTok{.}\DecValTok{0}\NormalTok{);}
    \NormalTok{\}}
\NormalTok{\}}

\KeywordTok{fn} \NormalTok{main() \{}
    \KeywordTok{let} \NormalTok{(inspector, days);}
    \NormalTok{days = }\DataTypeTok{Box}\NormalTok{::new(}\DecValTok{1}\NormalTok{);}
    \NormalTok{inspector = Inspector(&days);}
    \CommentTok{// Let's say `days` happens to get dropped first.}
    \CommentTok{// Then when Inspector is dropped, it will try to read free'd memory!}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
<anon>:12:28: 12:32 error: `days` does not live long enough
<anon>:12     inspector = Inspector(&days);
                                     ^~~~
<anon>:9:11: 15:2 note: reference must be valid for the block at 9:10...
<anon>:9 fn main() {
<anon>:10     let (inspector, days);
<anon>:11     days = Box::new(1);
<anon>:12     inspector = Inspector(&days);
<anon>:13     // Let's say `days` happens to get dropped first.
<anon>:14     // Then when Inspector is dropped, it will try to read free'd memory!
          ...
<anon>:10:27: 15:2 note: ...but borrowed value is only valid for the block suffix foll
â†³ owing statement 0 at 10:26
<anon>:10     let (inspector, days);
<anon>:11     days = Box::new(1);
<anon>:12     inspector = Inspector(&days);
<anon>:13     // Let's say `days` happens to get dropped first.
<anon>:14     // Then when Inspector is dropped, it will try to read free'd memory!
<anon>:15 }
\end{verbatim}

Implementing Drop lets the Inspector execute some arbitrary code during
its death. This means it can potentially observe that types that are
supposed to live as long as it does actually were destroyed first.

Interestingly, only generic types need to worry about this. If they
aren't generic, then the only lifetimes they can harbor are
\texttt{\textquotesingle{}static}, which will truly live \emph{forever}.
This is why this problem is referred to as \emph{sound generic drop}.
Sound generic drop is enforced by the \emph{drop checker}. As of this
writing, some of the finer details of how the drop checker validates
types is totally up in the air. However The Big Rule is the subtlety
that we have focused on this whole section:

\textbf{For a generic type to soundly implement drop, its generics
arguments must strictly outlive it.}

Obeying this rule is (usually) necessary to satisfy the borrow checker;
obeying it is sufficient but not necessary to be sound. That is, if your
type obeys this rule then it's definitely sound to drop.

The reason that it is not always necessary to satisfy the above rule is
that some Drop implementations will not access borrowed data even though
their type gives them the capability for such access.

For example, this variant of the above \texttt{Inspector} example will
never accessed borrowed data:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{struct} \NormalTok{Inspector<}\OtherTok{'a}\NormalTok{>(&}\OtherTok{'a} \DataTypeTok{u8}\NormalTok{, &}\OtherTok{'static} \DataTypeTok{str}\NormalTok{);}

\KeywordTok{impl}\NormalTok{<}\OtherTok{'a}\NormalTok{> }\BuiltInTok{Drop} \KeywordTok{for} \NormalTok{Inspector<}\OtherTok{'a}\NormalTok{> \{}
    \KeywordTok{fn} \NormalTok{drop(&}\KeywordTok{mut} \KeywordTok{self}\NormalTok{) \{}
        \PreprocessorTok{println!}\NormalTok{(}\StringTok{"Inspector(_, \{\}) knows when *not* to inspect."}\NormalTok{, }\KeywordTok{self}\NormalTok{.}\DecValTok{1}\NormalTok{);}
    \NormalTok{\}}
\NormalTok{\}}

\KeywordTok{fn} \NormalTok{main() \{}
    \KeywordTok{let} \NormalTok{(inspector, days);}
    \NormalTok{days = }\DataTypeTok{Box}\NormalTok{::new(}\DecValTok{1}\NormalTok{);}
    \NormalTok{inspector = Inspector(&days, }\StringTok{"gadget"}\NormalTok{);}
    \CommentTok{// Let's say `days` happens to get dropped first.}
    \CommentTok{// Even when Inspector is dropped, its destructor will not access the}
    \CommentTok{// borrowed `days`.}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

Likewise, this variant will also never access borrowed data:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{use} \NormalTok{std::fmt;}

\KeywordTok{struct} \NormalTok{Inspector<T: fmt::}\BuiltInTok{Display}\NormalTok{>(T, &}\OtherTok{'static} \DataTypeTok{str}\NormalTok{);}

\KeywordTok{impl}\NormalTok{<T: fmt::}\BuiltInTok{Display}\NormalTok{> }\BuiltInTok{Drop} \KeywordTok{for} \NormalTok{Inspector<T> \{}
    \KeywordTok{fn} \NormalTok{drop(&}\KeywordTok{mut} \KeywordTok{self}\NormalTok{) \{}
        \PreprocessorTok{println!}\NormalTok{(}\StringTok{"Inspector(_, \{\}) knows when *not* to inspect."}\NormalTok{, }\KeywordTok{self}\NormalTok{.}\DecValTok{1}\NormalTok{);}
    \NormalTok{\}}
\NormalTok{\}}

\KeywordTok{fn} \NormalTok{main() \{}
    \KeywordTok{let} \NormalTok{(inspector, days): (Inspector<&}\DataTypeTok{u8}\NormalTok{>, }\DataTypeTok{Box}\NormalTok{<}\DataTypeTok{u8}\NormalTok{>);}
    \NormalTok{days = }\DataTypeTok{Box}\NormalTok{::new(}\DecValTok{1}\NormalTok{);}
    \NormalTok{inspector = Inspector(&days, }\StringTok{"gadget"}\NormalTok{);}
    \CommentTok{// Let's say `days` happens to get dropped first.}
    \CommentTok{// Even when Inspector is dropped, its destructor will not access the}
    \CommentTok{// borrowed `days`.}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

However, \emph{both} of the above variants are rejected by the borrow
checker during the analysis of \texttt{fn\ main}, saying that
\texttt{days} does not live long enough.

The reason is that the borrow checking analysis of \texttt{main} does
not know about the internals of each Inspector's Drop implementation. As
far as the borrow checker knows while it is analyzing \texttt{main}, the
body of an inspector's destructor might access that borrowed data.

Therefore, the drop checker forces all borrowed data in a value to
strictly outlive that value.

\subsection{An Escape Hatch}\label{an-escape-hatch}

The precise rules that govern drop checking may be less restrictive in
the future.

The current analysis is deliberately conservative and trivial; it forces
all borrowed data in a value to outlive that value, which is certainly
sound.

Future versions of the language may make the analysis more precise, to
reduce the number of cases where sound code is rejected as unsafe. This
would help address cases such as the two Inspectors above that know not
to inspect during destruction.

In the meantime, there is an unstable attribute that one can use to
assert (unsafely) that a generic type's destructor is \emph{guaranteed}
to not access any expired data, even if its type gives it the capability
to do so.

That attribute is called \texttt{unsafe\_destructor\_blind\_to\_params}.
To deploy it on the Inspector example from above, we would write:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{struct} \NormalTok{Inspector<}\OtherTok{'a}\NormalTok{>(&}\OtherTok{'a} \DataTypeTok{u8}\NormalTok{, &}\OtherTok{'static} \DataTypeTok{str}\NormalTok{);}

\KeywordTok{impl}\NormalTok{<}\OtherTok{'a}\NormalTok{> }\BuiltInTok{Drop} \KeywordTok{for} \NormalTok{Inspector<}\OtherTok{'a}\NormalTok{> \{}
    \AttributeTok{#[}\NormalTok{unsafe_destructor_blind_to_params}\AttributeTok{]}
    \KeywordTok{fn} \NormalTok{drop(&}\KeywordTok{mut} \KeywordTok{self}\NormalTok{) \{}
        \PreprocessorTok{println!}\NormalTok{(}\StringTok{"Inspector(_, \{\}) knows when *not* to inspect."}\NormalTok{, }\KeywordTok{self}\NormalTok{.}\DecValTok{1}\NormalTok{);}
    \NormalTok{\}}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

This attribute has the word \texttt{unsafe} in it because the compiler
is not checking the implicit assertion that no potentially expired data
(e.g. \texttt{self.0} above) is accessed.

It is sometimes obvious that no such access can occur, like the case
above. However, when dealing with a generic type parameter, such access
can occur indirectly. Examples of such indirect access are:

\begin{itemize}
\tightlist
\item
  invoking a callback,
\item
  via a trait method call.
\end{itemize}

(Future changes to the language, such as impl specialization, may add
other avenues for such indirect access.)

Here is an example of invoking a callback:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{struct} \NormalTok{Inspector<T>(T, &}\OtherTok{'static} \DataTypeTok{str}\NormalTok{, }\DataTypeTok{Box}\NormalTok{<}\KeywordTok{for} \NormalTok{<}\OtherTok{'r}\NormalTok{> }\KeywordTok{fn}\NormalTok{(&}\OtherTok{'r} \NormalTok{T) -> }\DataTypeTok{String}\NormalTok{>);}

\KeywordTok{impl}\NormalTok{<T> }\BuiltInTok{Drop} \KeywordTok{for} \NormalTok{Inspector<T> \{}
    \KeywordTok{fn} \NormalTok{drop(&}\KeywordTok{mut} \KeywordTok{self}\NormalTok{) \{}
        \CommentTok{// The `self.2` call could access a borrow e.g. if `T` is `&'a _`.}
        \PreprocessorTok{println!}\NormalTok{(}\StringTok{"Inspector(\{\}, \{\}) unwittingly inspects expired data."}\NormalTok{,}
                 \NormalTok{(}\KeywordTok{self}\NormalTok{.}\DecValTok{2}\NormalTok{)(&}\KeywordTok{self}\NormalTok{.}\DecValTok{0}\NormalTok{), }\KeywordTok{self}\NormalTok{.}\DecValTok{1}\NormalTok{);}
    \NormalTok{\}}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

Here is an example of a trait method call:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{use} \NormalTok{std::fmt;}

\KeywordTok{struct} \NormalTok{Inspector<T: fmt::}\BuiltInTok{Display}\NormalTok{>(T, &}\OtherTok{'static} \DataTypeTok{str}\NormalTok{);}

\KeywordTok{impl}\NormalTok{<T: fmt::}\BuiltInTok{Display}\NormalTok{> }\BuiltInTok{Drop} \KeywordTok{for} \NormalTok{Inspector<T> \{}
    \KeywordTok{fn} \NormalTok{drop(&}\KeywordTok{mut} \KeywordTok{self}\NormalTok{) \{}
        \CommentTok{// There is a hidden call to `<T as Display>::fmt` below, which}
        \CommentTok{// could access a borrow e.g. if `T` is `&'a _`}
        \PreprocessorTok{println!}\NormalTok{(}\StringTok{"Inspector(\{\}, \{\}) unwittingly inspects expired data."}\NormalTok{,}
                 \KeywordTok{self}\NormalTok{.}\DecValTok{0}\NormalTok{, }\KeywordTok{self}\NormalTok{.}\DecValTok{1}\NormalTok{);}
    \NormalTok{\}}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

And of course, all of these accesses could be further hidden within some
other method invoked by the destructor, rather than being written
directly within it.

In all of the above cases where the \texttt{\&\textquotesingle{}a\ u8}
is accessed in the destructor, adding the
\texttt{\#{[}unsafe\_destructor\_blind\_to\_params{]}} attribute makes
the type vulnerable to misuse that the borrower checker will not catch,
inviting havoc. It is better to avoid adding the attribute.

\subsection{Is that all about drop
checker?}\label{is-that-all-about-drop-checker}

It turns out that when writing unsafe code, we generally don't need to
worry at all about doing the right thing for the drop checker. However
there is one special case that you need to worry about, which we will
look at in the next section.

\section{PhantomData}\label{sec--phantom-data}

When working with unsafe code, we can often end up in a situation where
types or lifetimes are logically associated with a struct, but not
actually part of a field. This most commonly occurs with lifetimes. For
instance, the \texttt{Iter} for \texttt{\&\textquotesingle{}a\ {[}T{]}}
is (approximately) defined as follows:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{struct} \NormalTok{Iter<}\OtherTok{'a}\NormalTok{, T: }\OtherTok{'a}\NormalTok{> \{}
    \NormalTok{ptr: *}\KeywordTok{const} \NormalTok{T,}
    \NormalTok{end: *}\KeywordTok{const} \NormalTok{T,}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

However because \texttt{\textquotesingle{}a} is unused within the
struct's body, it's \emph{unbounded}. Because of the troubles this has
historically caused, unbounded lifetimes and types are \emph{forbidden}
in struct definitions. Therefore we must somehow refer to these types in
the body. Correctly doing this is necessary to have correct variance and
drop checking.

We do this using \texttt{PhantomData}, which is a special marker type.
\texttt{PhantomData} consumes no space, but simulates a field of the
given type for the purpose of static analysis. This was deemed to be
less error-prone than explicitly telling the type-system the kind of
variance that you want, while also providing other useful such as the
information needed by drop check.

Iter logically contains a bunch of \texttt{\&\textquotesingle{}a\ T}s,
so this is exactly what we tell the PhantomData to simulate:

\begin{verbatim}
use std::marker;

struct Iter<'a, T: 'a> {
    ptr: *const T,
    end: *const T,
    _marker: marker::PhantomData<&'a T>,
}
\end{verbatim}

and that's it. The lifetime will be bounded, and your iterator will be
variant over \texttt{\textquotesingle{}a} and \texttt{T}. Everything
Just Works.

Another important example is Vec, which is (approximately) defined as
follows:

\begin{verbatim}
struct Vec<T> {
    data: *const T, // *const for variance!
    len: usize,
    cap: usize,
}
\end{verbatim}

Unlike the previous example it \emph{appears} that everything is exactly
as we want. Every generic argument to Vec shows up in the at least one
field. Good to go!

Nope.

The drop checker will generously determine that Vec does not own any
values of type T. This will in turn make it conclude that it doesn't
need to worry about Vec dropping any T's in its destructor for
determining drop check soundness. This will in turn allow people to
create unsoundness using Vec's destructor.

In order to tell dropck that we \emph{do} own values of type T, and
therefore may drop some T's when \emph{we} drop, we must add an extra
PhantomData saying exactly that:

\begin{verbatim}
use std::marker;

struct Vec<T> {
    data: *const T, // *const for covariance!
    len: usize,
    cap: usize,
    _marker: marker::PhantomData<T>,
}
\end{verbatim}

Raw pointers that own an allocation is such a pervasive pattern that the
standard library made a utility for itself called
\texttt{Unique\textless{}T\textgreater{}} which:

\begin{itemize}
\tightlist
\item
  wraps a \texttt{*const\ T} for variance
\item
  includes a \texttt{PhantomData\textless{}T\textgreater{}},
\item
  auto-derives Send/Sync as if T was contained
\item
  marks the pointer as NonZero for the null-pointer optimization
\end{itemize}

\section{Splitting Borrows}\label{sec--borrow-splitting}

The mutual exclusion property of mutable references can be very limiting
when working with a composite structure. The borrow checker understands
some basic stuff, but will fall over pretty easily. It does understand
structs sufficiently to know that it's possible to borrow disjoint
fields of a struct simultaneously. So this works today:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{struct} \NormalTok{Foo \{}
    \NormalTok{a: }\DataTypeTok{i32}\NormalTok{,}
    \NormalTok{b: }\DataTypeTok{i32}\NormalTok{,}
    \NormalTok{c: }\DataTypeTok{i32}\NormalTok{,}
\NormalTok{\}}

\KeywordTok{let} \KeywordTok{mut} \NormalTok{x = Foo \{a: }\DecValTok{0}\NormalTok{, b: }\DecValTok{0}\NormalTok{, c: }\DecValTok{0}\NormalTok{\};}
\KeywordTok{let} \NormalTok{a = &}\KeywordTok{mut} \NormalTok{x.a;}
\KeywordTok{let} \NormalTok{b = &}\KeywordTok{mut} \NormalTok{x.b;}
\KeywordTok{let} \NormalTok{c = &x.c;}
\NormalTok{*b += }\DecValTok{1}\NormalTok{;}
\KeywordTok{let} \NormalTok{c2 = &x.c;}
\NormalTok{*a += }\DecValTok{10}\NormalTok{;}
\PreprocessorTok{println!}\NormalTok{(}\StringTok{"\{\} \{\} \{\} \{\}"}\NormalTok{, a, b, c, c2);}
\end{Highlighting}
\end{Shaded}

However borrowck doesn't understand arrays or slices in any way, so this
doesn't work:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{let} \KeywordTok{mut} \NormalTok{x = [}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{];}
\KeywordTok{let} \NormalTok{a = &}\KeywordTok{mut} \NormalTok{x[}\DecValTok{0}\NormalTok{];}
\KeywordTok{let} \NormalTok{b = &}\KeywordTok{mut} \NormalTok{x[}\DecValTok{1}\NormalTok{];}
\PreprocessorTok{println!}\NormalTok{(}\StringTok{"\{\} \{\}"}\NormalTok{, a, b);}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
<anon>:4:14: 4:18 error: cannot borrow `x[..]` as mutable more than once at a time
<anon>:4 let b = &mut x[1];
                      ^~~~
<anon>:3:14: 3:18 note: previous borrow of `x[..]` occurs here; the mutable borrow pre
â†³ vents subsequent moves, borrows, or modification of `x[..]` until the borrow ends
<anon>:3 let a = &mut x[0];
                      ^~~~
<anon>:6:2: 6:2 note: previous borrow ends here
<anon>:1 fn main() {
<anon>:2 let mut x = [1, 2, 3];
<anon>:3 let a = &mut x[0];
<anon>:4 let b = &mut x[1];
<anon>:5 println!("{} {}", a, b);
<anon>:6 }
         ^
error: aborting due to 2 previous errors
\end{verbatim}

While it was plausible that borrowck could understand this simple case,
it's pretty clearly hopeless for borrowck to understand disjointness in
general container types like a tree, especially if distinct keys
actually \emph{do} map to the same value.

In order to ``teach'' borrowck that what we're doing is ok, we need to
drop down to unsafe code. For instance, mutable slices expose a
\texttt{split\_at\_mut} function that consumes the slice and returns two
mutable slices. One for everything to the left of the index, and one for
everything to the right. Intuitively we know this is safe because the
slices don't overlap, and therefore alias. However the implementation
requires some unsafety:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{fn} \NormalTok{split_at_mut(&}\KeywordTok{mut} \KeywordTok{self}\NormalTok{, mid: }\DataTypeTok{usize}\NormalTok{) -> (&}\KeywordTok{mut} \NormalTok{[T], &}\KeywordTok{mut} \NormalTok{[T]) \{}
    \KeywordTok{let} \NormalTok{len = }\KeywordTok{self}\NormalTok{.len();}
    \KeywordTok{let} \NormalTok{ptr = }\KeywordTok{self}\NormalTok{.as_mut_ptr();}
    \PreprocessorTok{assert!}\NormalTok{(mid <= len);}
    \KeywordTok{unsafe} \NormalTok{\{}
        \NormalTok{(from_raw_parts_mut(ptr, mid),}
         \NormalTok{from_raw_parts_mut(ptr.offset(mid }\KeywordTok{as} \DataTypeTok{isize}\NormalTok{), len - mid))}
    \NormalTok{\}}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

This is actually a bit subtle. So as to avoid ever making two
\texttt{\&mut}'s to the same value, we explicitly construct brand-new
slices through raw pointers.

However more subtle is how iterators that yield mutable references work.
The iterator trait is defined as follows:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{trait} \BuiltInTok{Iterator} \NormalTok{\{}
    \KeywordTok{type} \NormalTok{Item;}

    \KeywordTok{fn} \NormalTok{next(&}\KeywordTok{mut} \KeywordTok{self}\NormalTok{) -> }\DataTypeTok{Option}\NormalTok{<}\KeywordTok{Self}\NormalTok{::Item>;}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

Given this definition, Self::Item has \emph{no} connection to
\texttt{self}. This means that we can call \texttt{next} several times
in a row, and hold onto all the results \emph{concurrently}. This is
perfectly fine for by-value iterators, which have exactly these
semantics. It's also actually fine for shared references, as they admit
arbitrarily many references to the same thing (although the iterator
needs to be a separate object from the thing being shared).

But mutable references make this a mess. At first glance, they might
seem completely incompatible with this API, as it would produce multiple
mutable references to the same object!

However it actually \emph{does} work, exactly because iterators are
one-shot objects. Everything an IterMut yields will be yielded at most
once, so we don't actually ever yield multiple mutable references to the
same piece of data.

Perhaps surprisingly, mutable iterators don't require unsafe code to be
implemented for many types!

For instance here's a singly linked list:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{type} \NormalTok{Link<T> = }\DataTypeTok{Option}\NormalTok{<}\DataTypeTok{Box}\NormalTok{<Node<T>>>;}

\KeywordTok{struct} \NormalTok{Node<T> \{}
    \NormalTok{elem: T,}
    \NormalTok{next: Link<T>,}
\NormalTok{\}}

\KeywordTok{pub} \KeywordTok{struct} \NormalTok{LinkedList<T> \{}
    \NormalTok{head: Link<T>,}
\NormalTok{\}}

\KeywordTok{pub} \KeywordTok{struct} \NormalTok{IterMut<}\OtherTok{'a}\NormalTok{, T: }\OtherTok{'a}\NormalTok{>(}\DataTypeTok{Option}\NormalTok{<&}\OtherTok{'a} \KeywordTok{mut} \NormalTok{Node<T>>);}

\KeywordTok{impl}\NormalTok{<T> LinkedList<T> \{}
    \KeywordTok{fn} \NormalTok{iter_mut(&}\KeywordTok{mut} \KeywordTok{self}\NormalTok{) -> IterMut<T> \{}
        \NormalTok{IterMut(}\KeywordTok{self}\NormalTok{.head.as_mut().map(|node| &}\KeywordTok{mut} \NormalTok{**node))}
    \NormalTok{\}}
\NormalTok{\}}

\KeywordTok{impl}\NormalTok{<}\OtherTok{'a}\NormalTok{, T> }\BuiltInTok{Iterator} \KeywordTok{for} \NormalTok{IterMut<}\OtherTok{'a}\NormalTok{, T> \{}
    \KeywordTok{type} \NormalTok{Item = &}\OtherTok{'a} \KeywordTok{mut} \NormalTok{T;}

    \KeywordTok{fn} \NormalTok{next(&}\KeywordTok{mut} \KeywordTok{self}\NormalTok{) -> }\DataTypeTok{Option}\NormalTok{<}\KeywordTok{Self}\NormalTok{::Item> \{}
        \KeywordTok{self}\NormalTok{.}\DecValTok{0.}\NormalTok{take().map(|node| \{}
            \KeywordTok{self}\NormalTok{.}\DecValTok{0} \NormalTok{= node.next.as_mut().map(|node| &}\KeywordTok{mut} \NormalTok{**node);}
            \NormalTok{&}\KeywordTok{mut} \NormalTok{node.elem}
        \NormalTok{\})}
    \NormalTok{\}}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

Here's a mutable slice:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{use} \NormalTok{std::mem;}

\KeywordTok{pub} \KeywordTok{struct} \NormalTok{IterMut<}\OtherTok{'a}\NormalTok{, T: }\OtherTok{'a}\NormalTok{>(&}\OtherTok{'a} \KeywordTok{mut}\NormalTok{[T]);}

\KeywordTok{impl}\NormalTok{<}\OtherTok{'a}\NormalTok{, T> }\BuiltInTok{Iterator} \KeywordTok{for} \NormalTok{IterMut<}\OtherTok{'a}\NormalTok{, T> \{}
    \KeywordTok{type} \NormalTok{Item = &}\OtherTok{'a} \KeywordTok{mut} \NormalTok{T;}

    \KeywordTok{fn} \NormalTok{next(&}\KeywordTok{mut} \KeywordTok{self}\NormalTok{) -> }\DataTypeTok{Option}\NormalTok{<}\KeywordTok{Self}\NormalTok{::Item> \{}
        \KeywordTok{let} \NormalTok{slice = mem::replace(&}\KeywordTok{mut} \KeywordTok{self}\NormalTok{.}\DecValTok{0}\NormalTok{, &}\KeywordTok{mut} \NormalTok{[]);}
        \KeywordTok{if} \NormalTok{slice.is_empty() \{ }\KeywordTok{return} \ConstantTok{None}\NormalTok{; \}}

        \KeywordTok{let} \NormalTok{(l, r) = slice.split_at_mut(}\DecValTok{1}\NormalTok{);}
        \KeywordTok{self}\NormalTok{.}\DecValTok{0} \NormalTok{= r;}
        \NormalTok{l.get_mut(}\DecValTok{0}\NormalTok{)}
    \NormalTok{\}}
\NormalTok{\}}

\KeywordTok{impl}\NormalTok{<}\OtherTok{'a}\NormalTok{, T> }\BuiltInTok{DoubleEndedIterator} \KeywordTok{for} \NormalTok{IterMut<}\OtherTok{'a}\NormalTok{, T> \{}
    \KeywordTok{fn} \NormalTok{next_back(&}\KeywordTok{mut} \KeywordTok{self}\NormalTok{) -> }\DataTypeTok{Option}\NormalTok{<}\KeywordTok{Self}\NormalTok{::Item> \{}
        \KeywordTok{let} \NormalTok{slice = mem::replace(&}\KeywordTok{mut} \KeywordTok{self}\NormalTok{.}\DecValTok{0}\NormalTok{, &}\KeywordTok{mut} \NormalTok{[]);}
        \KeywordTok{if} \NormalTok{slice.is_empty() \{ }\KeywordTok{return} \ConstantTok{None}\NormalTok{; \}}

        \KeywordTok{let} \NormalTok{new_len = slice.len() - }\DecValTok{1}\NormalTok{;}
        \KeywordTok{let} \NormalTok{(l, r) = slice.split_at_mut(new_len);}
        \KeywordTok{self}\NormalTok{.}\DecValTok{0} \NormalTok{= l;}
        \NormalTok{r.get_mut(}\DecValTok{0}\NormalTok{)}
    \NormalTok{\}}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

And here's a binary tree:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{use} \NormalTok{std::collections::VecDeque;}

\KeywordTok{type} \NormalTok{Link<T> = }\DataTypeTok{Option}\NormalTok{<}\DataTypeTok{Box}\NormalTok{<Node<T>>>;}

\KeywordTok{struct} \NormalTok{Node<T> \{}
    \NormalTok{elem: T,}
    \NormalTok{left: Link<T>,}
    \NormalTok{right: Link<T>,}
\NormalTok{\}}

\KeywordTok{pub} \KeywordTok{struct} \NormalTok{Tree<T> \{}
    \NormalTok{root: Link<T>,}
\NormalTok{\}}

\KeywordTok{struct} \NormalTok{NodeIterMut<}\OtherTok{'a}\NormalTok{, T: }\OtherTok{'a}\NormalTok{> \{}
    \NormalTok{elem: }\DataTypeTok{Option}\NormalTok{<&}\OtherTok{'a} \KeywordTok{mut} \NormalTok{T>,}
    \NormalTok{left: }\DataTypeTok{Option}\NormalTok{<&}\OtherTok{'a} \KeywordTok{mut} \NormalTok{Node<T>>,}
    \NormalTok{right: }\DataTypeTok{Option}\NormalTok{<&}\OtherTok{'a} \KeywordTok{mut} \NormalTok{Node<T>>,}
\NormalTok{\}}

\KeywordTok{enum} \NormalTok{State<}\OtherTok{'a}\NormalTok{, T: }\OtherTok{'a}\NormalTok{> \{}
    \NormalTok{Elem(&}\OtherTok{'a} \KeywordTok{mut} \NormalTok{T),}
    \NormalTok{Node(&}\OtherTok{'a} \KeywordTok{mut} \NormalTok{Node<T>),}
\NormalTok{\}}

\KeywordTok{pub} \KeywordTok{struct} \NormalTok{IterMut<}\OtherTok{'a}\NormalTok{, T: }\OtherTok{'a}\NormalTok{>(VecDeque<NodeIterMut<}\OtherTok{'a}\NormalTok{, T>>);}

\KeywordTok{impl}\NormalTok{<T> Tree<T> \{}
    \KeywordTok{pub} \KeywordTok{fn} \NormalTok{iter_mut(&}\KeywordTok{mut} \KeywordTok{self}\NormalTok{) -> IterMut<T> \{}
        \KeywordTok{let} \KeywordTok{mut} \NormalTok{deque = VecDeque::new();}
        \KeywordTok{self}\NormalTok{.root.as_mut().map(|root| deque.push_front(root.iter_mut()));}
        \NormalTok{IterMut(deque)}
    \NormalTok{\}}
\NormalTok{\}}

\KeywordTok{impl}\NormalTok{<T> Node<T> \{}
    \KeywordTok{pub} \KeywordTok{fn} \NormalTok{iter_mut(&}\KeywordTok{mut} \KeywordTok{self}\NormalTok{) -> NodeIterMut<T> \{}
        \NormalTok{NodeIterMut \{}
            \NormalTok{elem: }\ConstantTok{Some}\NormalTok{(&}\KeywordTok{mut} \KeywordTok{self}\NormalTok{.elem),}
            \NormalTok{left: }\KeywordTok{self}\NormalTok{.left.as_mut().map(|node| &}\KeywordTok{mut} \NormalTok{**node),}
            \NormalTok{right: }\KeywordTok{self}\NormalTok{.right.as_mut().map(|node| &}\KeywordTok{mut} \NormalTok{**node),}
        \NormalTok{\}}
    \NormalTok{\}}
\NormalTok{\}}


\KeywordTok{impl}\NormalTok{<}\OtherTok{'a}\NormalTok{, T> }\BuiltInTok{Iterator} \KeywordTok{for} \NormalTok{NodeIterMut<}\OtherTok{'a}\NormalTok{, T> \{}
    \KeywordTok{type} \NormalTok{Item = State<}\OtherTok{'a}\NormalTok{, T>;}

    \KeywordTok{fn} \NormalTok{next(&}\KeywordTok{mut} \KeywordTok{self}\NormalTok{) -> }\DataTypeTok{Option}\NormalTok{<}\KeywordTok{Self}\NormalTok{::Item> \{}
        \KeywordTok{match} \KeywordTok{self}\NormalTok{.left.take() \{}
            \ConstantTok{Some}\NormalTok{(node) => }\ConstantTok{Some}\NormalTok{(State::Node(node)),}
            \ConstantTok{None} \NormalTok{=> }\KeywordTok{match} \KeywordTok{self}\NormalTok{.elem.take() \{}
                \ConstantTok{Some}\NormalTok{(elem) => }\ConstantTok{Some}\NormalTok{(State::Elem(elem)),}
                \ConstantTok{None} \NormalTok{=> }\KeywordTok{match} \KeywordTok{self}\NormalTok{.right.take() \{}
                    \ConstantTok{Some}\NormalTok{(node) => }\ConstantTok{Some}\NormalTok{(State::Node(node)),}
                    \ConstantTok{None} \NormalTok{=> }\ConstantTok{None}\NormalTok{,}
                \NormalTok{\}}
            \NormalTok{\}}
        \NormalTok{\}}
    \NormalTok{\}}
\NormalTok{\}}

\KeywordTok{impl}\NormalTok{<}\OtherTok{'a}\NormalTok{, T> }\BuiltInTok{DoubleEndedIterator} \KeywordTok{for} \NormalTok{NodeIterMut<}\OtherTok{'a}\NormalTok{, T> \{}
    \KeywordTok{fn} \NormalTok{next_back(&}\KeywordTok{mut} \KeywordTok{self}\NormalTok{) -> }\DataTypeTok{Option}\NormalTok{<}\KeywordTok{Self}\NormalTok{::Item> \{}
        \KeywordTok{match} \KeywordTok{self}\NormalTok{.right.take() \{}
            \ConstantTok{Some}\NormalTok{(node) => }\ConstantTok{Some}\NormalTok{(State::Node(node)),}
            \ConstantTok{None} \NormalTok{=> }\KeywordTok{match} \KeywordTok{self}\NormalTok{.elem.take() \{}
                \ConstantTok{Some}\NormalTok{(elem) => }\ConstantTok{Some}\NormalTok{(State::Elem(elem)),}
                \ConstantTok{None} \NormalTok{=> }\KeywordTok{match} \KeywordTok{self}\NormalTok{.left.take() \{}
                    \ConstantTok{Some}\NormalTok{(node) => }\ConstantTok{Some}\NormalTok{(State::Node(node)),}
                    \ConstantTok{None} \NormalTok{=> }\ConstantTok{None}\NormalTok{,}
                \NormalTok{\}}
            \NormalTok{\}}
        \NormalTok{\}}
    \NormalTok{\}}
\NormalTok{\}}

\KeywordTok{impl}\NormalTok{<}\OtherTok{'a}\NormalTok{, T> }\BuiltInTok{Iterator} \KeywordTok{for} \NormalTok{IterMut<}\OtherTok{'a}\NormalTok{, T> \{}
    \KeywordTok{type} \NormalTok{Item = &}\OtherTok{'a} \KeywordTok{mut} \NormalTok{T;}
    \KeywordTok{fn} \NormalTok{next(&}\KeywordTok{mut} \KeywordTok{self}\NormalTok{) -> }\DataTypeTok{Option}\NormalTok{<}\KeywordTok{Self}\NormalTok{::Item> \{}
        \KeywordTok{loop} \NormalTok{\{}
            \KeywordTok{match} \KeywordTok{self}\NormalTok{.}\DecValTok{0.f}\NormalTok{ront_mut().and_then(|node_it| node_it.next()) \{}
                \ConstantTok{Some}\NormalTok{(State::Elem(elem)) => }\KeywordTok{return} \ConstantTok{Some}\NormalTok{(elem),}
                \ConstantTok{Some}\NormalTok{(State::Node(node)) => }\KeywordTok{self}\NormalTok{.}\DecValTok{0.}\NormalTok{push_front(node.iter_mut()),}
                \ConstantTok{None} \NormalTok{=> }\KeywordTok{if} \KeywordTok{let} \ConstantTok{None} \NormalTok{= }\KeywordTok{self}\NormalTok{.}\DecValTok{0.}\NormalTok{pop_front() \{ }\KeywordTok{return} \ConstantTok{None} \NormalTok{\},}
            \NormalTok{\}}
        \NormalTok{\}}
    \NormalTok{\}}
\NormalTok{\}}

\KeywordTok{impl}\NormalTok{<}\OtherTok{'a}\NormalTok{, T> }\BuiltInTok{DoubleEndedIterator} \KeywordTok{for} \NormalTok{IterMut<}\OtherTok{'a}\NormalTok{, T> \{}
    \KeywordTok{fn} \NormalTok{next_back(&}\KeywordTok{mut} \KeywordTok{self}\NormalTok{) -> }\DataTypeTok{Option}\NormalTok{<}\KeywordTok{Self}\NormalTok{::Item> \{}
        \KeywordTok{loop} \NormalTok{\{}
            \KeywordTok{match} \KeywordTok{self}\NormalTok{.}\DecValTok{0.}\NormalTok{back_mut().and_then(|node_it| node_it.next_back()) \{}
                \ConstantTok{Some}\NormalTok{(State::Elem(elem)) => }\KeywordTok{return} \ConstantTok{Some}\NormalTok{(elem),}
                \ConstantTok{Some}\NormalTok{(State::Node(node)) => }\KeywordTok{self}\NormalTok{.}\DecValTok{0.}\NormalTok{push_back(node.iter_mut()),}
                \ConstantTok{None} \NormalTok{=> }\KeywordTok{if} \KeywordTok{let} \ConstantTok{None} \NormalTok{= }\KeywordTok{self}\NormalTok{.}\DecValTok{0.}\NormalTok{pop_back() \{ }\KeywordTok{return} \ConstantTok{None} \NormalTok{\},}
            \NormalTok{\}}
        \NormalTok{\}}
    \NormalTok{\}}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

All of these are completely safe and work on stable Rust! This
ultimately falls out of the simple struct case we saw before: Rust
understands that you can safely split a mutable reference into
subfields. We can then encode permanently consuming a reference via
Options (or in the case of slices, replacing with an empty slice).

\chapter{Type Conversions}\label{sec--conversions}

At the end of the day, everything is just a pile of bits somewhere, and
type systems are just there to help us use those bits right. There are
two common problems with typing bits: needing to reinterpret those exact
bits as a different type, and needing to change the bits to have
equivalent meaning for a different type. Because Rust encourages
encoding important properties in the type system, these problems are
incredibly pervasive. As such, Rust consequently gives you several ways
to solve them.

First we'll look at the ways that Safe Rust gives you to reinterpret
values. The most trivial way to do this is to just destructure a value
into its constituent parts and then build a new type out of them. e.g.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{struct} \NormalTok{Foo \{}
    \NormalTok{x: }\DataTypeTok{u32}\NormalTok{,}
    \NormalTok{y: }\DataTypeTok{u16}\NormalTok{,}
\NormalTok{\}}

\KeywordTok{struct} \NormalTok{Bar \{}
    \NormalTok{a: }\DataTypeTok{u32}\NormalTok{,}
    \NormalTok{b: }\DataTypeTok{u16}\NormalTok{,}
\NormalTok{\}}

\KeywordTok{fn} \NormalTok{reinterpret(foo: Foo) -> Bar \{}
    \KeywordTok{let} \NormalTok{Foo \{ x, y \} = foo;}
    \NormalTok{Bar \{ a: x, b: y \}}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

But this is, at best, annoying. For common conversions, Rust provides
more ergonomic alternatives.

\section{Coercions}\label{sec--coercions}

Types can implicitly be coerced to change in certain contexts. These
changes are generally just \emph{weakening} of types, largely focused
around pointers and lifetimes. They mostly exist to make Rust ``just
work'' in more cases, and are largely harmless.

Here's all the kinds of coercion:

Coercion is allowed between the following types:

\begin{itemize}
\tightlist
\item
  Transitivity: \texttt{T\_1} to \texttt{T\_3} where \texttt{T\_1}
  coerces to \texttt{T\_2} and \texttt{T\_2} coerces to \texttt{T\_3}
\item
  Pointer Weakening:

  \begin{itemize}
  \tightlist
  \item
    \texttt{\&mut\ T} to \texttt{\&T}
  \item
    \texttt{*mut\ T} to \texttt{*const\ T}
  \item
    \texttt{\&T} to \texttt{*const\ T}
  \item
    \texttt{\&mut\ T} to \texttt{*mut\ T}
  \end{itemize}
\item
  Unsizing: \texttt{T} to \texttt{U} if \texttt{T} implements
  \texttt{CoerceUnsized\textless{}U\textgreater{}}
\end{itemize}

\texttt{CoerceUnsized\textless{}Pointer\textless{}U\textgreater{}\textgreater{}\ for\ Pointer\textless{}T\textgreater{}\ where\ T:\ Unsize\textless{}U\textgreater{}}
is implemented for all pointer types (including smart pointers like Box
and Rc). Unsize is only implemented automatically, and enables the
following transformations:

\begin{itemize}
\tightlist
\item
  \texttt{{[}T;\ n{]}} =\textgreater{} \texttt{{[}T{]}}
\item
  \texttt{T} =\textgreater{} \texttt{Trait} where \texttt{T:\ Trait}
\item
  \texttt{Foo\textless{}...,\ T,\ ...\textgreater{}} =\textgreater{}
  \texttt{Foo\textless{}...,\ U,\ ...\textgreater{}} where:

  \begin{itemize}
  \tightlist
  \item
    \texttt{T:\ Unsize\textless{}U\textgreater{}}
  \item
    \texttt{Foo} is a struct
  \item
    Only the last field of \texttt{Foo} has type \texttt{T}
  \item
    \texttt{T} is not part of the type of any other fields
  \end{itemize}
\end{itemize}

Coercions occur at a \emph{coercion site}. Any location that is
explicitly typed will cause a coercion to its type. If inference is
necessary, the coercion will not be performed. Exhaustively, the
coercion sites for an expression \texttt{e} to type \texttt{U} are:

\begin{itemize}
\tightlist
\item
  let statements, statics, and consts: \texttt{let\ x:\ U\ =\ e}
\item
  Arguments to functions: \texttt{takes\_a\_U(e)}
\item
  Any expression that will be returned:
  \texttt{fn\ foo()\ -\textgreater{}\ U\ \{\ e\ \}}
\item
  Struct literals: \texttt{Foo\ \{\ some\_u:\ e\ \}}
\item
  Array literals: \texttt{let\ x:\ {[}U;\ 10{]}\ =\ {[}e,\ ..{]}}
\item
  Tuple literals: \texttt{let\ x:\ (U,\ ..)\ =\ (e,\ ..)}
\item
  The last expression in a block: \texttt{let\ x:\ U\ =\ \{\ ..;\ e\ \}}
\end{itemize}

Note that we do not perform coercions when matching traits (except for
receivers, see below). If there is an impl for some type \texttt{U} and
\texttt{T} coerces to \texttt{U}, that does not constitute an
implementation for \texttt{T}. For example, the following will not type
check, even though it is OK to coerce \texttt{t} to \texttt{\&T} and
there is an impl for \texttt{\&T}:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{trait} \NormalTok{Trait \{\}}

\KeywordTok{fn} \NormalTok{foo<X: Trait>(t: X) \{\}}

\KeywordTok{impl}\NormalTok{<}\OtherTok{'a}\NormalTok{> Trait }\KeywordTok{for} \NormalTok{&}\OtherTok{'a} \DataTypeTok{i32} \NormalTok{\{\}}


\KeywordTok{fn} \NormalTok{main() \{}
    \KeywordTok{let} \NormalTok{t: &}\KeywordTok{mut} \DataTypeTok{i32} \NormalTok{= &}\KeywordTok{mut} \DecValTok{0}\NormalTok{;}
    \NormalTok{foo(t);}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
<anon>:10:5: 10:8 error: the trait bound `&mut i32 : Trait` is not satisfied [E0277]
<anon>:10     foo(t);
              ^~~
\end{verbatim}

\section{The Dot Operator}\label{sec--dot-operator}

The dot operator will perform a lot of magic to convert types. It will
perform auto-referencing, auto-dereferencing, and coercion until types
match.

TODO: steal information from
http://stackoverflow.com/questions/28519997/what-are-rusts-exact-auto-dereferencing-rules/28552082\#28552082

\section{Casts}\label{sec--casts}

Casts are a superset of coercions: every coercion can be explicitly
invoked via a cast. However some conversions require a cast. While
coercions are pervasive and largely harmless, these ``true casts'' are
rare and potentially dangerous. As such, casts must be explicitly
invoked using the \texttt{as} keyword: \texttt{expr\ as\ Type}.

True casts generally revolve around raw pointers and the primitive
numeric types. Even though they're dangerous, these casts are infallible
at runtime. If a cast triggers some subtle corner case no indication
will be given that this occurred. The cast will simply succeed. That
said, casts must be valid at the type level, or else they will be
prevented statically. For instance, \texttt{7u8\ as\ bool} will not
compile.

That said, casts aren't \texttt{unsafe} because they generally can't
violate memory safety \emph{on their own}. For instance, converting an
integer to a raw pointer can very easily lead to terrible things.
However the act of creating the pointer itself is safe, because actually
using a raw pointer is already marked as \texttt{unsafe}.

Here's an exhaustive list of all the true casts. For brevity, we will
use \texttt{*} to denote either a \texttt{*const} or \texttt{*mut}, and
\texttt{integer} to denote any integral primitive:

\begin{itemize}
\tightlist
\item
  \texttt{*T\ as\ *U} where \texttt{T,\ U:\ Sized}
\item
  \texttt{*T\ as\ *U} TODO: explain unsized situation
\item
  \texttt{*T\ as\ integer}
\item
  \texttt{integer\ as\ *T}
\item
  \texttt{number\ as\ number}
\item
  \texttt{C-like-enum\ as\ integer}
\item
  \texttt{bool\ as\ integer}
\item
  \texttt{char\ as\ integer}
\item
  \texttt{u8\ as\ char}
\item
  \texttt{\&{[}T;\ n{]}\ as\ *const\ T}
\item
  \texttt{fn\ as\ *T} where \texttt{T:\ Sized}
\item
  \texttt{fn\ as\ integer}
\end{itemize}

Note that lengths are not adjusted when casting raw slices -
\texttt{*const\ {[}u16{]}\ as\ *const\ {[}u8{]}} creates a slice that
only includes half of the original memory.

Casting is not transitive, that is, even if \texttt{e\ as\ U1\ as\ U2}
is a valid expression, \texttt{e\ as\ U2} is not necessarily so.

For numeric casts, there are quite a few cases to consider:

\begin{itemize}
\tightlist
\item
  casting between two integers of the same size (e.g.~i32
  -\textgreater{} u32) is a no-op
\item
  casting from a larger integer to a smaller integer (e.g.~u32
  -\textgreater{} u8) will truncate
\item
  casting from a smaller integer to a larger integer (e.g.~u8
  -\textgreater{} u32) will

  \begin{itemize}
  \tightlist
  \item
    zero-extend if the source is unsigned
  \item
    sign-extend if the source is signed
  \end{itemize}
\item
  casting from a float to an integer will round the float towards zero

  \begin{itemize}
  \tightlist
  \item
    \textbf{\href{https://github.com/rust-lang/rust/issues/10184}{NOTE:
    currently this will cause Undefined Behavior if the rounded value
    cannot be represented by the target integer type}}. This includes
    Inf and NaN. This is a bug and will be fixed.
  \end{itemize}
\item
  casting from an integer to float will produce the floating point
  representation of the integer, rounded if necessary (rounding strategy
  unspecified)
\item
  casting from an f32 to an f64 is perfect and lossless
\item
  casting from an f64 to an f32 will produce the closest possible value
  (rounding strategy unspecified)

  \begin{itemize}
  \tightlist
  \item
    \textbf{\href{https://github.com/rust-lang/rust/issues/15536}{NOTE:
    currently this will cause Undefined Behavior if the value is finite
    but larger or smaller than the largest or smallest finite value
    representable by f32}}. This is a bug and will be fixed.
  \end{itemize}
\end{itemize}

\section{Transmutes}\label{sec--transmutes}

Get out of our way type system! We're going to reinterpret these bits or
die trying! Even though this book is all about doing things that are
unsafe, I really can't emphasize that you should deeply think about
finding Another Way than the operations covered in this section. This is
really, truly, the most horribly unsafe thing you can do in Rust. The
railguards here are dental floss.

\texttt{mem::transmute\textless{}T,\ U\textgreater{}} takes a value of
type \texttt{T} and reinterprets it to have type \texttt{U}. The only
restriction is that the \texttt{T} and \texttt{U} are verified to have
the same size. The ways to cause Undefined Behavior with this are mind
boggling.

\begin{itemize}
\tightlist
\item
  First and foremost, creating an instance of \emph{any} type with an
  invalid state is going to cause arbitrary chaos that can't really be
  predicted.
\item
  Transmute has an overloaded return type. If you do not specify the
  return type it may produce a surprising type to satisfy inference.
\item
  Making a primitive with an invalid value is UB
\item
  Transmuting between non-repr(C) types is UB
\item
  Transmuting an \& to \&mut is UB

  \begin{itemize}
  \tightlist
  \item
    Transmuting an \& to \&mut is \emph{always} UB
  \item
    No you can't do it
  \item
    No you're not special
  \end{itemize}
\item
  Transmuting to a reference without an explicitly provided lifetime
  produces an {[}unbounded lifetime{]}
\end{itemize}

\texttt{mem::transmute\_copy\textless{}T,\ U\textgreater{}} somehow
manages to be \emph{even more} wildly unsafe than this. It copies
\texttt{size\_of\textless{}U\textgreater{}} bytes out of an \texttt{\&T}
and interprets them as a \texttt{U}. The size check that
\texttt{mem::transmute} has is gone (as it may be valid to copy out a
prefix), though it is Undefined Behavior for \texttt{U} to be larger
than \texttt{T}.

Also of course you can get most of the functionality of these functions
using pointer casts.

\hypertarget{sec--uninitialized}{\chapter{Uninitialized
Memory}\label{sec--uninitialized}}

All runtime-allocated memory in a Rust program begins its life as
\emph{uninitialized}. In this state the value of the memory is an
indeterminate pile of bits that may or may not even reflect a valid
state for the type that is supposed to inhabit that location of memory.
Attempting to interpret this memory as a value of \emph{any} type will
cause Undefined Behavior. Do Not Do This.

Rust provides mechanisms to work with uninitialized memory in checked
(safe) and unchecked (unsafe) ways.

\section{Checked}\label{sec--checked-uninit}

Like C, all stack variables in Rust are uninitialized until a value is
explicitly assigned to them. Unlike C, Rust statically prevents you from
ever reading them until you do:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{fn} \NormalTok{main() \{}
    \KeywordTok{let} \NormalTok{x: }\DataTypeTok{i32}\NormalTok{;}
    \PreprocessorTok{println!}\NormalTok{(}\StringTok{"\{\}"}\NormalTok{, x);}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
src/main.rs:3:20: 3:21 error: use of possibly uninitialized variable: `x`
src/main.rs:3     println!("{}", x);
                                 ^
\end{verbatim}

This is based off of a basic branch analysis: every branch must assign a
value to \texttt{x} before it is first used. Interestingly, Rust doesn't
require the variable to be mutable to perform a delayed initialization
if every branch assigns exactly once. However the analysis does not take
advantage of constant analysis or anything like that. So this compiles:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{fn} \NormalTok{main() \{}
    \KeywordTok{let} \NormalTok{x: }\DataTypeTok{i32}\NormalTok{;}

    \KeywordTok{if} \ConstantTok{true} \NormalTok{\{}
        \NormalTok{x = }\DecValTok{1}\NormalTok{;}
    \NormalTok{\} }\KeywordTok{else} \NormalTok{\{}
        \NormalTok{x = }\DecValTok{2}\NormalTok{;}
    \NormalTok{\}}

    \PreprocessorTok{println!}\NormalTok{(}\StringTok{"\{\}"}\NormalTok{, x);}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

but this doesn't:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{fn} \NormalTok{main() \{}
    \KeywordTok{let} \NormalTok{x: }\DataTypeTok{i32}\NormalTok{;}
    \KeywordTok{if} \ConstantTok{true} \NormalTok{\{}
        \NormalTok{x = }\DecValTok{1}\NormalTok{;}
    \NormalTok{\}}
    \PreprocessorTok{println!}\NormalTok{(}\StringTok{"\{\}"}\NormalTok{, x);}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
src/main.rs:6:17: 6:18 error: use of possibly uninitialized variable: `x`
src/main.rs:6   println!("{}", x);
\end{verbatim}

while this does:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{fn} \NormalTok{main() \{}
    \KeywordTok{let} \NormalTok{x: }\DataTypeTok{i32}\NormalTok{;}
    \KeywordTok{if} \ConstantTok{true} \NormalTok{\{}
        \NormalTok{x = }\DecValTok{1}\NormalTok{;}
        \PreprocessorTok{println!}\NormalTok{(}\StringTok{"\{\}"}\NormalTok{, x);}
    \NormalTok{\}}
    \CommentTok{// Don't care that there are branches where it's not initialized}
    \CommentTok{// since we don't use the value in those branches}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

Of course, while the analysis doesn't consider actual values, it does
have a relatively sophisticated understanding of dependencies and
control flow. For instance, this works:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{let} \NormalTok{x: }\DataTypeTok{i32}\NormalTok{;}

\KeywordTok{loop} \NormalTok{\{}
    \CommentTok{// Rust doesn't understand that this branch will be taken unconditionally,}
    \CommentTok{// because it relies on actual values.}
    \KeywordTok{if} \ConstantTok{true} \NormalTok{\{}
        \CommentTok{// But it does understand that it will only be taken once because}
        \CommentTok{// we unconditionally break out of it. Therefore `x` doesn't}
        \CommentTok{// need to be marked as mutable.}
        \NormalTok{x = }\DecValTok{0}\NormalTok{;}
        \KeywordTok{break}\NormalTok{;}
    \NormalTok{\}}
\NormalTok{\}}
\CommentTok{// It also knows that it's impossible to get here without reaching the break.}
\CommentTok{// And therefore that `x` must be initialized here!}
\PreprocessorTok{println!}\NormalTok{(}\StringTok{"\{\}"}\NormalTok{, x);}
\end{Highlighting}
\end{Shaded}

If a value is moved out of a variable, that variable becomes logically
uninitialized if the type of the value isn't Copy. That is:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{fn} \NormalTok{main() \{}
    \KeywordTok{let} \NormalTok{x = }\DecValTok{0}\NormalTok{;}
    \KeywordTok{let} \NormalTok{y = }\DataTypeTok{Box}\NormalTok{::new(}\DecValTok{0}\NormalTok{);}
    \KeywordTok{let} \NormalTok{z1 = x; }\CommentTok{// x is still valid because i32 is Copy}
    \KeywordTok{let} \NormalTok{z2 = y; }\CommentTok{// y is now logically uninitialized because Box isn't Copy}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

However reassigning \texttt{y} in this example \emph{would} require
\texttt{y} to be marked as mutable, as a Safe Rust program could observe
that the value of \texttt{y} changed:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{fn} \NormalTok{main() \{}
    \KeywordTok{let} \KeywordTok{mut} \NormalTok{y = }\DataTypeTok{Box}\NormalTok{::new(}\DecValTok{0}\NormalTok{);}
    \KeywordTok{let} \NormalTok{z = y; }\CommentTok{// y is now logically uninitialized because Box isn't Copy}
    \NormalTok{y = }\DataTypeTok{Box}\NormalTok{::new(}\DecValTok{1}\NormalTok{); }\CommentTok{// reinitialize y}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

Otherwise it's like \texttt{y} is a brand new variable.

\hypertarget{sec--drop-flags}{\section{Drop
Flags}\label{sec--drop-flags}}

The examples in the previous section introduce an interesting problem
for Rust. We have seen that it's possible to conditionally initialize,
deinitialize, and reinitialize locations of memory totally safely. For
Copy types, this isn't particularly notable since they're just a random
pile of bits. However types with destructors are a different story: Rust
needs to know whether to call a destructor whenever a variable is
assigned to, or a variable goes out of scope. How can it do this with
conditional initialization?

Note that this is not a problem that all assignments need worry about.
In particular, assigning through a dereference unconditionally drops,
and assigning in a \texttt{let} unconditionally doesn't drop:

\begin{verbatim}
let mut x = Box::new(0); // let makes a fresh variable, so never need to drop
let y = &mut x;
*y = Box::new(1); // Deref assumes the referent is initialized, so always drops
\end{verbatim}

This is only a problem when overwriting a previously initialized
variable or one of its subfields.

It turns out that Rust actually tracks whether a type should be dropped
or not \emph{at runtime}. As a variable becomes initialized and
uninitialized, a \emph{drop flag} for that variable is toggled. When a
variable might need to be dropped, this flag is evaluated to determine
if it should be dropped.

Of course, it is often the case that a value's initialization state can
be statically known at every point in the program. If this is the case,
then the compiler can theoretically generate more efficient code! For
instance, straight- line code has such \emph{static drop semantics}:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{let} \KeywordTok{mut} \NormalTok{x = }\DataTypeTok{Box}\NormalTok{::new(}\DecValTok{0}\NormalTok{); }\CommentTok{// x was uninit; just overwrite.}
\KeywordTok{let} \KeywordTok{mut} \NormalTok{y = x;           }\CommentTok{// y was uninit; just overwrite and make x uninit.}
\NormalTok{x = }\DataTypeTok{Box}\NormalTok{::new(}\DecValTok{0}\NormalTok{);         }\CommentTok{// x was uninit; just overwrite.}
\NormalTok{y = x;                   }\CommentTok{// y was init; Drop y, overwrite it, and make x uninit!}
                         \CommentTok{// y goes out of scope; y was init; Drop y!}
                         \CommentTok{// x goes out of scope; x was uninit; do nothing.}
\end{Highlighting}
\end{Shaded}

Similarly, branched code where all branches have the same behavior with
respect to initialization has static drop semantics:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{let} \KeywordTok{mut} \NormalTok{x = }\DataTypeTok{Box}\NormalTok{::new(}\DecValTok{0}\NormalTok{);    }\CommentTok{// x was uninit; just overwrite.}
\KeywordTok{if} \NormalTok{condition \{}
    \NormalTok{drop(x)                 }\CommentTok{// x gets moved out; make x uninit.}
\NormalTok{\} }\KeywordTok{else} \NormalTok{\{}
    \PreprocessorTok{println!}\NormalTok{(}\StringTok{"\{\}"}\NormalTok{, x);}
    \NormalTok{drop(x)                 }\CommentTok{// x gets moved out; make x uninit.}
\NormalTok{\}}
\NormalTok{x = }\DataTypeTok{Box}\NormalTok{::new(}\DecValTok{0}\NormalTok{);            }\CommentTok{// x was uninit; just overwrite.}
                            \CommentTok{// x goes out of scope; x was init; Drop x!}
\end{Highlighting}
\end{Shaded}

However code like this \emph{requires} runtime information to correctly
Drop:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{let} \NormalTok{x;}
\KeywordTok{if} \NormalTok{condition \{}
    \NormalTok{x = }\DataTypeTok{Box}\NormalTok{::new(}\DecValTok{0}\NormalTok{);        }\CommentTok{// x was uninit; just overwrite.}
    \PreprocessorTok{println!}\NormalTok{(}\StringTok{"\{\}"}\NormalTok{, x);}
\NormalTok{\}}
                            \CommentTok{// x goes out of scope; x might be uninit;}
                            \CommentTok{// check the flag!}
\end{Highlighting}
\end{Shaded}

Of course, in this case it's trivial to retrieve static drop semantics:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{if} \NormalTok{condition \{}
    \KeywordTok{let} \NormalTok{x = }\DataTypeTok{Box}\NormalTok{::new(}\DecValTok{0}\NormalTok{);}
    \PreprocessorTok{println!}\NormalTok{(}\StringTok{"\{\}"}\NormalTok{, x);}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

As of Rust 1.0, the drop flags are actually not-so-secretly stashed in a
hidden field of any type that implements Drop. Rust sets the drop flag
by overwriting the entire value with a particular bit pattern. This is
pretty obviously Not The Fastest and causes a bunch of trouble with
optimizing code. It's legacy from a time when you could do much more
complex conditional initialization.

As such work is currently under way to move the flags out onto the stack
frame where they more reasonably belong. Unfortunately, this work will
take some time as it requires fairly substantial changes to the
compiler.

Regardless, Rust programs don't need to worry about uninitialized values
on the stack for correctness. Although they might care for performance.
Thankfully, Rust makes it easy to take control here! Uninitialized
values are there, and you can work with them in Safe Rust, but you're
never in danger.

\section{Unchecked}\label{sec--unchecked-uninit}

One interesting exception to this rule is working with arrays. Safe Rust
doesn't permit you to partially initialize an array. When you initialize
an array, you can either set every value to the same thing with
\texttt{let\ x\ =\ {[}val;\ N{]}}, or you can specify each member
individually with \texttt{let\ x\ =\ {[}val1,\ val2,\ val3{]}}.
Unfortunately this is pretty rigid, especially if you need to initialize
your array in a more incremental or dynamic way.

Unsafe Rust gives us a powerful tool to handle this problem:
\texttt{mem::uninitialized}. This function pretends to return a value
when really it does nothing at all. Using it, we can convince Rust that
we have initialized a variable, allowing us to do trickier things with
conditional and incremental initialization.

Unfortunately, this opens us up to all kinds of problems. Assignment has
a different meaning to Rust based on whether it believes that a variable
is initialized or not. If it's believed uninitialized, then Rust will
semantically just memcopy the bits over the uninitialized ones, and do
nothing else. However if Rust believes a value to be initialized, it
will try to \texttt{Drop} the old value! Since we've tricked Rust into
believing that the value is initialized, we can no longer safely use
normal assignment.

This is also a problem if you're working with a raw system allocator,
which returns a pointer to uninitialized memory.

To handle this, we must use the \texttt{ptr} module. In particular, it
provides three functions that allow us to assign bytes to a location in
memory without dropping the old value: \texttt{write}, \texttt{copy},
and \texttt{copy\_nonoverlapping}.

\begin{itemize}
\tightlist
\item
  \texttt{ptr::write(ptr,\ val)} takes a \texttt{val} and moves it into
  the address pointed to by \texttt{ptr}.
\item
  \texttt{ptr::copy(src,\ dest,\ count)} copies the bits that
  \texttt{count} T's would occupy from src to dest. (this is equivalent
  to memmove -- note that the argument order is reversed!)
\item
  \texttt{ptr::copy\_nonoverlapping(src,\ dest,\ count)} does what
  \texttt{copy} does, but a little faster on the assumption that the two
  ranges of memory don't overlap. (this is equivalent to memcpy -- note
  that the argument order is reversed!)
\end{itemize}

It should go without saying that these functions, if misused, will cause
serious havoc or just straight up Undefined Behavior. The only things
that these functions \emph{themselves} require is that the locations you
want to read and write are allocated. However the ways writing arbitrary
bits to arbitrary locations of memory can break things are basically
uncountable!

Putting this all together, we get the following:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{use} \NormalTok{std::mem;}
\KeywordTok{use} \NormalTok{std::ptr;}

\CommentTok{// size of the array is hard-coded but easy to change. This means we can't}
\CommentTok{// use [a, b, c] syntax to initialize the array, though!}
\KeywordTok{const} \NormalTok{SIZE: }\DataTypeTok{usize} \NormalTok{= }\DecValTok{10}\NormalTok{;}

\KeywordTok{let} \KeywordTok{mut} \NormalTok{x: [}\DataTypeTok{Box}\NormalTok{<}\DataTypeTok{u32}\NormalTok{>; SIZE];}

\KeywordTok{unsafe} \NormalTok{\{}
    \CommentTok{// convince Rust that x is Totally Initialized}
    \NormalTok{x = mem::uninitialized();}
    \KeywordTok{for} \NormalTok{i }\KeywordTok{in} \DecValTok{0.}\NormalTok{.SIZE \{}
        \CommentTok{// very carefully overwrite each index without reading it}
        \CommentTok{// NOTE: exception safety is not a concern; Box can't panic}
        \NormalTok{ptr::write(&}\KeywordTok{mut} \NormalTok{x[i], }\DataTypeTok{Box}\NormalTok{::new(i }\KeywordTok{as} \DataTypeTok{u32}\NormalTok{));}
    \NormalTok{\}}
\NormalTok{\}}

\PreprocessorTok{println!}\NormalTok{(}\StringTok{"\{:?\}"}\NormalTok{, x);}
\end{Highlighting}
\end{Shaded}

It's worth noting that you don't need to worry about
\texttt{ptr::write}-style shenanigans with types which don't implement
\texttt{Drop} or contain \texttt{Drop} types, because Rust knows not to
try to drop them. Similarly you should be able to assign to fields of
partially initialized structs directly if those fields don't contain any
\texttt{Drop} types.

However when working with uninitialized memory you need to be
ever-vigilant for Rust trying to drop values you make like this before
they're fully initialized. Every control path through that variable's
scope must initialize the value before it ends, if it has a destructor.
\emph{\protect\hyperlink{sec--unwinding}{This includes code panicking}}.

And that's about it for working with uninitialized memory! Basically
nothing anywhere expects to be handed uninitialized memory, so if you're
going to pass it around at all, be sure to be \emph{really} careful.

\chapter{Ownership Based Resource Management}\label{sec--obrm}

OBRM (AKA RAII: Resource Acquisition Is Initialization) is something
you'll interact with a lot in Rust. Especially if you use the standard
library.

Roughly speaking the pattern is as follows: to acquire a resource, you
create an object that manages it. To release the resource, you simply
destroy the object, and it cleans up the resource for you. The most
common ``resource'' this pattern manages is simply \emph{memory}.
\texttt{Box}, \texttt{Rc}, and basically everything in
\texttt{std::collections} is a convenience to enable correctly managing
memory. This is particularly important in Rust because we have no
pervasive GC to rely on for memory management. Which is the point,
really: Rust is about control. However we are not limited to just
memory. Pretty much every other system resource like a thread, file, or
socket is exposed through this kind of API.

\section{Constructors}\label{sec--constructors}

There is exactly one way to create an instance of a user-defined type:
name it, and initialize all its fields at once:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{struct} \NormalTok{Foo \{}
    \NormalTok{a: }\DataTypeTok{u8}\NormalTok{,}
    \NormalTok{b: }\DataTypeTok{u32}\NormalTok{,}
    \NormalTok{c: }\DataTypeTok{bool}\NormalTok{,}
\NormalTok{\}}

\KeywordTok{enum} \NormalTok{Bar \{}
    \NormalTok{X(}\DataTypeTok{u32}\NormalTok{),}
    \NormalTok{Y(}\DataTypeTok{bool}\NormalTok{),}
\NormalTok{\}}

\KeywordTok{struct} \NormalTok{Unit;}

\KeywordTok{let} \NormalTok{foo = Foo \{ a: }\DecValTok{0}\NormalTok{, b: }\DecValTok{1}\NormalTok{, c: }\ConstantTok{false} \NormalTok{\};}
\KeywordTok{let} \NormalTok{bar = Bar::X(}\DecValTok{0}\NormalTok{);}
\KeywordTok{let} \NormalTok{empty = Unit;}
\end{Highlighting}
\end{Shaded}

That's it. Every other way you make an instance of a type is just
calling a totally vanilla function that does some stuff and eventually
bottoms out to The One True Constructor.

Unlike C++, Rust does not come with a slew of built-in kinds of
constructor. There are no Copy, Default, Assignment, Move, or whatever
constructors. The reasons for this are varied, but it largely boils down
to Rust's philosophy of \emph{being explicit}.

Move constructors are meaningless in Rust because we don't enable types
to ``care'' about their location in memory. Every type must be ready for
it to be blindly memcopied to somewhere else in memory. This means pure
on-the-stack-but- still-movable intrusive linked lists are simply not
happening in Rust (safely).

Assignment and copy constructors similarly don't exist because move
semantics are the only semantics in Rust. At most \texttt{x\ =\ y} just
moves the bits of y into the x variable. Rust does provide two
facilities for providing C++'s copy- oriented semantics: \texttt{Copy}
and \texttt{Clone}. Clone is our moral equivalent of a copy constructor,
but it's never implicitly invoked. You have to explicitly call
\texttt{clone} on an element you want to be cloned. Copy is a special
case of Clone where the implementation is just ``copy the bits''. Copy
types \emph{are} implicitly cloned whenever they're moved, but because
of the definition of Copy this just means not treating the old copy as
uninitialized -- a no-op.

While Rust provides a \texttt{Default} trait for specifying the moral
equivalent of a default constructor, it's incredibly rare for this trait
to be used. This is because variables
\protect\hyperlink{sec--uninitialized}{aren't implicitly initialized}.
Default is basically only useful for generic programming. In concrete
contexts, a type will provide a static \texttt{new} method for any kind
of ``default'' constructor. This has no relation to \texttt{new} in
other languages and has no special meaning. It's just a naming
convention.

TODO: talk about ``placement new''?

\section{Destructors}\label{sec--destructors}

What the language \emph{does} provide is full-blown automatic
destructors through the \texttt{Drop} trait, which provides the
following method:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{fn} \NormalTok{drop(&}\KeywordTok{mut} \KeywordTok{self}\NormalTok{);}
\end{Highlighting}
\end{Shaded}

This method gives the type time to somehow finish what it was doing.

\textbf{After \texttt{drop} is run, Rust will recursively try to drop
all of the fields of \texttt{self}.}

This is a convenience feature so that you don't have to write
``destructor boilerplate'' to drop children. If a struct has no special
logic for being dropped other than dropping its children, then it means
\texttt{Drop} doesn't need to be implemented at all!

\textbf{There is no stable way to prevent this behavior in Rust 1.0.}

Note that taking \texttt{\&mut\ self} means that even if you could
suppress recursive Drop, Rust will prevent you from e.g.~moving fields
out of self. For most types, this is totally fine.

For instance, a custom implementation of \texttt{Box} might write
\texttt{Drop} like this:

\begin{Shaded}
\begin{Highlighting}[]
\AttributeTok{#![}\NormalTok{feature}\AttributeTok{(}\NormalTok{alloc}\AttributeTok{,} \NormalTok{heap_api}\AttributeTok{,} \NormalTok{drop_in_place}\AttributeTok{,} \NormalTok{unique}\AttributeTok{)]}

\KeywordTok{extern} \KeywordTok{crate} \NormalTok{alloc;}

\KeywordTok{use} \NormalTok{std::ptr::\{drop_in_place, Unique\};}
\KeywordTok{use} \NormalTok{std::mem;}

\KeywordTok{use} \NormalTok{alloc::heap;}

\KeywordTok{struct} \DataTypeTok{Box}\NormalTok{<T>\{ ptr: Unique<T> \}}

\KeywordTok{impl}\NormalTok{<T> }\BuiltInTok{Drop} \KeywordTok{for} \DataTypeTok{Box}\NormalTok{<T> \{}
    \KeywordTok{fn} \NormalTok{drop(&}\KeywordTok{mut} \KeywordTok{self}\NormalTok{) \{}
        \KeywordTok{unsafe} \NormalTok{\{}
            \NormalTok{drop_in_place(*}\KeywordTok{self}\NormalTok{.ptr);}
            \NormalTok{heap::deallocate((*}\KeywordTok{self}\NormalTok{.ptr) }\KeywordTok{as} \NormalTok{*}\KeywordTok{mut} \DataTypeTok{u8}\NormalTok{,}
                             \NormalTok{mem::size_of::<T>(),}
                             \NormalTok{mem::align_of::<T>());}
        \NormalTok{\}}
    \NormalTok{\}}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

and this works fine because when Rust goes to drop the \texttt{ptr}
field it just sees a {[}Unique{]} that has no actual \texttt{Drop}
implementation. Similarly nothing can use-after-free the \texttt{ptr}
because when drop exits, it becomes inaccessible.

However this wouldn't work:

\begin{Shaded}
\begin{Highlighting}[]
\AttributeTok{#![}\NormalTok{feature}\AttributeTok{(}\NormalTok{alloc}\AttributeTok{,} \NormalTok{heap_api}\AttributeTok{,} \NormalTok{drop_in_place}\AttributeTok{,} \NormalTok{unique}\AttributeTok{)]}

\KeywordTok{extern} \KeywordTok{crate} \NormalTok{alloc;}

\KeywordTok{use} \NormalTok{std::ptr::\{drop_in_place, Unique\};}
\KeywordTok{use} \NormalTok{std::mem;}

\KeywordTok{use} \NormalTok{alloc::heap;}

\KeywordTok{struct} \DataTypeTok{Box}\NormalTok{<T>\{ ptr: Unique<T> \}}

\KeywordTok{impl}\NormalTok{<T> }\BuiltInTok{Drop} \KeywordTok{for} \DataTypeTok{Box}\NormalTok{<T> \{}
    \KeywordTok{fn} \NormalTok{drop(&}\KeywordTok{mut} \KeywordTok{self}\NormalTok{) \{}
        \KeywordTok{unsafe} \NormalTok{\{}
            \NormalTok{drop_in_place(*}\KeywordTok{self}\NormalTok{.ptr);}
            \NormalTok{heap::deallocate((*}\KeywordTok{self}\NormalTok{.ptr) }\KeywordTok{as} \NormalTok{*}\KeywordTok{mut} \DataTypeTok{u8}\NormalTok{,}
                             \NormalTok{mem::size_of::<T>(),}
                             \NormalTok{mem::align_of::<T>());}
        \NormalTok{\}}
    \NormalTok{\}}
\NormalTok{\}}

\KeywordTok{struct} \NormalTok{SuperBox<T> \{ my_box: }\DataTypeTok{Box}\NormalTok{<T> \}}

\KeywordTok{impl}\NormalTok{<T> }\BuiltInTok{Drop} \KeywordTok{for} \NormalTok{SuperBox<T> \{}
    \KeywordTok{fn} \NormalTok{drop(&}\KeywordTok{mut} \KeywordTok{self}\NormalTok{) \{}
        \KeywordTok{unsafe} \NormalTok{\{}
            \CommentTok{// Hyper-optimized: deallocate the box's contents for it}
            \CommentTok{// without `drop`ing the contents}
            \NormalTok{heap::deallocate((*}\KeywordTok{self}\NormalTok{.my_box.ptr) }\KeywordTok{as} \NormalTok{*}\KeywordTok{mut} \DataTypeTok{u8}\NormalTok{,}
                             \NormalTok{mem::size_of::<T>(),}
                             \NormalTok{mem::align_of::<T>());}
        \NormalTok{\}}
    \NormalTok{\}}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

After we deallocate the \texttt{box}'s ptr in SuperBox's destructor,
Rust will happily proceed to tell the box to Drop itself and everything
will blow up with use-after-frees and double-frees.

Note that the recursive drop behavior applies to all structs and enums
regardless of whether they implement Drop. Therefore something like

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{struct} \NormalTok{Boxy<T> \{}
    \NormalTok{data1: }\DataTypeTok{Box}\NormalTok{<T>,}
    \NormalTok{data2: }\DataTypeTok{Box}\NormalTok{<T>,}
    \NormalTok{info: }\DataTypeTok{u32}\NormalTok{,}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

will have its data1 and data2's fields destructors whenever it ``would''
be dropped, even though it itself doesn't implement Drop. We say that
such a type \emph{needs Drop}, even though it is not itself Drop.

Similarly,

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{enum} \NormalTok{Link \{}
    \NormalTok{Next(}\DataTypeTok{Box}\NormalTok{<Link>),}
    \ConstantTok{None}\NormalTok{,}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

will have its inner Box field dropped if and only if an instance stores
the Next variant.

In general this works really nicely because you don't need to worry
about adding/removing drops when you refactor your data layout. Still
there's certainly many valid usecases for needing to do trickier things
with destructors.

The classic safe solution to overriding recursive drop and allowing
moving out of Self during \texttt{drop} is to use an Option:

\begin{Shaded}
\begin{Highlighting}[]
\AttributeTok{#![}\NormalTok{feature}\AttributeTok{(}\NormalTok{alloc}\AttributeTok{,} \NormalTok{heap_api}\AttributeTok{,} \NormalTok{drop_in_place}\AttributeTok{,} \NormalTok{unique}\AttributeTok{)]}

\KeywordTok{extern} \KeywordTok{crate} \NormalTok{alloc;}

\KeywordTok{use} \NormalTok{std::ptr::\{drop_in_place, Unique\};}
\KeywordTok{use} \NormalTok{std::mem;}

\KeywordTok{use} \NormalTok{alloc::heap;}

\KeywordTok{struct} \DataTypeTok{Box}\NormalTok{<T>\{ ptr: Unique<T> \}}

\KeywordTok{impl}\NormalTok{<T> }\BuiltInTok{Drop} \KeywordTok{for} \DataTypeTok{Box}\NormalTok{<T> \{}
    \KeywordTok{fn} \NormalTok{drop(&}\KeywordTok{mut} \KeywordTok{self}\NormalTok{) \{}
        \KeywordTok{unsafe} \NormalTok{\{}
            \NormalTok{drop_in_place(*}\KeywordTok{self}\NormalTok{.ptr);}
            \NormalTok{heap::deallocate((*}\KeywordTok{self}\NormalTok{.ptr) }\KeywordTok{as} \NormalTok{*}\KeywordTok{mut} \DataTypeTok{u8}\NormalTok{,}
                             \NormalTok{mem::size_of::<T>(),}
                             \NormalTok{mem::align_of::<T>());}
        \NormalTok{\}}
    \NormalTok{\}}
\NormalTok{\}}

\KeywordTok{struct} \NormalTok{SuperBox<T> \{ my_box: }\DataTypeTok{Option}\NormalTok{<}\DataTypeTok{Box}\NormalTok{<T>> \}}

\KeywordTok{impl}\NormalTok{<T> }\BuiltInTok{Drop} \KeywordTok{for} \NormalTok{SuperBox<T> \{}
    \KeywordTok{fn} \NormalTok{drop(&}\KeywordTok{mut} \KeywordTok{self}\NormalTok{) \{}
        \KeywordTok{unsafe} \NormalTok{\{}
            \CommentTok{// Hyper-optimized: deallocate the box's contents for it}
            \CommentTok{// without `drop`ing the contents. Need to set the `box`}
            \CommentTok{// field as `None` to prevent Rust from trying to Drop it.}
            \KeywordTok{let} \NormalTok{my_box = }\KeywordTok{self}\NormalTok{.my_box.take().unwrap();}
            \NormalTok{heap::deallocate((*my_box.ptr) }\KeywordTok{as} \NormalTok{*}\KeywordTok{mut} \DataTypeTok{u8}\NormalTok{,}
                             \NormalTok{mem::size_of::<T>(),}
                             \NormalTok{mem::align_of::<T>());}
            \NormalTok{mem::forget(my_box);}
        \NormalTok{\}}
    \NormalTok{\}}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

However this has fairly odd semantics: you're saying that a field that
\emph{should} always be Some \emph{may} be None, just because that
happens in the destructor. Of course this conversely makes a lot of
sense: you can call arbitrary methods on self during the destructor, and
this should prevent you from ever doing so after deinitializing the
field. Not that it will prevent you from producing any other arbitrarily
invalid state in there.

On balance this is an ok choice. Certainly what you should reach for by
default. However, in the future we expect there to be a first-class way
to announce that a field shouldn't be automatically dropped.

\hypertarget{sec--leaking}{\section{Leaking}\label{sec--leaking}}

Ownership-based resource management is intended to simplify composition.
You acquire resources when you create the object, and you release the
resources when it gets destroyed. Since destruction is handled for you,
it means you can't forget to release the resources, and it happens as
soon as possible! Surely this is perfect and all of our problems are
solved.

Everything is terrible and we have new and exotic problems to try to
solve.

Many people like to believe that Rust eliminates resource leaks. In
practice, this is basically true. You would be surprised to see a Safe
Rust program leak resources in an uncontrolled way.

However from a theoretical perspective this is absolutely not the case,
no matter how you look at it. In the strictest sense, ``leaking'' is so
abstract as to be unpreventable. It's quite trivial to initialize a
collection at the start of a program, fill it with tons of objects with
destructors, and then enter an infinite event loop that never refers to
it. The collection will sit around uselessly, holding on to its precious
resources until the program terminates (at which point all those
resources would have been reclaimed by the OS anyway).

We may consider a more restricted form of leak: failing to drop a value
that is unreachable. Rust also doesn't prevent this. In fact Rust
\emph{has a function for doing this}: \texttt{mem::forget}. This
function consumes the value it is passed \emph{and then doesn't run its
destructor}.

In the past \texttt{mem::forget} was marked as unsafe as a sort of lint
against using it, since failing to call a destructor is generally not a
well-behaved thing to do (though useful for some special unsafe code).
However this was generally determined to be an untenable stance to take:
there are many ways to fail to call a destructor in safe code. The most
famous example is creating a cycle of reference-counted pointers using
interior mutability.

It is reasonable for safe code to assume that destructor leaks do not
happen, as any program that leaks destructors is probably wrong. However
\emph{unsafe} code cannot rely on destructors to be run in order to be
safe. For most types this doesn't matter: if you leak the destructor
then the type is by definition inaccessible, so it doesn't matter,
right? For instance, if you leak a
\texttt{Box\textless{}u8\textgreater{}} then you waste some memory but
that's hardly going to violate memory-safety.

However where we must be careful with destructor leaks are \emph{proxy}
types. These are types which manage access to a distinct object, but
don't actually own it. Proxy objects are quite rare. Proxy objects
you'll need to care about are even rarer. However we'll focus on three
interesting examples in the standard library:

\begin{itemize}
\tightlist
\item
  \texttt{vec::Drain}
\item
  \texttt{Rc}
\item
  \texttt{thread::scoped::JoinGuard}
\end{itemize}

\subsubsection{Drain}\label{drain}

\texttt{drain} is a collections API that moves data out of the container
without consuming the container. This enables us to reuse the allocation
of a \texttt{Vec} after claiming ownership over all of its contents. It
produces an iterator (Drain) that returns the contents of the Vec
by-value.

Now, consider Drain in the middle of iteration: some values have been
moved out, and others haven't. This means that part of the Vec is now
full of logically uninitialized data! We could backshift all the
elements in the Vec every time we remove a value, but this would have
pretty catastrophic performance consequences.

Instead, we would like Drain to fix the Vec's backing storage when it is
dropped. It should run itself to completion, backshift any elements that
weren't removed (drain supports subranges), and then fix Vec's
\texttt{len}. It's even unwinding-safe! Easy!

Now consider the following:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{let} \KeywordTok{mut} \NormalTok{vec = }\PreprocessorTok{vec!}\NormalTok{[}\DataTypeTok{Box}\NormalTok{::new(}\DecValTok{0}\NormalTok{); }\DecValTok{4}\NormalTok{];}

\NormalTok{\{}
    \CommentTok{// start draining, vec can no longer be accessed}
    \KeywordTok{let} \KeywordTok{mut} \NormalTok{drainer = vec.drain(..);}

    \CommentTok{// pull out two elements and immediately drop them}
    \NormalTok{drainer.next();}
    \NormalTok{drainer.next();}

    \CommentTok{// get rid of drainer, but don't call its destructor}
    \NormalTok{mem::forget(drainer);}
\NormalTok{\}}

\CommentTok{// Oops, vec[0] was dropped, we're reading a pointer into free'd memory!}
\PreprocessorTok{println!}\NormalTok{(}\StringTok{"\{\}"}\NormalTok{, vec[}\DecValTok{0}\NormalTok{]);}
\end{Highlighting}
\end{Shaded}

This is pretty clearly Not Good. Unfortunately, we're kind of stuck
between a rock and a hard place: maintaining consistent state at every
step has an enormous cost (and would negate any benefits of the API).
Failing to maintain consistent state gives us Undefined Behavior in safe
code (making the API unsound).

So what can we do? Well, we can pick a trivially consistent state: set
the Vec's len to be 0 when we start the iteration, and fix it up if
necessary in the destructor. That way, if everything executes like
normal we get the desired behavior with minimal overhead. But if someone
has the \emph{audacity} to mem::forget us in the middle of the
iteration, all that does is \emph{leak even more} (and possibly leave
the Vec in an unexpected but otherwise consistent state). Since we've
accepted that mem::forget is safe, this is definitely safe. We call
leaks causing more leaks a \emph{leak amplification}.

\subsubsection{Rc}\label{rc}

Rc is an interesting case because at first glance it doesn't appear to
be a proxy value at all. After all, it manages the data it points to,
and dropping all the Rcs for a value will drop that value. Leaking an Rc
doesn't seem like it would be particularly dangerous. It will leave the
refcount permanently incremented and prevent the data from being freed
or dropped, but that seems just like Box, right?

Nope.

Let's consider a simplified implementation of Rc:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{struct} \NormalTok{Rc<T> \{}
    \NormalTok{ptr: *}\KeywordTok{mut} \NormalTok{RcBox<T>,}
\NormalTok{\}}

\KeywordTok{struct} \NormalTok{RcBox<T> \{}
    \NormalTok{data: T,}
    \NormalTok{ref_count: }\DataTypeTok{usize}\NormalTok{,}
\NormalTok{\}}

\KeywordTok{impl}\NormalTok{<T> Rc<T> \{}
    \KeywordTok{fn} \NormalTok{new(data: T) -> }\KeywordTok{Self} \NormalTok{\{}
        \KeywordTok{unsafe} \NormalTok{\{}
            \CommentTok{// Wouldn't it be nice if heap::allocate worked like this?}
            \KeywordTok{let} \NormalTok{ptr = heap::allocate::<RcBox<T>>();}
            \NormalTok{ptr::write(ptr, RcBox \{}
                \NormalTok{data: data,}
                \NormalTok{ref_count: }\DecValTok{1}\NormalTok{,}
            \NormalTok{\});}
            \NormalTok{Rc \{ ptr: ptr \}}
        \NormalTok{\}}
    \NormalTok{\}}

    \KeywordTok{fn} \NormalTok{clone(&}\KeywordTok{self}\NormalTok{) -> }\KeywordTok{Self} \NormalTok{\{}
        \KeywordTok{unsafe} \NormalTok{\{}
            \NormalTok{(*}\KeywordTok{self}\NormalTok{.ptr).ref_count += }\DecValTok{1}\NormalTok{;}
        \NormalTok{\}}
        \NormalTok{Rc \{ ptr: }\KeywordTok{self}\NormalTok{.ptr \}}
    \NormalTok{\}}
\NormalTok{\}}

\KeywordTok{impl}\NormalTok{<T> }\BuiltInTok{Drop} \KeywordTok{for} \NormalTok{Rc<T> \{}
    \KeywordTok{fn} \NormalTok{drop(&}\KeywordTok{mut} \KeywordTok{self}\NormalTok{) \{}
        \KeywordTok{unsafe} \NormalTok{\{}
            \NormalTok{(*}\KeywordTok{self}\NormalTok{.ptr).ref_count -= }\DecValTok{1}\NormalTok{;}
            \KeywordTok{if} \NormalTok{(*}\KeywordTok{self}\NormalTok{.ptr).ref_count == }\DecValTok{0} \NormalTok{\{}
                \CommentTok{// drop the data and then free it}
                \NormalTok{ptr::read(}\KeywordTok{self}\NormalTok{.ptr);}
                \NormalTok{heap::deallocate(}\KeywordTok{self}\NormalTok{.ptr);}
            \NormalTok{\}}
        \NormalTok{\}}
    \NormalTok{\}}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

This code contains an implicit and subtle assumption:
\texttt{ref\_count} can fit in a \texttt{usize}, because there can't be
more than \texttt{usize::MAX} Rcs in memory. However this itself assumes
that the \texttt{ref\_count} accurately reflects the number of Rcs in
memory, which we know is false with \texttt{mem::forget}. Using
\texttt{mem::forget} we can overflow the \texttt{ref\_count}, and then
get it down to 0 with outstanding Rcs. Then we can happily
use-after-free the inner data. Bad Bad Not Good.

This can be solved by just checking the \texttt{ref\_count} and doing
\emph{something}. The standard library's stance is to just abort,
because your program has become horribly degenerate. Also \emph{oh my
gosh} it's such a ridiculous corner case.

\subsubsection{thread::scoped::JoinGuard}\label{threadscopedjoinguard}

The thread::scoped API intends to allow threads to be spawned that
reference data on their parent's stack without any synchronization over
that data by ensuring the parent joins the thread before any of the
shared data goes out of scope.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{pub} \KeywordTok{fn} \NormalTok{scoped<}\OtherTok{'a}\NormalTok{, F>(f: F) -> JoinGuard<}\OtherTok{'a}\NormalTok{>}
    \KeywordTok{where} \NormalTok{F: }\BuiltInTok{FnOnce}\NormalTok{() + }\BuiltInTok{Send} \NormalTok{+ }\OtherTok{'a}
\end{Highlighting}
\end{Shaded}

Here \texttt{f} is some closure for the other thread to execute. Saying
that \texttt{F:\ Send\ +\textquotesingle{}a} is saying that it closes
over data that lives for \texttt{\textquotesingle{}a}, and it either
owns that data or the data was Sync (implying \texttt{\&data} is Send).

Because JoinGuard has a lifetime, it keeps all the data it closes over
borrowed in the parent thread. This means the JoinGuard can't outlive
the data that the other thread is working on. When the JoinGuard
\emph{does} get dropped it blocks the parent thread, ensuring the child
terminates before any of the closed-over data goes out of scope in the
parent.

Usage looked like:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{let} \KeywordTok{mut} \NormalTok{data = [}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{7}\NormalTok{, }\DecValTok{8}\NormalTok{, }\DecValTok{9}\NormalTok{, }\DecValTok{10}\NormalTok{];}
\NormalTok{\{}
    \KeywordTok{let} \NormalTok{guards = }\PreprocessorTok{vec!}\NormalTok{[];}
    \KeywordTok{for} \NormalTok{x }\KeywordTok{in} \NormalTok{&}\KeywordTok{mut} \NormalTok{data \{}
        \CommentTok{// Move the mutable reference into the closure, and execute}
        \CommentTok{// it on a different thread. The closure has a lifetime bound}
        \CommentTok{// by the lifetime of the mutable reference `x` we store in it.}
        \CommentTok{// The guard that is returned is in turn assigned the lifetime}
        \CommentTok{// of the closure, so it also mutably borrows `data` as `x` did.}
        \CommentTok{// This means we cannot access `data` until the guard goes away.}
        \KeywordTok{let} \NormalTok{guard = thread::scoped(}\KeywordTok{move} \NormalTok{|| \{}
            \NormalTok{*x *= }\DecValTok{2}\NormalTok{;}
        \NormalTok{\});}
        \CommentTok{// store the thread's guard for later}
        \NormalTok{guards.push(guard);}
    \NormalTok{\}}
    \CommentTok{// All guards are dropped here, forcing the threads to join}
    \CommentTok{// (this thread blocks here until the others terminate).}
    \CommentTok{// Once the threads join, the borrow expires and the data becomes}
    \CommentTok{// accessible again in this thread.}
\NormalTok{\}}
\CommentTok{// data is definitely mutated here.}
\end{Highlighting}
\end{Shaded}

In principle, this totally works! Rust's ownership system perfectly
ensures it! \ldots{}except it relies on a destructor being called to be
safe.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{let} \KeywordTok{mut} \NormalTok{data = }\DataTypeTok{Box}\NormalTok{::new(}\DecValTok{0}\NormalTok{);}
\NormalTok{\{}
    \KeywordTok{let} \NormalTok{guard = thread::scoped(|| \{}
        \CommentTok{// This is at best a data race. At worst, it's also a use-after-free.}
        \NormalTok{*data += }\DecValTok{1}\NormalTok{;}
    \NormalTok{\});}
    \CommentTok{// Because the guard is forgotten, expiring the loan without blocking this}
    \CommentTok{// thread.}
    \NormalTok{mem::forget(guard);}
\NormalTok{\}}
\CommentTok{// So the Box is dropped here while the scoped thread may or may not be trying}
\CommentTok{// to access it.}
\end{Highlighting}
\end{Shaded}

Dang. Here the destructor running was pretty fundamental to the API, and
it had to be scrapped in favor of a completely different design.

\hypertarget{sec--unwinding}{\chapter{Unwinding}\label{sec--unwinding}}

Rust has a \emph{tiered} error-handling scheme:

\begin{itemize}
\tightlist
\item
  If something might reasonably be absent, Option is used.
\item
  If something goes wrong and can reasonably be handled, Result is used.
\item
  If something goes wrong and cannot reasonably be handled, the thread
  panics.
\item
  If something catastrophic happens, the program aborts.
\end{itemize}

Option and Result are overwhelmingly preferred in most situations,
especially since they can be promoted into a panic or abort at the API
user's discretion. Panics cause the thread to halt normal execution and
unwind its stack, calling destructors as if every function instantly
returned.

As of 1.0, Rust is of two minds when it comes to panics. In the
long-long-ago, Rust was much more like Erlang. Like Erlang, Rust had
lightweight tasks, and tasks were intended to kill themselves with a
panic when they reached an untenable state. Unlike an exception in Java
or C++, a panic could not be caught at any time. Panics could only be
caught by the owner of the task, at which point they had to be handled
or \emph{that} task would itself panic.

Unwinding was important to this story because if a task's destructors
weren't called, it would cause memory and other system resources to
leak. Since tasks were expected to die during normal execution, this
would make Rust very poor for long-running systems!

As the Rust we know today came to be, this style of programming grew out
of fashion in the push for less-and-less abstraction. Light-weight tasks
were killed in the name of heavy-weight OS threads. Still, on stable
Rust as of 1.0 panics can only be caught by the parent thread. This
means catching a panic requires spinning up an entire OS thread! This
unfortunately stands in conflict to Rust's philosophy of zero-cost
abstractions.

There is an unstable API called \texttt{catch\_panic} that enables
catching a panic without spawning a thread. Still, we would encourage
you to only do this sparingly. In particular, Rust's current unwinding
implementation is heavily optimized for the ``doesn't unwind'' case. If
a program doesn't unwind, there should be no runtime cost for the
program being \emph{ready} to unwind. As a consequence, actually
unwinding will be more expensive than in e.g.~Java. Don't build your
programs to unwind under normal circumstances. Ideally, you should only
panic for programming errors or \emph{extreme} problems.

Rust's unwinding strategy is not specified to be fundamentally
compatible with any other language's unwinding. As such, unwinding into
Rust from another language, or unwinding into another language from Rust
is Undefined Behavior. You must \emph{absolutely} catch any panics at
the FFI boundary! What you do at that point is up to you, but
\emph{something} must be done. If you fail to do this, at best, your
application will crash and burn. At worst, your application \emph{won't}
crash and burn, and will proceed with completely clobbered state.

\section{Exception Safety}\label{sec--exception-safety}

Although programs should use unwinding sparingly, there's a lot of code
that \emph{can} panic. If you unwrap a None, index out of bounds, or
divide by 0, your program will panic. On debug builds, every arithmetic
operation can panic if it overflows. Unless you are very careful and
tightly control what code runs, pretty much everything can unwind, and
you need to be ready for it.

Being ready for unwinding is often referred to as \emph{exception
safety} in the broader programming world. In Rust, there are two levels
of exception safety that one may concern themselves with:

\begin{itemize}
\item
  In unsafe code, we \emph{must} be exception safe to the point of not
  violating memory safety. We'll call this \emph{minimal} exception
  safety.
\item
  In safe code, it is \emph{good} to be exception safe to the point of
  your program doing the right thing. We'll call this \emph{maximal}
  exception safety.
\end{itemize}

As is the case in many places in Rust, Unsafe code must be ready to deal
with bad Safe code when it comes to unwinding. Code that transiently
creates unsound states must be careful that a panic does not cause that
state to be used. Generally this means ensuring that only non-panicking
code is run while these states exist, or making a guard that cleans up
the state in the case of a panic. This does not necessarily mean that
the state a panic witnesses is a fully coherent state. We need only
guarantee that it's a \emph{safe} state.

Most Unsafe code is leaf-like, and therefore fairly easy to make
exception-safe. It controls all the code that runs, and most of that
code can't panic. However it is not uncommon for Unsafe code to work
with arrays of temporarily uninitialized data while repeatedly invoking
caller-provided code. Such code needs to be careful and consider
exception safety.

\subsubsection{Vec::push\_all}\label{vecpushux5fall}

\texttt{Vec::push\_all} is a temporary hack to get extending a Vec by a
slice reliably efficient without specialization. Here's a simple
implementation:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{impl}\NormalTok{<T: }\BuiltInTok{Clone}\NormalTok{> }\DataTypeTok{Vec}\NormalTok{<T> \{}
    \KeywordTok{fn} \NormalTok{push_all(&}\KeywordTok{mut} \KeywordTok{self}\NormalTok{, to_push: &[T]) \{}
        \KeywordTok{self}\NormalTok{.reserve(to_push.len());}
        \KeywordTok{unsafe} \NormalTok{\{}
            \CommentTok{// can't overflow because we just reserved this}
            \KeywordTok{self}\NormalTok{.set_len(}\KeywordTok{self}\NormalTok{.len() + to_push.len());}

            \KeywordTok{for} \NormalTok{(i, x) }\KeywordTok{in} \NormalTok{to_push.iter().enumerate() \{}
                \KeywordTok{self}\NormalTok{.ptr().offset(i }\KeywordTok{as} \DataTypeTok{isize}\NormalTok{).write(x.clone());}
            \NormalTok{\}}
        \NormalTok{\}}
    \NormalTok{\}}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

We bypass \texttt{push} in order to avoid redundant capacity and
\texttt{len} checks on the Vec that we definitely know has capacity. The
logic is totally correct, except there's a subtle problem with our code:
it's not exception-safe! \texttt{set\_len}, \texttt{offset}, and
\texttt{write} are all fine; \texttt{clone} is the panic bomb we
over-looked.

Clone is completely out of our control, and is totally free to panic. If
it does, our function will exit early with the length of the Vec set too
large. If the Vec is looked at or dropped, uninitialized memory will be
read!

The fix in this case is fairly simple. If we want to guarantee that the
values we \emph{did} clone are dropped, we can set the \texttt{len}
every loop iteration. If we just want to guarantee that uninitialized
memory can't be observed, we can set the \texttt{len} after the loop.

\subsubsection{BinaryHeap::sift\_up}\label{binaryheapsiftux5fup}

Bubbling an element up a heap is a bit more complicated than extending a
Vec. The pseudocode is as follows:

\begin{verbatim}
bubble_up(heap, index):
    while index != 0 && heap[index] < heap[parent(index)]:
        heap.swap(index, parent(index))
        index = parent(index)
\end{verbatim}

A literal transcription of this code to Rust is totally fine, but has an
annoying performance characteristic: the \texttt{self} element is
swapped over and over again uselessly. We would rather have the
following:

\begin{verbatim}
bubble_up(heap, index):
    let elem = heap[index]
    while index != 0 && element < heap[parent(index)]:
        heap[index] = heap[parent(index)]
        index = parent(index)
    heap[index] = elem
\end{verbatim}

This code ensures that each element is copied as little as possible (it
is in fact necessary that elem be copied twice in general). However it
now exposes some exception safety trouble! At all times, there exists
two copies of one value. If we panic in this function something will be
double-dropped. Unfortunately, we also don't have full control of the
code: that comparison is user-defined!

Unlike Vec, the fix isn't as easy here. One option is to break the
user-defined code and the unsafe code into two separate phases:

\begin{verbatim}
bubble_up(heap, index):
    let end_index = index;
    while end_index != 0 && heap[end_index] < heap[parent(end_index)]:
        end_index = parent(end_index)

    let elem = heap[index]
    while index != end_index:
        heap[index] = heap[parent(index)]
        index = parent(index)
    heap[index] = elem
\end{verbatim}

If the user-defined code blows up, that's no problem anymore, because we
haven't actually touched the state of the heap yet. Once we do start
messing with the heap, we're working with only data and functions that
we trust, so there's no concern of panics.

Perhaps you're not happy with this design. Surely it's cheating! And we
have to do the complex heap traversal \emph{twice}! Alright, let's bite
the bullet. Let's intermix untrusted and unsafe code \emph{for reals}.

If Rust had \texttt{try} and \texttt{finally} like in Java, we could do
the following:

\begin{verbatim}
bubble_up(heap, index):
    let elem = heap[index]
    try:
        while index != 0 && element < heap[parent(index)]:
            heap[index] = heap[parent(index)]
            index = parent(index)
    finally:
        heap[index] = elem
\end{verbatim}

The basic idea is simple: if the comparison panics, we just toss the
loose element in the logically uninitialized index and bail out. Anyone
who observes the heap will see a potentially \emph{inconsistent} heap,
but at least it won't cause any double-drops! If the algorithm
terminates normally, then this operation happens to coincide precisely
with the how we finish up regardless.

Sadly, Rust has no such construct, so we're going to need to roll our
own! The way to do this is to store the algorithm's state in a separate
struct with a destructor for the ``finally'' logic. Whether we panic or
not, that destructor will run and clean up after us.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{struct} \NormalTok{Hole<}\OtherTok{'a}\NormalTok{, T: }\OtherTok{'a}\NormalTok{> \{}
    \NormalTok{data: &}\OtherTok{'a} \KeywordTok{mut} \NormalTok{[T],}
    \CommentTok{/// `elt` is always `Some` from new until drop.}
    \NormalTok{elt: }\DataTypeTok{Option}\NormalTok{<T>,}
    \NormalTok{pos: }\DataTypeTok{usize}\NormalTok{,}
\NormalTok{\}}

\KeywordTok{impl}\NormalTok{<}\OtherTok{'a}\NormalTok{, T> Hole<}\OtherTok{'a}\NormalTok{, T> \{}
    \KeywordTok{fn} \NormalTok{new(data: &}\OtherTok{'a} \KeywordTok{mut} \NormalTok{[T], pos: }\DataTypeTok{usize}\NormalTok{) -> }\KeywordTok{Self} \NormalTok{\{}
        \KeywordTok{unsafe} \NormalTok{\{}
            \KeywordTok{let} \NormalTok{elt = ptr::read(&data[pos]);}
            \NormalTok{Hole \{}
                \NormalTok{data: data,}
                \NormalTok{elt: }\ConstantTok{Some}\NormalTok{(elt),}
                \NormalTok{pos: pos,}
            \NormalTok{\}}
        \NormalTok{\}}
    \NormalTok{\}}

    \KeywordTok{fn} \NormalTok{pos(&}\KeywordTok{self}\NormalTok{) -> }\DataTypeTok{usize} \NormalTok{\{ }\KeywordTok{self}\NormalTok{.pos \}}

    \KeywordTok{fn} \NormalTok{removed(&}\KeywordTok{self}\NormalTok{) -> &T \{ }\KeywordTok{self}\NormalTok{.elt.as_ref().unwrap() \}}

    \KeywordTok{unsafe} \KeywordTok{fn} \NormalTok{get(&}\KeywordTok{self}\NormalTok{, index: }\DataTypeTok{usize}\NormalTok{) -> &T \{ &}\KeywordTok{self}\NormalTok{.data[index] \}}

    \KeywordTok{unsafe} \KeywordTok{fn} \NormalTok{move_to(&}\KeywordTok{mut} \KeywordTok{self}\NormalTok{, index: }\DataTypeTok{usize}\NormalTok{) \{}
        \KeywordTok{let} \NormalTok{index_ptr: *}\KeywordTok{const} \NormalTok{_ = &}\KeywordTok{self}\NormalTok{.data[index];}
        \KeywordTok{let} \NormalTok{hole_ptr = &}\KeywordTok{mut} \KeywordTok{self}\NormalTok{.data[}\KeywordTok{self}\NormalTok{.pos];}
        \NormalTok{ptr::copy_nonoverlapping(index_ptr, hole_ptr, }\DecValTok{1}\NormalTok{);}
        \KeywordTok{self}\NormalTok{.pos = index;}
    \NormalTok{\}}
\NormalTok{\}}

\KeywordTok{impl}\NormalTok{<}\OtherTok{'a}\NormalTok{, T> }\BuiltInTok{Drop} \KeywordTok{for} \NormalTok{Hole<}\OtherTok{'a}\NormalTok{, T> \{}
    \KeywordTok{fn} \NormalTok{drop(&}\KeywordTok{mut} \KeywordTok{self}\NormalTok{) \{}
        \CommentTok{// fill the hole again}
        \KeywordTok{unsafe} \NormalTok{\{}
            \KeywordTok{let} \NormalTok{pos = }\KeywordTok{self}\NormalTok{.pos;}
            \NormalTok{ptr::write(&}\KeywordTok{mut} \KeywordTok{self}\NormalTok{.data[pos], }\KeywordTok{self}\NormalTok{.elt.take().unwrap());}
        \NormalTok{\}}
    \NormalTok{\}}
\NormalTok{\}}

\KeywordTok{impl}\NormalTok{<T: }\BuiltInTok{Ord}\NormalTok{> BinaryHeap<T> \{}
    \KeywordTok{fn} \NormalTok{sift_up(&}\KeywordTok{mut} \KeywordTok{self}\NormalTok{, pos: }\DataTypeTok{usize}\NormalTok{) \{}
        \KeywordTok{unsafe} \NormalTok{\{}
            \CommentTok{// Take out the value at `pos` and create a hole.}
            \KeywordTok{let} \KeywordTok{mut} \NormalTok{hole = Hole::new(&}\KeywordTok{mut} \KeywordTok{self}\NormalTok{.data, pos);}

            \KeywordTok{while} \NormalTok{hole.pos() != }\DecValTok{0} \NormalTok{\{}
                \KeywordTok{let} \NormalTok{parent = parent(hole.pos());}
                \KeywordTok{if} \NormalTok{hole.removed() <= hole.get(parent) \{ }\KeywordTok{break} \NormalTok{\}}
                \NormalTok{hole.move_to(parent);}
            \NormalTok{\}}
            \CommentTok{// Hole will be unconditionally filled here; panic or not!}
        \NormalTok{\}}
    \NormalTok{\}}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\section{Poisoning}\label{sec--poisoning}

Although all unsafe code \emph{must} ensure it has minimal exception
safety, not all types ensure \emph{maximal} exception safety. Even if
the type does, your code may ascribe additional meaning to it. For
instance, an integer is certainly exception-safe, but has no semantics
on its own. It's possible that code that panics could fail to correctly
update the integer, producing an inconsistent program state.

This is \emph{usually} fine, because anything that witnesses an
exception is about to get destroyed. For instance, if you send a Vec to
another thread and that thread panics, it doesn't matter if the Vec is
in a weird state. It will be dropped and go away forever. However some
types are especially good at smuggling values across the panic boundary.

These types may choose to explicitly \emph{poison} themselves if they
witness a panic. Poisoning doesn't entail anything in particular.
Generally it just means preventing normal usage from proceeding. The
most notable example of this is the standard library's Mutex type. A
Mutex will poison itself if one of its MutexGuards (the thing it returns
when a lock is obtained) is dropped during a panic. Any future attempts
to lock the Mutex will return an \texttt{Err} or panic.

Mutex poisons not for true safety in the sense that Rust normally cares
about. It poisons as a safety-guard against blindly using the data that
comes out of a Mutex that has witnessed a panic while locked. The data
in such a Mutex was likely in the middle of being modified, and as such
may be in an inconsistent or incomplete state. It is important to note
that one cannot violate memory safety with such a type if it is
correctly written. After all, it must be minimally exception-safe!

However if the Mutex contained, say, a BinaryHeap that does not actually
have the heap property, it's unlikely that any code that uses it will do
what the author intended. As such, the program should not proceed
normally. Still, if you're double-plus-sure that you can do
\emph{something} with the value, the Mutex exposes a method to get the
lock anyway. It \emph{is} safe, after all. Just maybe nonsense.

\chapter{Concurrency}\label{sec--concurrency}

Rust as a language doesn't \emph{really} have an opinion on how to do
concurrency or parallelism. The standard library exposes OS threads and
blocking sys-calls because everyone has those, and they're uniform
enough that you can provide an abstraction over them in a relatively
uncontroversial way. Message passing, green threads, and async APIs are
all diverse enough that any abstraction over them tends to involve
trade-offs that we weren't willing to commit to for 1.0.

However the way Rust models concurrency makes it relatively easy to
design your own concurrency paradigm as a library and have everyone
else's code Just Work with yours. Just require the right lifetimes and
Send and Sync where appropriate and you're off to the races. Or rather,
off to the\ldots{} not\ldots{} having\ldots{} races.

\hypertarget{sec--races}{\section{Races}\label{sec--races}}

Safe Rust guarantees an absence of data races, which are defined as:

\begin{itemize}
\tightlist
\item
  two or more threads concurrently accessing a location of memory
\item
  one of them is a write
\item
  one of them is unsynchronized
\end{itemize}

A data race has Undefined Behavior, and is therefore impossible to
perform in Safe Rust. Data races are \emph{mostly} prevented through
rust's ownership system: it's impossible to alias a mutable reference,
so it's impossible to perform a data race. Interior mutability makes
this more complicated, which is largely why we have the Send and Sync
traits (see below).

\textbf{However Rust does not prevent general race conditions.}

This is pretty fundamentally impossible, and probably honestly
undesirable. Your hardware is racy, your OS is racy, the other programs
on your computer are racy, and the world this all runs in is racy. Any
system that could genuinely claim to prevent \emph{all} race conditions
would be pretty awful to use, if not just incorrect.

So it's perfectly ``fine'' for a Safe Rust program to get deadlocked or
do something incredibly stupid with incorrect synchronization. Obviously
such a program isn't very good, but Rust can only hold your hand so far.
Still, a race condition can't violate memory safety in a Rust program on
its own. Only in conjunction with some other unsafe code can a race
condition actually violate memory safety. For instance:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{use} \NormalTok{std::thread;}
\KeywordTok{use} \NormalTok{std::sync::atomic::\{AtomicUsize, Ordering\};}
\KeywordTok{use} \NormalTok{std::sync::Arc;}

\KeywordTok{let} \NormalTok{data = }\PreprocessorTok{vec!}\NormalTok{[}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{4}\NormalTok{];}
\CommentTok{// Arc so that the memory the AtomicUsize is stored in still exists for}
\CommentTok{// the other thread to increment, even if we completely finish executing}
\CommentTok{// before it. Rust won't compile the program without it, because of the}
\CommentTok{// lifetime requirements of thread::spawn!}
\KeywordTok{let} \NormalTok{idx = Arc::new(AtomicUsize::new(}\DecValTok{0}\NormalTok{));}
\KeywordTok{let} \NormalTok{other_idx = idx.clone();}

\CommentTok{// `move` captures other_idx by-value, moving it into this thread}
\NormalTok{thread::spawn(}\KeywordTok{move} \NormalTok{|| \{}
    \CommentTok{// It's ok to mutate idx because this value}
    \CommentTok{// is an atomic, so it can't cause a Data Race.}
    \NormalTok{other_idx.fetch_add(}\DecValTok{10}\NormalTok{, Ordering::SeqCst);}
\NormalTok{\});}

\CommentTok{// Index with the value loaded from the atomic. This is safe because we}
\CommentTok{// read the atomic memory only once, and then pass a copy of that value}
\CommentTok{// to the Vec's indexing implementation. This indexing will be correctly}
\CommentTok{// bounds checked, and there's no chance of the value getting changed}
\CommentTok{// in the middle. However our program may panic if the thread we spawned}
\CommentTok{// managed to increment before this ran. A race condition because correct}
\CommentTok{// program execution (panicking is rarely correct) depends on order of}
\CommentTok{// thread execution.}
\PreprocessorTok{println!}\NormalTok{(}\StringTok{"\{\}"}\NormalTok{, data[idx.load(Ordering::SeqCst)]);}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{use} \NormalTok{std::thread;}
\KeywordTok{use} \NormalTok{std::sync::atomic::\{AtomicUsize, Ordering\};}
\KeywordTok{use} \NormalTok{std::sync::Arc;}

\KeywordTok{let} \NormalTok{data = }\PreprocessorTok{vec!}\NormalTok{[}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{4}\NormalTok{];}

\KeywordTok{let} \NormalTok{idx = Arc::new(AtomicUsize::new(}\DecValTok{0}\NormalTok{));}
\KeywordTok{let} \NormalTok{other_idx = idx.clone();}

\CommentTok{// `move` captures other_idx by-value, moving it into this thread}
\NormalTok{thread::spawn(}\KeywordTok{move} \NormalTok{|| \{}
    \CommentTok{// It's ok to mutate idx because this value}
    \CommentTok{// is an atomic, so it can't cause a Data Race.}
    \NormalTok{other_idx.fetch_add(}\DecValTok{10}\NormalTok{, Ordering::SeqCst);}
\NormalTok{\});}

\KeywordTok{if} \NormalTok{idx.load(Ordering::SeqCst) < data.len() \{}
    \KeywordTok{unsafe} \NormalTok{\{}
        \CommentTok{// Incorrectly loading the idx after we did the bounds check.}
        \CommentTok{// It could have changed. This is a race condition, *and dangerous*}
        \CommentTok{// because we decided to do `get_unchecked`, which is `unsafe`.}
        \PreprocessorTok{println!}\NormalTok{(}\StringTok{"\{\}"}\NormalTok{, data.get_unchecked(idx.load(Ordering::SeqCst)));}
    \NormalTok{\}}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\section{Send and Sync}\label{sec--send-and-sync}

Not everything obeys inherited mutability, though. Some types allow you
to multiply alias a location in memory while mutating it. Unless these
types use synchronization to manage this access, they are absolutely not
thread safe. Rust captures this through the \texttt{Send} and
\texttt{Sync} traits.

\begin{itemize}
\tightlist
\item
  A type is Send if it is safe to send it to another thread.
\item
  A type is Sync if it is safe to share between threads (\texttt{\&T} is
  Send).
\end{itemize}

Send and Sync are fundamental to Rust's concurrency story. As such, a
substantial amount of special tooling exists to make them work right.
First and foremost, they're {[}unsafe traits{]}. This means that they
are unsafe to implement, and other unsafe code can assume that they are
correctly implemented. Since they're \emph{marker traits} (they have no
associated items like methods), correctly implemented simply means that
they have the intrinsic properties an implementor should have.
Incorrectly implementing Send or Sync can cause Undefined Behavior.

Send and Sync are also automatically derived traits. This means that,
unlike every other trait, if a type is composed entirely of Send or Sync
types, then it is Send or Sync. Almost all primitives are Send and Sync,
and as a consequence pretty much all types you'll ever interact with are
Send and Sync.

Major exceptions include:

\begin{itemize}
\tightlist
\item
  raw pointers are neither Send nor Sync (because they have no safety
  guards).
\item
  \texttt{UnsafeCell} isn't Sync (and therefore \texttt{Cell} and
  \texttt{RefCell} aren't).
\item
  \texttt{Rc} isn't Send or Sync (because the refcount is shared and
  unsynchronized).
\end{itemize}

\texttt{Rc} and \texttt{UnsafeCell} are very fundamentally not
thread-safe: they enable unsynchronized shared mutable state. However
raw pointers are, strictly speaking, marked as thread-unsafe as more of
a \emph{lint}. Doing anything useful with a raw pointer requires
dereferencing it, which is already unsafe. In that sense, one could
argue that it would be ``fine'' for them to be marked as thread safe.

However it's important that they aren't thread safe to prevent types
that contain them from being automatically marked as thread safe. These
types have non-trivial untracked ownership, and it's unlikely that their
author was necessarily thinking hard about thread safety. In the case of
Rc, we have a nice example of a type that contains a \texttt{*mut} that
is definitely not thread safe.

Types that aren't automatically derived can simply implement them if
desired:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{struct} \NormalTok{MyBox(*}\KeywordTok{mut} \DataTypeTok{u8}\NormalTok{);}

\KeywordTok{unsafe} \KeywordTok{impl} \BuiltInTok{Send} \KeywordTok{for} \NormalTok{MyBox \{\}}
\KeywordTok{unsafe} \KeywordTok{impl} \BuiltInTok{Sync} \KeywordTok{for} \NormalTok{MyBox \{\}}
\end{Highlighting}
\end{Shaded}

In the \emph{incredibly rare} case that a type is inappropriately
automatically derived to be Send or Sync, then one can also unimplement
Send and Sync:

\begin{Shaded}
\begin{Highlighting}[]
\AttributeTok{#![}\NormalTok{feature}\AttributeTok{(}\NormalTok{optin_builtin_traits}\AttributeTok{)]}

\CommentTok{// I have some magic semantics for some synchronization primitive!}
\KeywordTok{struct} \NormalTok{SpecialThreadToken(}\DataTypeTok{u8}\NormalTok{);}

\KeywordTok{impl} \NormalTok{!}\BuiltInTok{Send} \KeywordTok{for} \NormalTok{SpecialThreadToken \{\}}
\KeywordTok{impl} \NormalTok{!}\BuiltInTok{Sync} \KeywordTok{for} \NormalTok{SpecialThreadToken \{\}}
\end{Highlighting}
\end{Shaded}

Note that \emph{in and of itself} it is impossible to incorrectly derive
Send and Sync. Only types that are ascribed special meaning by other
unsafe code can possible cause trouble by being incorrectly Send or
Sync.

Most uses of raw pointers should be encapsulated behind a sufficient
abstraction that Send and Sync can be derived. For instance all of
Rust's standard collections are Send and Sync (when they contain Send
and Sync types) in spite of their pervasive use of raw pointers to
manage allocations and complex ownership. Similarly, most iterators into
these collections are Send and Sync because they largely behave like an
\texttt{\&} or \texttt{\&mut} into the collection.

TODO: better explain what can or can't be Send or Sync. Sufficient to
appeal only to data races?

\section{Atomics}\label{sec--atomics}

Rust pretty blatantly just inherits C11's memory model for atomics. This
is not due to this model being particularly excellent or easy to
understand. Indeed, this model is quite complex and known to have
\href{http://plv.mpi-sws.org/c11comp/popl15.pdf}{several flaws}. Rather,
it is a pragmatic concession to the fact that \emph{everyone} is pretty
bad at modeling atomics. At very least, we can benefit from existing
tooling and research around C.

Trying to fully explain the model in this book is fairly hopeless. It's
defined in terms of madness-inducing causality graphs that require a
full book to properly understand in a practical way. If you want all the
nitty-gritty details, you should check out
\href{http://www.open-std.org/jtc1/sc22/wg14/www/standards.html\#9899}{C's
specification (Section 7.17)}. Still, we'll try to cover the basics and
some of the problems Rust developers face.

The C11 memory model is fundamentally about trying to bridge the gap
between the semantics we want, the optimizations compilers want, and the
inconsistent chaos our hardware wants. \emph{We} would like to just
write programs and have them do exactly what we said but, you know,
fast. Wouldn't that be great?

\subsection{Compiler Reordering}\label{compiler-reordering}

Compilers fundamentally want to be able to do all sorts of crazy
transformations to reduce data dependencies and eliminate dead code. In
particular, they may radically change the actual order of events, or
make events never occur! If we write something like

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x = }\DecValTok{1}\NormalTok{;}
\NormalTok{y = }\DecValTok{3}\NormalTok{;}
\NormalTok{x = }\DecValTok{2}\NormalTok{;}
\end{Highlighting}
\end{Shaded}

The compiler may conclude that it would be best if your program did

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x = }\DecValTok{2}\NormalTok{;}
\NormalTok{y = }\DecValTok{3}\NormalTok{;}
\end{Highlighting}
\end{Shaded}

This has inverted the order of events and completely eliminated one
event. From a single-threaded perspective this is completely
unobservable: after all the statements have executed we are in exactly
the same state. But if our program is multi-threaded, we may have been
relying on \texttt{x} to actually be assigned to 1 before \texttt{y} was
assigned. We would like the compiler to be able to make these kinds of
optimizations, because they can seriously improve performance. On the
other hand, we'd also like to be able to depend on our program
\emph{doing the thing we said}.

\subsection{Hardware Reordering}\label{hardware-reordering}

On the other hand, even if the compiler totally understood what we
wanted and respected our wishes, our hardware might instead get us in
trouble. Trouble comes from CPUs in the form of memory hierarchies.
There is indeed a global shared memory space somewhere in your hardware,
but from the perspective of each CPU core it is \emph{so very far away}
and \emph{so very slow}. Each CPU would rather work with its local cache
of the data and only go through all the anguish of talking to shared
memory only when it doesn't actually have that memory in cache.

After all, that's the whole point of the cache, right? If every read
from the cache had to run back to shared memory to double check that it
hadn't changed, what would the point be? The end result is that the
hardware doesn't guarantee that events that occur in the same order on
\emph{one} thread, occur in the same order on \emph{another} thread. To
guarantee this, we must issue special instructions to the CPU telling it
to be a bit less smart.

For instance, say we convince the compiler to emit this logic:

\begin{verbatim}
initial state: x = 0, y = 1

THREAD 1        THREAD2
y = 3;          if x == 1 {
x = 1;              y *= 2;
                }
\end{verbatim}

Ideally this program has 2 possible final states:

\begin{itemize}
\tightlist
\item
  \texttt{y\ =\ 3}: (thread 2 did the check before thread 1 completed)
\item
  \texttt{y\ =\ 6}: (thread 2 did the check after thread 1 completed)
\end{itemize}

However there's a third potential state that the hardware enables:

\begin{itemize}
\tightlist
\item
  \texttt{y\ =\ 2}: (thread 2 saw \texttt{x\ =\ 1}, but not
  \texttt{y\ =\ 3}, and then overwrote \texttt{y\ =\ 3})
\end{itemize}

It's worth noting that different kinds of CPU provide different
guarantees. It is common to separate hardware into two categories:
strongly-ordered and weakly- ordered. Most notably x86/64 provides
strong ordering guarantees, while ARM provides weak ordering guarantees.
This has two consequences for concurrent programming:

\begin{itemize}
\item
  Asking for stronger guarantees on strongly-ordered hardware may be
  cheap or even free because they already provide strong guarantees
  unconditionally. Weaker guarantees may only yield performance wins on
  weakly-ordered hardware.
\item
  Asking for guarantees that are too weak on strongly-ordered hardware
  is more likely to \emph{happen} to work, even though your program is
  strictly incorrect. If possible, concurrent algorithms should be
  tested on weakly-ordered hardware.
\end{itemize}

\subsection{Data Accesses}\label{data-accesses}

The C11 memory model attempts to bridge the gap by allowing us to talk
about the \emph{causality} of our program. Generally, this is by
establishing a \emph{happens before} relationship between parts of the
program and the threads that are running them. This gives the hardware
and compiler room to optimize the program more aggressively where a
strict happens-before relationship isn't established, but forces them to
be more careful where one is established. The way we communicate these
relationships are through \emph{data accesses} and \emph{atomic
accesses}.

Data accesses are the bread-and-butter of the programming world. They
are fundamentally unsynchronized and compilers are free to aggressively
optimize them. In particular, data accesses are free to be reordered by
the compiler on the assumption that the program is single-threaded. The
hardware is also free to propagate the changes made in data accesses to
other threads as lazily and inconsistently as it wants. Most critically,
data accesses are how data races happen. Data accesses are very friendly
to the hardware and compiler, but as we've seen they offer \emph{awful}
semantics to try to write synchronized code with. Actually, that's too
weak.

\textbf{It is literally impossible to write correct synchronized code
using only data accesses.}

Atomic accesses are how we tell the hardware and compiler that our
program is multi-threaded. Each atomic access can be marked with an
\emph{ordering} that specifies what kind of relationship it establishes
with other accesses. In practice, this boils down to telling the
compiler and hardware certain things they \emph{can't} do. For the
compiler, this largely revolves around re-ordering of instructions. For
the hardware, this largely revolves around how writes are propagated to
other threads. The set of orderings Rust exposes are:

\begin{itemize}
\tightlist
\item
  Sequentially Consistent (SeqCst)
\item
  Release
\item
  Acquire
\item
  Relaxed
\end{itemize}

(Note: We explicitly do not expose the C11 \emph{consume} ordering)

TODO: negative reasoning vs positive reasoning? TODO: ``can't forget to
synchronize''

\subsection{Sequentially Consistent}\label{sequentially-consistent}

Sequentially Consistent is the most powerful of all, implying the
restrictions of all other orderings. Intuitively, a sequentially
consistent operation cannot be reordered: all accesses on one thread
that happen before and after a SeqCst access stay before and after it. A
data-race-free program that uses only sequentially consistent atomics
and data accesses has the very nice property that there is a single
global execution of the program's instructions that all threads agree
on. This execution is also particularly nice to reason about: it's just
an interleaving of each thread's individual executions. This does not
hold if you start using the weaker atomic orderings.

The relative developer-friendliness of sequential consistency doesn't
come for free. Even on strongly-ordered platforms sequential consistency
involves emitting memory fences.

In practice, sequential consistency is rarely necessary for program
correctness. However sequential consistency is definitely the right
choice if you're not confident about the other memory orders. Having
your program run a bit slower than it needs to is certainly better than
it running incorrectly! It's also mechanically trivial to downgrade
atomic operations to have a weaker consistency later on. Just change
\texttt{SeqCst} to \texttt{Relaxed} and you're done! Of course, proving
that this transformation is \emph{correct} is a whole other matter.

\subsection{Acquire-Release}\label{acquire-release}

Acquire and Release are largely intended to be paired. Their names hint
at their use case: they're perfectly suited for acquiring and releasing
locks, and ensuring that critical sections don't overlap.

Intuitively, an acquire access ensures that every access after it stays
after it. However operations that occur before an acquire are free to be
reordered to occur after it. Similarly, a release access ensures that
every access before it stays before it. However operations that occur
after a release are free to be reordered to occur before it.

When thread A releases a location in memory and then thread B
subsequently acquires \emph{the same} location in memory, causality is
established. Every write that happened before A's release will be
observed by B after its release. However no causality is established
with any other threads. Similarly, no causality is established if A and
B access \emph{different} locations in memory.

Basic use of release-acquire is therefore simple: you acquire a location
of memory to begin the critical section, and then release that location
to end it. For instance, a simple spinlock might look like:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{use} \NormalTok{std::sync::Arc;}
\KeywordTok{use} \NormalTok{std::sync::atomic::\{AtomicBool, Ordering\};}
\KeywordTok{use} \NormalTok{std::thread;}

\KeywordTok{fn} \NormalTok{main() \{}
    \KeywordTok{let} \NormalTok{lock = Arc::new(AtomicBool::new(}\ConstantTok{false}\NormalTok{)); }\CommentTok{// value answers "am I locked?"}

    \CommentTok{// ... distribute lock to threads somehow ...}

    \CommentTok{// Try to acquire the lock by setting it to true}
    \KeywordTok{while} \NormalTok{lock.compare_and_swap(}\ConstantTok{false}\NormalTok{, }\ConstantTok{true}\NormalTok{, Ordering::Acquire) \{ \}}
    \CommentTok{// broke out of the loop, so we successfully acquired the lock!}

    \CommentTok{// ... scary data accesses ...}

    \CommentTok{// ok we're done, release the lock}
    \NormalTok{lock.store(}\ConstantTok{false}\NormalTok{, Ordering::Release);}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

On strongly-ordered platforms most accesses have release or acquire
semantics, making release and acquire often totally free. This is not
the case on weakly-ordered platforms.

\subsection{Relaxed}\label{relaxed}

Relaxed accesses are the absolute weakest. They can be freely re-ordered
and provide no happens-before relationship. Still, relaxed operations
are still atomic. That is, they don't count as data accesses and any
read-modify-write operations done to them occur atomically. Relaxed
operations are appropriate for things that you definitely want to
happen, but don't particularly otherwise care about. For instance,
incrementing a counter can be safely done by multiple threads using a
relaxed \texttt{fetch\_add} if you're not using the counter to
synchronize any other accesses.

There's rarely a benefit in making an operation relaxed on
strongly-ordered platforms, since they usually provide release-acquire
semantics anyway. However relaxed operations can be cheaper on
weakly-ordered platforms.

\chapter{Implementing Vec}\label{sec--vec}

To bring everything together, we're going to write \texttt{std::Vec}
from scratch. Because all the best tools for writing unsafe code are
unstable, this project will only work on nightly (as of Rust 1.9.0).
With the exception of the allocator API, much of the unstable code we'll
use is expected to be stabilized in a similar form as it is today.

However we will generally try to avoid unstable code where possible. In
particular we won't use any intrinsics that could make a code a little
bit nicer or efficient because intrinsics are permanently unstable.
Although many intrinsics \emph{do} become stabilized elsewhere
(\texttt{std::ptr} and \texttt{str::mem} consist of many intrinsics).

Ultimately this means our implementation may not take advantage of all
possible optimizations, though it will be by no means \emph{naive}. We
will definitely get into the weeds over nitty-gritty details, even when
the problem doesn't \emph{really} merit it.

You wanted advanced. We're gonna go advanced.

\section{Layout}\label{sec--vec-layout}

First off, we need to come up with the struct layout. A Vec has three
parts: a pointer to the allocation, the size of the allocation, and the
number of elements that have been initialized.

Naively, this means we just want this design:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{pub} \KeywordTok{struct} \DataTypeTok{Vec}\NormalTok{<T> \{}
    \NormalTok{ptr: *}\KeywordTok{mut} \NormalTok{T,}
    \NormalTok{cap: }\DataTypeTok{usize}\NormalTok{,}
    \NormalTok{len: }\DataTypeTok{usize}\NormalTok{,}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

And indeed this would compile. Unfortunately, it would be incorrect.
First, the compiler will give us too strict variance. So a
\texttt{\&Vec\textless{}\&\textquotesingle{}static\ str\textgreater{}}
couldn't be used where an
\texttt{\&Vec\textless{}\&\textquotesingle{}a\ str\textgreater{}} was
expected. More importantly, it will give incorrect ownership information
to the drop checker, as it will conservatively assume we don't own any
values of type \texttt{T}. See \protect\hyperlink{sec--ownership}{the
chapter on ownership and lifetimes} for all the details on variance and
drop check.

As we saw in the ownership chapter, we should use
\texttt{Unique\textless{}T\textgreater{}} in place of \texttt{*mut\ T}
when we have a raw pointer to an allocation we own. Unique is unstable,
so we'd like to not use it if possible, though.

As a recap, Unique is a wrapper around a raw pointer that declares that:

\begin{itemize}
\tightlist
\item
  We are variant over \texttt{T}
\item
  We may own a value of type \texttt{T} (for drop check)
\item
  We are Send/Sync if \texttt{T} is Send/Sync
\item
  We deref to \texttt{*mut\ T} (so it largely acts like a \texttt{*mut}
  in our code)
\item
  Our pointer is never null (so
  \texttt{Option\textless{}Vec\textless{}T\textgreater{}\textgreater{}}
  is null-pointer-optimized)
\end{itemize}

We can implement all of the above requirements except for the last one
in stable Rust:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{use} \NormalTok{std::marker::PhantomData;}
\KeywordTok{use} \NormalTok{std::ops::Deref;}
\KeywordTok{use} \NormalTok{std::mem;}

\KeywordTok{struct} \NormalTok{Unique<T> \{}
    \NormalTok{ptr: *}\KeywordTok{const} \NormalTok{T,              }\CommentTok{// *const for variance}
    \NormalTok{_marker: PhantomData<T>,    }\CommentTok{// For the drop checker}
\NormalTok{\}}

\CommentTok{// Deriving Send and Sync is safe because we are the Unique owners}
\CommentTok{// of this data. It's like Unique<T> is "just" T.}
\KeywordTok{unsafe} \KeywordTok{impl}\NormalTok{<T: }\BuiltInTok{Send}\NormalTok{> }\BuiltInTok{Send} \KeywordTok{for} \NormalTok{Unique<T> \{\}}
\KeywordTok{unsafe} \KeywordTok{impl}\NormalTok{<T: }\BuiltInTok{Sync}\NormalTok{> }\BuiltInTok{Sync} \KeywordTok{for} \NormalTok{Unique<T> \{\}}

\KeywordTok{impl}\NormalTok{<T> Unique<T> \{}
    \KeywordTok{pub} \KeywordTok{fn} \NormalTok{new(ptr: *}\KeywordTok{mut} \NormalTok{T) -> }\KeywordTok{Self} \NormalTok{\{}
        \NormalTok{Unique \{ ptr: ptr, _marker: PhantomData \}}
    \NormalTok{\}}
\NormalTok{\}}

\KeywordTok{impl}\NormalTok{<T> Deref }\KeywordTok{for} \NormalTok{Unique<T> \{}
    \KeywordTok{type} \NormalTok{Target = *}\KeywordTok{mut} \NormalTok{T;}
    \KeywordTok{fn} \NormalTok{deref(&}\KeywordTok{self}\NormalTok{) -> &*}\KeywordTok{mut} \NormalTok{T \{}
        \CommentTok{// There's no way to cast the *const to a *mut}
        \CommentTok{// while also taking a reference. So we just}
        \CommentTok{// transmute it since it's all "just pointers".}
        \KeywordTok{unsafe} \NormalTok{\{ mem::transmute(&}\KeywordTok{self}\NormalTok{.ptr) \}}
    \NormalTok{\}}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

Unfortunately the mechanism for stating that your value is non-zero is
unstable and unlikely to be stabilized soon. As such we're just going to
take the hit and use std's Unique:

\begin{Shaded}
\begin{Highlighting}[]
\AttributeTok{#![}\NormalTok{feature}\AttributeTok{(}\NormalTok{unique}\AttributeTok{)]}

\KeywordTok{use} \NormalTok{std::ptr::\{Unique, }\KeywordTok{self}\NormalTok{\};}

\KeywordTok{pub} \KeywordTok{struct} \DataTypeTok{Vec}\NormalTok{<T> \{}
    \NormalTok{ptr: Unique<T>,}
    \NormalTok{cap: }\DataTypeTok{usize}\NormalTok{,}
    \NormalTok{len: }\DataTypeTok{usize}\NormalTok{,}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

If you don't care about the null-pointer optimization, then you can use
the stable code. However we will be designing the rest of the code
around enabling the optimization. In particular, \texttt{Unique::new} is
unsafe to call, because putting \texttt{null} inside of it is Undefined
Behavior. Our stable Unique doesn't need \texttt{new} to be unsafe
because it doesn't make any interesting guarantees about its contents.

\section{Allocating}\label{sec--vec-alloc}

Using Unique throws a wrench in an important feature of Vec (and indeed
all of the std collections): an empty Vec doesn't actually allocate at
all. So if we can't allocate, but also can't put a null pointer in
\texttt{ptr}, what do we do in \texttt{Vec::new}? Well, we just put some
other garbage in there!

This is perfectly fine because we already have \texttt{cap\ ==\ 0} as
our sentinel for no allocation. We don't even need to handle it
specially in almost any code because we usually need to check if
\texttt{cap\ \textgreater{}\ len} or \texttt{len\ \textgreater{}\ 0}
anyway. The traditional Rust value to put here is \texttt{0x01}. The
standard library actually exposes this as \texttt{alloc::heap::EMPTY}.
There are quite a few places where we'll want to use
\texttt{heap::EMPTY} because there's no real allocation to talk about
but \texttt{null} would make the compiler do bad things.

All of the \texttt{heap} API is totally unstable under the
\texttt{heap\_api} feature, though. We could trivially define
\texttt{heap::EMPTY} ourselves, but we'll want the rest of the
\texttt{heap} API anyway, so let's just get that dependency over with.

So:

\begin{Shaded}
\begin{Highlighting}[]
\AttributeTok{#![}\NormalTok{feature}\AttributeTok{(}\NormalTok{alloc}\AttributeTok{,} \NormalTok{heap_api}\AttributeTok{)]}

\KeywordTok{use} \NormalTok{std::mem;}

\KeywordTok{use} \NormalTok{alloc::heap::EMPTY;}

\KeywordTok{impl}\NormalTok{<T> }\DataTypeTok{Vec}\NormalTok{<T> \{}
    \KeywordTok{fn} \NormalTok{new() -> }\KeywordTok{Self} \NormalTok{\{}
        \PreprocessorTok{assert!}\NormalTok{(mem::size_of::<T>() != }\DecValTok{0}\NormalTok{, }\StringTok{"We're not ready to handle ZSTs"}\NormalTok{);}
        \KeywordTok{unsafe} \NormalTok{\{}
            \CommentTok{// need to cast EMPTY to the actual ptr type we want, let}
            \CommentTok{// inference handle it.}
            \DataTypeTok{Vec} \NormalTok{\{ ptr: Unique::new(heap::EMPTY }\KeywordTok{as} \NormalTok{*}\KeywordTok{mut} \NormalTok{_), len: }\DecValTok{0}\NormalTok{, cap: }\DecValTok{0} \NormalTok{\}}
        \NormalTok{\}}
    \NormalTok{\}}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

I slipped in that assert there because zero-sized types will require
some special handling throughout our code, and I want to defer the issue
for now. Without this assert, some of our early drafts will do some Very
Bad Things.

Next we need to figure out what to actually do when we \emph{do} want
space. For that, we'll need to use the rest of the heap APIs. These
basically allow us to talk directly to Rust's allocator (jemalloc by
default).

We'll also need a way to handle out-of-memory (OOM) conditions. The
standard library calls the \texttt{abort} intrinsic, which just calls an
illegal instruction to crash the whole program. The reason we abort and
don't panic is because unwinding can cause allocations to happen, and
that seems like a bad thing to do when your allocator just came back
with ``hey I don't have any more memory''.

Of course, this is a bit silly since most platforms don't actually run
out of memory in a conventional way. Your operating system will probably
kill the application by another means if you legitimately start using up
all the memory. The most likely way we'll trigger OOM is by just asking
for ludicrous quantities of memory at once (e.g.~half the theoretical
address space). As such it's \emph{probably} fine to panic and nothing
bad will happen. Still, we're trying to be like the standard library as
much as possible, so we'll just kill the whole program.

We said we don't want to use intrinsics, so doing exactly what
\texttt{std} does is out. Instead, we'll call
\texttt{std::process::exit} with some random number.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{fn} \NormalTok{oom() \{}
    \NormalTok{::std::process::exit(-}\DecValTok{9999}\NormalTok{);}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

Okay, now we can write growing. Roughly, we want to have this logic:

\begin{verbatim}
if cap == 0:
    allocate()
    cap = 1
else:
    reallocate()
    cap *= 2
\end{verbatim}

But Rust's only supported allocator API is so low level that we'll need
to do a fair bit of extra work. We also need to guard against some
special conditions that can occur with really large allocations or empty
allocations.

In particular, \texttt{ptr::offset} will cause us a lot of trouble,
because it has the semantics of LLVM's GEP inbounds instruction. If
you're fortunate enough to not have dealt with this instruction, here's
the basic story with GEP: alias analysis, alias analysis, alias
analysis. It's super important to an optimizing compiler to be able to
reason about data dependencies and aliasing.

As a simple example, consider the following fragment of code:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{*x *= }\DecValTok{7}\NormalTok{;}
\NormalTok{*y *= }\DecValTok{3}\NormalTok{;}
\end{Highlighting}
\end{Shaded}

If the compiler can prove that \texttt{x} and \texttt{y} point to
different locations in memory, the two operations can in theory be
executed in parallel (by e.g.~loading them into different registers and
working on them independently). However the compiler can't do this in
general because if x and y point to the same location in memory, the
operations need to be done to the same value, and they can't just be
merged afterwards.

When you use GEP inbounds, you are specifically telling LLVM that the
offsets you're about to do are within the bounds of a single
``allocated'' entity. The ultimate payoff being that LLVM can assume
that if two pointers are known to point to two disjoint objects, all the
offsets of those pointers are \emph{also} known to not alias (because
you won't just end up in some random place in memory). LLVM is heavily
optimized to work with GEP offsets, and inbounds offsets are the best of
all, so it's important that we use them as much as possible.

So that's what GEP's about, how can it cause us trouble?

The first problem is that we index into arrays with unsigned integers,
but GEP (and as a consequence \texttt{ptr::offset}) takes a signed
integer. This means that half of the seemingly valid indices into an
array will overflow GEP and actually go in the wrong direction! As such
we must limit all allocations to \texttt{isize::MAX} elements. This
actually means we only need to worry about byte-sized objects, because
e.g. \texttt{\textgreater{}\ isize::MAX} \texttt{u16}s will truly
exhaust all of the system's memory. However in order to avoid subtle
corner cases where someone reinterprets some array of
\texttt{\textless{}\ isize::MAX} objects as bytes, std limits all
allocations to \texttt{isize::MAX} bytes.

On all 64-bit targets that Rust currently supports we're artificially
limited to significantly less than all 64 bits of the address space
(modern x64 platforms only expose 48-bit addressing), so we can rely on
just running out of memory first. However on 32-bit targets,
particularly those with extensions to use more of the address space (PAE
x86 or x32), it's theoretically possible to successfully allocate more
than \texttt{isize::MAX} bytes of memory.

However since this is a tutorial, we're not going to be particularly
optimal here, and just unconditionally check, rather than use clever
platform-specific \texttt{cfg}s.

The other corner-case we need to worry about is empty allocations. There
will be two kinds of empty allocations we need to worry about:
\texttt{cap\ =\ 0} for all T, and \texttt{cap\ \textgreater{}\ 0} for
zero-sized types.

These cases are tricky because they come down to what LLVM means by
``allocated''. LLVM's notion of an allocation is significantly more
abstract than how we usually use it. Because LLVM needs to work with
different languages' semantics and custom allocators, it can't really
intimately understand allocation. Instead, the main idea behind
allocation is ``doesn't overlap with other stuff''. That is, heap
allocations, stack allocations, and globals don't randomly overlap. Yep,
it's about alias analysis. As such, Rust can technically play a bit fast
and loose with the notion of an allocation as long as it's
\emph{consistent}.

Getting back to the empty allocation case, there are a couple of places
where we want to offset by 0 as a consequence of generic code. The
question is then: is it consistent to do so? For zero-sized types, we
have concluded that it is indeed consistent to do a GEP inbounds offset
by an arbitrary number of elements. This is a runtime no-op because
every element takes up no space, and it's fine to pretend that there's
infinite zero-sized types allocated at \texttt{0x01}. No allocator will
ever allocate that address, because they won't allocate \texttt{0x00}
and they generally allocate to some minimal alignment higher than a
byte. Also generally the whole first page of memory is protected from
being allocated anyway (a whole 4k, on many platforms).

However what about for positive-sized types? That one's a bit trickier.
In principle, you can argue that offsetting by 0 gives LLVM no
information: either there's an element before the address or after it,
but it can't know which. However we've chosen to conservatively assume
that it may do bad things. As such we will guard against this case
explicitly.

\emph{Phew}

Ok with all the nonsense out of the way, let's actually allocate some
memory:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{fn} \NormalTok{grow(&}\KeywordTok{mut} \KeywordTok{self}\NormalTok{) \{}
    \CommentTok{// this is all pretty delicate, so let's say it's all unsafe}
    \KeywordTok{unsafe} \NormalTok{\{}
        \CommentTok{// current API requires us to specify size and alignment manually.}
        \KeywordTok{let} \NormalTok{align = mem::align_of::<T>();}
        \KeywordTok{let} \NormalTok{elem_size = mem::size_of::<T>();}

        \KeywordTok{let} \NormalTok{(new_cap, ptr) = }\KeywordTok{if} \KeywordTok{self}\NormalTok{.cap == }\DecValTok{0} \NormalTok{\{}
            \KeywordTok{let} \NormalTok{ptr = heap::allocate(elem_size, align);}
            \NormalTok{(}\DecValTok{1}\NormalTok{, ptr)}
        \NormalTok{\} }\KeywordTok{else} \NormalTok{\{}
            \CommentTok{// as an invariant, we can assume that `self.cap < isize::MAX`,}
            \CommentTok{// so this doesn't need to be checked.}
            \KeywordTok{let} \NormalTok{new_cap = }\KeywordTok{self}\NormalTok{.cap * }\DecValTok{2}\NormalTok{;}
            \CommentTok{// Similarly this can't overflow due to previously allocating this}
            \KeywordTok{let} \NormalTok{old_num_bytes = }\KeywordTok{self}\NormalTok{.cap * elem_size;}

            \CommentTok{// check that the new allocation doesn't exceed `isize::MAX` at all}
            \CommentTok{// regardless of the actual size of the capacity. This combines the}
            \CommentTok{// `new_cap <= isize::MAX` and `new_num_bytes <= usize::MAX` checks}
            \CommentTok{// we need to make. We lose the ability to allocate e.g. 2/3rds of}
            \CommentTok{// the address space with a single Vec of i16's on 32-bit though.}
            \CommentTok{// Alas, poor Yorick -- I knew him, Horatio.}
            \PreprocessorTok{assert!}\NormalTok{(old_num_bytes <= (::std::}\DataTypeTok{isize}\NormalTok{::MAX }\KeywordTok{as} \DataTypeTok{usize}\NormalTok{) / }\DecValTok{2}\NormalTok{,}
                    \StringTok{"capacity overflow"}\NormalTok{);}

            \KeywordTok{let} \NormalTok{new_num_bytes = old_num_bytes * }\DecValTok{2}\NormalTok{;}
            \KeywordTok{let} \NormalTok{ptr = heap::reallocate(*}\KeywordTok{self}\NormalTok{.ptr }\KeywordTok{as} \NormalTok{*}\KeywordTok{mut} \NormalTok{_,}
                                        \NormalTok{old_num_bytes,}
                                        \NormalTok{new_num_bytes,}
                                        \NormalTok{align);}
            \NormalTok{(new_cap, ptr)}
        \NormalTok{\};}

        \CommentTok{// If allocate or reallocate fail, we'll get `null` back}
        \KeywordTok{if} \NormalTok{ptr.is_null() \{ oom(); \}}

        \KeywordTok{self}\NormalTok{.ptr = Unique::new(ptr }\KeywordTok{as} \NormalTok{*}\KeywordTok{mut} \NormalTok{_);}
        \KeywordTok{self}\NormalTok{.cap = new_cap;}
    \NormalTok{\}}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

Nothing particularly tricky here. Just computing sizes and alignments
and doing some careful multiplication checks.

\section{Push and Pop}\label{sec--vec-push-pop}

Alright. We can initialize. We can allocate. Let's actually implement
some functionality! Let's start with \texttt{push}. All it needs to do
is check if we're full to grow, unconditionally write to the next index,
and then increment our length.

To do the write we have to be careful not to evaluate the memory we want
to write to. At worst, it's truly uninitialized memory from the
allocator. At best it's the bits of some old value we popped off. Either
way, we can't just index to the memory and dereference it, because that
will evaluate the memory as a valid instance of T. Worse,
\texttt{foo{[}idx{]}\ =\ x} will try to call \texttt{drop} on the old
value of \texttt{foo{[}idx{]}}!

The correct way to do this is with \texttt{ptr::write}, which just
blindly overwrites the target address with the bits of the value we
provide. No evaluation involved.

For \texttt{push}, if the old len (before push was called) is 0, then we
want to write to the 0th index. So we should offset by the old len.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{pub} \KeywordTok{fn} \NormalTok{push(&}\KeywordTok{mut} \KeywordTok{self}\NormalTok{, elem: T) \{}
    \KeywordTok{if} \KeywordTok{self}\NormalTok{.len == }\KeywordTok{self}\NormalTok{.cap \{ }\KeywordTok{self}\NormalTok{.grow(); \}}

    \KeywordTok{unsafe} \NormalTok{\{}
        \NormalTok{ptr::write(}\KeywordTok{self}\NormalTok{.ptr.offset(}\KeywordTok{self}\NormalTok{.len }\KeywordTok{as} \DataTypeTok{isize}\NormalTok{), elem);}
    \NormalTok{\}}

    \CommentTok{// Can't fail, we'll OOM first.}
    \KeywordTok{self}\NormalTok{.len += }\DecValTok{1}\NormalTok{;}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

Easy! How about \texttt{pop}? Although this time the index we want to
access is initialized, Rust won't just let us dereference the location
of memory to move the value out, because that would leave the memory
uninitialized! For this we need \texttt{ptr::read}, which just copies
out the bits from the target address and interprets it as a value of
type T. This will leave the memory at this address logically
uninitialized, even though there is in fact a perfectly good instance of
T there.

For \texttt{pop}, if the old len is 1, we want to read out of the 0th
index. So we should offset by the new len.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{pub} \KeywordTok{fn} \NormalTok{pop(&}\KeywordTok{mut} \KeywordTok{self}\NormalTok{) -> }\DataTypeTok{Option}\NormalTok{<T> \{}
    \KeywordTok{if} \KeywordTok{self}\NormalTok{.len == }\DecValTok{0} \NormalTok{\{}
        \ConstantTok{None}
    \NormalTok{\} }\KeywordTok{else} \NormalTok{\{}
        \KeywordTok{self}\NormalTok{.len -= }\DecValTok{1}\NormalTok{;}
        \KeywordTok{unsafe} \NormalTok{\{}
            \ConstantTok{Some}\NormalTok{(ptr::read(}\KeywordTok{self}\NormalTok{.ptr.offset(}\KeywordTok{self}\NormalTok{.len }\KeywordTok{as} \DataTypeTok{isize}\NormalTok{)))}
        \NormalTok{\}}
    \NormalTok{\}}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\section{Deallocating}\label{sec--vec-dealloc}

Next we should implement Drop so that we don't massively leak tons of
resources. The easiest way is to just call \texttt{pop} until it yields
None, and then deallocate our buffer. Note that calling \texttt{pop} is
unneeded if \texttt{T:\ !Drop}. In theory we can ask Rust if \texttt{T}
\texttt{needs\_drop} and omit the calls to \texttt{pop}. However in
practice LLVM is \emph{really} good at removing simple side-effect free
code like this, so I wouldn't bother unless you notice it's not being
stripped (in this case it is).

We must not call \texttt{heap::deallocate} when
\texttt{self.cap\ ==\ 0}, as in this case we haven't actually allocated
any memory.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{impl}\NormalTok{<T> }\BuiltInTok{Drop} \KeywordTok{for} \DataTypeTok{Vec}\NormalTok{<T> \{}
    \KeywordTok{fn} \NormalTok{drop(&}\KeywordTok{mut} \KeywordTok{self}\NormalTok{) \{}
        \KeywordTok{if} \KeywordTok{self}\NormalTok{.cap != }\DecValTok{0} \NormalTok{\{}
            \KeywordTok{while} \KeywordTok{let} \ConstantTok{Some}\NormalTok{(_) = }\KeywordTok{self}\NormalTok{.pop() \{ \}}

            \KeywordTok{let} \NormalTok{align = mem::align_of::<T>();}
            \KeywordTok{let} \NormalTok{elem_size = mem::size_of::<T>();}
            \KeywordTok{let} \NormalTok{num_bytes = elem_size * }\KeywordTok{self}\NormalTok{.cap;}
            \KeywordTok{unsafe} \NormalTok{\{}
                \NormalTok{heap::deallocate(*}\KeywordTok{self}\NormalTok{.ptr }\KeywordTok{as} \NormalTok{*}\KeywordTok{mut} \NormalTok{_, num_bytes, align);}
            \NormalTok{\}}
        \NormalTok{\}}
    \NormalTok{\}}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\section{Deref}\label{sec--vec-deref}

Alright! We've got a decent minimal stack implemented. We can push, we
can pop, and we can clean up after ourselves. However there's a whole
mess of functionality we'd reasonably want. In particular, we have a
proper array, but none of the slice functionality. That's actually
pretty easy to solve: we can implement
\texttt{Deref\textless{}Target={[}T{]}\textgreater{}}. This will
magically make our Vec coerce to, and behave like, a slice in all sorts
of conditions.

All we need is \texttt{slice::from\_raw\_parts}. It will correctly
handle empty slices for us. Later once we set up zero-sized type support
it will also Just Work for those too.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{use} \NormalTok{std::ops::Deref;}

\KeywordTok{impl}\NormalTok{<T> Deref }\KeywordTok{for} \DataTypeTok{Vec}\NormalTok{<T> \{}
    \KeywordTok{type} \NormalTok{Target = [T];}
    \KeywordTok{fn} \NormalTok{deref(&}\KeywordTok{self}\NormalTok{) -> &[T] \{}
        \KeywordTok{unsafe} \NormalTok{\{}
            \NormalTok{::std::slice::from_raw_parts(*}\KeywordTok{self}\NormalTok{.ptr, }\KeywordTok{self}\NormalTok{.len)}
        \NormalTok{\}}
    \NormalTok{\}}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

And let's do DerefMut too:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{use} \NormalTok{std::ops::DerefMut;}

\KeywordTok{impl}\NormalTok{<T> DerefMut }\KeywordTok{for} \DataTypeTok{Vec}\NormalTok{<T> \{}
    \KeywordTok{fn} \NormalTok{deref_mut(&}\KeywordTok{mut} \KeywordTok{self}\NormalTok{) -> &}\KeywordTok{mut} \NormalTok{[T] \{}
        \KeywordTok{unsafe} \NormalTok{\{}
            \NormalTok{::std::slice::from_raw_parts_mut(*}\KeywordTok{self}\NormalTok{.ptr, }\KeywordTok{self}\NormalTok{.len)}
        \NormalTok{\}}
    \NormalTok{\}}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

Now we have \texttt{len}, \texttt{first}, \texttt{last}, indexing,
slicing, sorting, \texttt{iter}, \texttt{iter\_mut}, and all other sorts
of bells and whistles provided by slice. Sweet!

\section{Insert and Remove}\label{sec--vec-insert-remove}

Something \emph{not} provided by slice is \texttt{insert} and
\texttt{remove}, so let's do those next.

Insert needs to shift all the elements at the target index to the right
by one. To do this we need to use \texttt{ptr::copy}, which is our
version of C's \texttt{memmove}. This copies some chunk of memory from
one location to another, correctly handling the case where the source
and destination overlap (which will definitely happen here).

If we insert at index \texttt{i}, we want to shift the
\texttt{{[}i\ ..\ len{]}} to \texttt{{[}i+1\ ..\ len+1{]}} using the old
len.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{pub} \KeywordTok{fn} \NormalTok{insert(&}\KeywordTok{mut} \KeywordTok{self}\NormalTok{, index: }\DataTypeTok{usize}\NormalTok{, elem: T) \{}
    \CommentTok{// Note: `<=` because it's valid to insert after everything}
    \CommentTok{// which would be equivalent to push.}
    \PreprocessorTok{assert!}\NormalTok{(index <= }\KeywordTok{self}\NormalTok{.len, }\StringTok{"index out of bounds"}\NormalTok{);}
    \KeywordTok{if} \KeywordTok{self}\NormalTok{.cap == }\KeywordTok{self}\NormalTok{.len \{ }\KeywordTok{self}\NormalTok{.grow(); \}}

    \KeywordTok{unsafe} \NormalTok{\{}
        \KeywordTok{if} \NormalTok{index < }\KeywordTok{self}\NormalTok{.len \{}
            \CommentTok{// ptr::copy(src, dest, len): "copy from source to dest len elems"}
            \NormalTok{ptr::copy(}\KeywordTok{self}\NormalTok{.ptr.offset(index }\KeywordTok{as} \DataTypeTok{isize}\NormalTok{),}
                      \KeywordTok{self}\NormalTok{.ptr.offset(index }\KeywordTok{as} \DataTypeTok{isize} \NormalTok{+ }\DecValTok{1}\NormalTok{),}
                      \KeywordTok{self}\NormalTok{.len - index);}
        \NormalTok{\}}
        \NormalTok{ptr::write(}\KeywordTok{self}\NormalTok{.ptr.offset(index }\KeywordTok{as} \DataTypeTok{isize}\NormalTok{), elem);}
        \KeywordTok{self}\NormalTok{.len += }\DecValTok{1}\NormalTok{;}
    \NormalTok{\}}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

Remove behaves in the opposite manner. We need to shift all the elements
from \texttt{{[}i+1\ ..\ len\ +\ 1{]}} to \texttt{{[}i\ ..\ len{]}}
using the \emph{new} len.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{pub} \KeywordTok{fn} \NormalTok{remove(&}\KeywordTok{mut} \KeywordTok{self}\NormalTok{, index: }\DataTypeTok{usize}\NormalTok{) -> T \{}
    \CommentTok{// Note: `<` because it's *not* valid to remove after everything}
    \PreprocessorTok{assert!}\NormalTok{(index < }\KeywordTok{self}\NormalTok{.len, }\StringTok{"index out of bounds"}\NormalTok{);}
    \KeywordTok{unsafe} \NormalTok{\{}
        \KeywordTok{self}\NormalTok{.len -= }\DecValTok{1}\NormalTok{;}
        \KeywordTok{let} \NormalTok{result = ptr::read(}\KeywordTok{self}\NormalTok{.ptr.offset(index }\KeywordTok{as} \DataTypeTok{isize}\NormalTok{));}
        \NormalTok{ptr::copy(}\KeywordTok{self}\NormalTok{.ptr.offset(index }\KeywordTok{as} \DataTypeTok{isize} \NormalTok{+ }\DecValTok{1}\NormalTok{),}
                  \KeywordTok{self}\NormalTok{.ptr.offset(index }\KeywordTok{as} \DataTypeTok{isize}\NormalTok{),}
                  \KeywordTok{self}\NormalTok{.len - index);}
        \NormalTok{result}
    \NormalTok{\}}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\section{IntoIter}\label{sec--vec-into-iter}

Let's move on to writing iterators. \texttt{iter} and \texttt{iter\_mut}
have already been written for us thanks to The Magic of Deref. However
there's two interesting iterators that Vec provides that slices can't:
\texttt{into\_iter} and \texttt{drain}.

IntoIter consumes the Vec by-value, and can consequently yield its
elements by-value. In order to enable this, IntoIter needs to take
control of Vec's allocation.

IntoIter needs to be DoubleEnded as well, to enable reading from both
ends. Reading from the back could just be implemented as calling
\texttt{pop}, but reading from the front is harder. We could call
\texttt{remove(0)} but that would be insanely expensive. Instead we're
going to just use ptr::read to copy values out of either end of the Vec
without mutating the buffer at all.

To do this we're going to use a very common C idiom for array iteration.
We'll make two pointers; one that points to the start of the array, and
one that points to one-element past the end. When we want an element
from one end, we'll read out the value pointed to at that end and move
the pointer over by one. When the two pointers are equal, we know we're
done.

Note that the order of read and offset are reversed for \texttt{next}
and \texttt{next\_back} For \texttt{next\_back} the pointer is always
after the element it wants to read next, while for \texttt{next} the
pointer is always at the element it wants to read next. To see why this
is, consider the case where every element but one has been yielded.

The array looks like this:

\begin{verbatim}
          S  E
[X, X, X, O, X, X, X]
\end{verbatim}

If E pointed directly at the element it wanted to yield next, it would
be indistinguishable from the case where there are no more elements to
yield.

Although we don't actually care about it during iteration, we also need
to hold onto the Vec's allocation information in order to free it once
IntoIter is dropped.

So we're going to use the following struct:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{struct} \NormalTok{IntoIter<T> \{}
    \NormalTok{buf: Unique<T>,}
    \NormalTok{cap: }\DataTypeTok{usize}\NormalTok{,}
    \NormalTok{start: *}\KeywordTok{const} \NormalTok{T,}
    \NormalTok{end: *}\KeywordTok{const} \NormalTok{T,}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

And this is what we end up with for initialization:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{impl}\NormalTok{<T> }\DataTypeTok{Vec}\NormalTok{<T> \{}
    \KeywordTok{fn} \NormalTok{into_iter(}\KeywordTok{self}\NormalTok{) -> IntoIter<T> \{}
        \CommentTok{// Can't destructure Vec since it's Drop}
        \KeywordTok{let} \NormalTok{ptr = }\KeywordTok{self}\NormalTok{.ptr;}
        \KeywordTok{let} \NormalTok{cap = }\KeywordTok{self}\NormalTok{.cap;}
        \KeywordTok{let} \NormalTok{len = }\KeywordTok{self}\NormalTok{.len;}

        \CommentTok{// Make sure not to drop Vec since that will free the buffer}
        \NormalTok{mem::forget(}\KeywordTok{self}\NormalTok{);}

        \KeywordTok{unsafe} \NormalTok{\{}
            \NormalTok{IntoIter \{}
                \NormalTok{buf: ptr,}
                \NormalTok{cap: cap,}
                \NormalTok{start: *ptr,}
                \NormalTok{end: }\KeywordTok{if} \NormalTok{cap == }\DecValTok{0} \NormalTok{\{}
                    \CommentTok{// can't offset off this pointer, it's not allocated!}
                    \NormalTok{*ptr}
                \NormalTok{\} }\KeywordTok{else} \NormalTok{\{}
                    \NormalTok{ptr.offset(len }\KeywordTok{as} \DataTypeTok{isize}\NormalTok{)}
                \NormalTok{\}}
            \NormalTok{\}}
        \NormalTok{\}}
    \NormalTok{\}}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

Here's iterating forward:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{impl}\NormalTok{<T> }\BuiltInTok{Iterator} \KeywordTok{for} \NormalTok{IntoIter<T> \{}
    \KeywordTok{type} \NormalTok{Item = T;}
    \KeywordTok{fn} \NormalTok{next(&}\KeywordTok{mut} \KeywordTok{self}\NormalTok{) -> }\DataTypeTok{Option}\NormalTok{<T> \{}
        \KeywordTok{if} \KeywordTok{self}\NormalTok{.start == }\KeywordTok{self}\NormalTok{.end \{}
            \ConstantTok{None}
        \NormalTok{\} }\KeywordTok{else} \NormalTok{\{}
            \KeywordTok{unsafe} \NormalTok{\{}
                \KeywordTok{let} \NormalTok{result = ptr::read(}\KeywordTok{self}\NormalTok{.start);}
                \KeywordTok{self}\NormalTok{.start = }\KeywordTok{self}\NormalTok{.start.offset(}\DecValTok{1}\NormalTok{);}
                \ConstantTok{Some}\NormalTok{(result)}
            \NormalTok{\}}
        \NormalTok{\}}
    \NormalTok{\}}

    \KeywordTok{fn} \NormalTok{size_hint(&}\KeywordTok{self}\NormalTok{) -> (}\DataTypeTok{usize}\NormalTok{, }\DataTypeTok{Option}\NormalTok{<}\DataTypeTok{usize}\NormalTok{>) \{}
        \KeywordTok{let} \NormalTok{len = (}\KeywordTok{self}\NormalTok{.end }\KeywordTok{as} \DataTypeTok{usize} \NormalTok{- }\KeywordTok{self}\NormalTok{.start }\KeywordTok{as} \DataTypeTok{usize}\NormalTok{)}
                  \NormalTok{/ mem::size_of::<T>();}
        \NormalTok{(len, }\ConstantTok{Some}\NormalTok{(len))}
    \NormalTok{\}}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

And here's iterating backwards.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{impl}\NormalTok{<T> }\BuiltInTok{DoubleEndedIterator} \KeywordTok{for} \NormalTok{IntoIter<T> \{}
    \KeywordTok{fn} \NormalTok{next_back(&}\KeywordTok{mut} \KeywordTok{self}\NormalTok{) -> }\DataTypeTok{Option}\NormalTok{<T> \{}
        \KeywordTok{if} \KeywordTok{self}\NormalTok{.start == }\KeywordTok{self}\NormalTok{.end \{}
            \ConstantTok{None}
        \NormalTok{\} }\KeywordTok{else} \NormalTok{\{}
            \KeywordTok{unsafe} \NormalTok{\{}
                \KeywordTok{self}\NormalTok{.end = }\KeywordTok{self}\NormalTok{.end.offset(-}\DecValTok{1}\NormalTok{);}
                \ConstantTok{Some}\NormalTok{(ptr::read(}\KeywordTok{self}\NormalTok{.end))}
            \NormalTok{\}}
        \NormalTok{\}}
    \NormalTok{\}}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

Because IntoIter takes ownership of its allocation, it needs to
implement Drop to free it. However it also wants to implement Drop to
drop any elements it contains that weren't yielded.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{impl}\NormalTok{<T> }\BuiltInTok{Drop} \KeywordTok{for} \NormalTok{IntoIter<T> \{}
    \KeywordTok{fn} \NormalTok{drop(&}\KeywordTok{mut} \KeywordTok{self}\NormalTok{) \{}
        \KeywordTok{if} \KeywordTok{self}\NormalTok{.cap != }\DecValTok{0} \NormalTok{\{}
            \CommentTok{// drop any remaining elements}
            \KeywordTok{for} \NormalTok{_ }\KeywordTok{in} \NormalTok{&}\KeywordTok{mut} \NormalTok{*}\KeywordTok{self} \NormalTok{\{\}}

            \KeywordTok{let} \NormalTok{align = mem::align_of::<T>();}
            \KeywordTok{let} \NormalTok{elem_size = mem::size_of::<T>();}
            \KeywordTok{let} \NormalTok{num_bytes = elem_size * }\KeywordTok{self}\NormalTok{.cap;}
            \KeywordTok{unsafe} \NormalTok{\{}
                \NormalTok{heap::deallocate(*}\KeywordTok{self}\NormalTok{.buf }\KeywordTok{as} \NormalTok{*}\KeywordTok{mut} \NormalTok{_, num_bytes, align);}
            \NormalTok{\}}
        \NormalTok{\}}
    \NormalTok{\}}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\section{RawVec}\label{sec--vec-raw}

We've actually reached an interesting situation here: we've duplicated
the logic for specifying a buffer and freeing its memory in Vec and
IntoIter. Now that we've implemented it and identified \emph{actual}
logic duplication, this is a good time to perform some logic
compression.

We're going to abstract out the \texttt{(ptr,\ cap)} pair and give them
the logic for allocating, growing, and freeing:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{struct} \NormalTok{RawVec<T> \{}
    \NormalTok{ptr: Unique<T>,}
    \NormalTok{cap: }\DataTypeTok{usize}\NormalTok{,}
\NormalTok{\}}

\KeywordTok{impl}\NormalTok{<T> RawVec<T> \{}
    \KeywordTok{fn} \NormalTok{new() -> }\KeywordTok{Self} \NormalTok{\{}
        \PreprocessorTok{assert!}\NormalTok{(mem::size_of::<T>() != }\DecValTok{0}\NormalTok{, }\StringTok{"TODO: implement ZST support"}\NormalTok{);}
        \KeywordTok{unsafe} \NormalTok{\{}
            \NormalTok{RawVec \{ ptr: Unique::new(heap::EMPTY }\KeywordTok{as} \NormalTok{*}\KeywordTok{mut} \NormalTok{T), cap: }\DecValTok{0} \NormalTok{\}}
        \NormalTok{\}}
    \NormalTok{\}}

    \CommentTok{// unchanged from Vec}
    \KeywordTok{fn} \NormalTok{grow(&}\KeywordTok{mut} \KeywordTok{self}\NormalTok{) \{}
        \KeywordTok{unsafe} \NormalTok{\{}
            \KeywordTok{let} \NormalTok{align = mem::align_of::<T>();}
            \KeywordTok{let} \NormalTok{elem_size = mem::size_of::<T>();}

            \KeywordTok{let} \NormalTok{(new_cap, ptr) = }\KeywordTok{if} \KeywordTok{self}\NormalTok{.cap == }\DecValTok{0} \NormalTok{\{}
                \KeywordTok{let} \NormalTok{ptr = heap::allocate(elem_size, align);}
                \NormalTok{(}\DecValTok{1}\NormalTok{, ptr)}
            \NormalTok{\} }\KeywordTok{else} \NormalTok{\{}
                \KeywordTok{let} \NormalTok{new_cap = }\DecValTok{2} \NormalTok{* }\KeywordTok{self}\NormalTok{.cap;}
                \KeywordTok{let} \NormalTok{ptr = heap::reallocate(*}\KeywordTok{self}\NormalTok{.ptr }\KeywordTok{as} \NormalTok{*}\KeywordTok{mut} \NormalTok{_,}
                                            \KeywordTok{self}\NormalTok{.cap * elem_size,}
                                            \NormalTok{new_cap * elem_size,}
                                            \NormalTok{align);}
                \NormalTok{(new_cap, ptr)}
            \NormalTok{\};}

            \CommentTok{// If allocate or reallocate fail, we'll get `null` back}
            \KeywordTok{if} \NormalTok{ptr.is_null() \{ oom() \}}

            \KeywordTok{self}\NormalTok{.ptr = Unique::new(ptr }\KeywordTok{as} \NormalTok{*}\KeywordTok{mut} \NormalTok{_);}
            \KeywordTok{self}\NormalTok{.cap = new_cap;}
        \NormalTok{\}}
    \NormalTok{\}}
\NormalTok{\}}


\KeywordTok{impl}\NormalTok{<T> }\BuiltInTok{Drop} \KeywordTok{for} \NormalTok{RawVec<T> \{}
    \KeywordTok{fn} \NormalTok{drop(&}\KeywordTok{mut} \KeywordTok{self}\NormalTok{) \{}
        \KeywordTok{if} \KeywordTok{self}\NormalTok{.cap != }\DecValTok{0} \NormalTok{\{}
            \KeywordTok{let} \NormalTok{align = mem::align_of::<T>();}
            \KeywordTok{let} \NormalTok{elem_size = mem::size_of::<T>();}
            \KeywordTok{let} \NormalTok{num_bytes = elem_size * }\KeywordTok{self}\NormalTok{.cap;}
            \KeywordTok{unsafe} \NormalTok{\{}
                \NormalTok{heap::deallocate(*}\KeywordTok{self}\NormalTok{.ptr }\KeywordTok{as} \NormalTok{*}\KeywordTok{mut} \NormalTok{_, num_bytes, align);}
            \NormalTok{\}}
        \NormalTok{\}}
    \NormalTok{\}}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

And change Vec as follows:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{pub} \KeywordTok{struct} \DataTypeTok{Vec}\NormalTok{<T> \{}
    \NormalTok{buf: RawVec<T>,}
    \NormalTok{len: }\DataTypeTok{usize}\NormalTok{,}
\NormalTok{\}}

\KeywordTok{impl}\NormalTok{<T> }\DataTypeTok{Vec}\NormalTok{<T> \{}
    \KeywordTok{fn} \NormalTok{ptr(&}\KeywordTok{self}\NormalTok{) -> *}\KeywordTok{mut} \NormalTok{T \{ *}\KeywordTok{self}\NormalTok{.buf.ptr \}}

    \KeywordTok{fn} \NormalTok{cap(&}\KeywordTok{self}\NormalTok{) -> }\DataTypeTok{usize} \NormalTok{\{ }\KeywordTok{self}\NormalTok{.buf.cap \}}

    \KeywordTok{pub} \KeywordTok{fn} \NormalTok{new() -> }\KeywordTok{Self} \NormalTok{\{}
        \DataTypeTok{Vec} \NormalTok{\{ buf: RawVec::new(), len: }\DecValTok{0} \NormalTok{\}}
    \NormalTok{\}}

    \CommentTok{// push/pop/insert/remove largely unchanged:}
    \CommentTok{// * `self.ptr -> self.ptr()`}
    \CommentTok{// * `self.cap -> self.cap()`}
    \CommentTok{// * `self.grow -> self.buf.grow()`}
\NormalTok{\}}

\KeywordTok{impl}\NormalTok{<T> }\BuiltInTok{Drop} \KeywordTok{for} \DataTypeTok{Vec}\NormalTok{<T> \{}
    \KeywordTok{fn} \NormalTok{drop(&}\KeywordTok{mut} \KeywordTok{self}\NormalTok{) \{}
        \KeywordTok{while} \KeywordTok{let} \ConstantTok{Some}\NormalTok{(_) = }\KeywordTok{self}\NormalTok{.pop() \{\}}
        \CommentTok{// deallocation is handled by RawVec}
    \NormalTok{\}}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

And finally we can really simplify IntoIter:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{struct} \NormalTok{IntoIter<T> \{}
    \NormalTok{_buf: RawVec<T>, }\CommentTok{// we don't actually care about this. Just need it to live.}
    \NormalTok{start: *}\KeywordTok{const} \NormalTok{T,}
    \NormalTok{end: *}\KeywordTok{const} \NormalTok{T,}
\NormalTok{\}}

\CommentTok{// next and next_back literally unchanged since they never referred to the buf}

\KeywordTok{impl}\NormalTok{<T> }\BuiltInTok{Drop} \KeywordTok{for} \NormalTok{IntoIter<T> \{}
    \KeywordTok{fn} \NormalTok{drop(&}\KeywordTok{mut} \KeywordTok{self}\NormalTok{) \{}
        \CommentTok{// only need to ensure all our elements are read;}
        \CommentTok{// buffer will clean itself up afterwards.}
        \KeywordTok{for} \NormalTok{_ }\KeywordTok{in} \NormalTok{&}\KeywordTok{mut} \NormalTok{*}\KeywordTok{self} \NormalTok{\{\}}
    \NormalTok{\}}
\NormalTok{\}}

\KeywordTok{impl}\NormalTok{<T> }\DataTypeTok{Vec}\NormalTok{<T> \{}
    \KeywordTok{pub} \KeywordTok{fn} \NormalTok{into_iter(}\KeywordTok{self}\NormalTok{) -> IntoIter<T> \{}
        \KeywordTok{unsafe} \NormalTok{\{}
            \CommentTok{// need to use ptr::read to unsafely move the buf out since it's}
            \CommentTok{// not Copy, and Vec implements Drop (so we can't destructure it).}
            \KeywordTok{let} \NormalTok{buf = ptr::read(&}\KeywordTok{self}\NormalTok{.buf);}
            \KeywordTok{let} \NormalTok{len = }\KeywordTok{self}\NormalTok{.len;}
            \NormalTok{mem::forget(}\KeywordTok{self}\NormalTok{);}

            \NormalTok{IntoIter \{}
                \NormalTok{start: *buf.ptr,}
                \NormalTok{end: buf.ptr.offset(len }\KeywordTok{as} \DataTypeTok{isize}\NormalTok{),}
                \NormalTok{_buf: buf,}
            \NormalTok{\}}
        \NormalTok{\}}
    \NormalTok{\}}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

Much better.

\section{Drain}\label{sec--vec-drain}

Let's move on to Drain. Drain is largely the same as IntoIter, except
that instead of consuming the Vec, it borrows the Vec and leaves its
allocation untouched. For now we'll only implement the ``basic''
full-range version.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{use} \NormalTok{std::marker::PhantomData;}

\KeywordTok{struct} \NormalTok{Drain<}\OtherTok{'a}\NormalTok{, T: }\OtherTok{'a}\NormalTok{> \{}
    \CommentTok{// Need to bound the lifetime here, so we do it with `&'a mut Vec<T>`}
    \CommentTok{// because that's semantically what we contain. We're "just" calling}
    \CommentTok{// `pop()` and `remove(0)`.}
    \NormalTok{vec: PhantomData<&}\OtherTok{'a} \KeywordTok{mut} \DataTypeTok{Vec}\NormalTok{<T>>}
    \NormalTok{start: *}\KeywordTok{const} \NormalTok{T,}
    \NormalTok{end: *}\KeywordTok{const} \NormalTok{T,}
\NormalTok{\}}

\KeywordTok{impl}\NormalTok{<}\OtherTok{'a}\NormalTok{, T> }\BuiltInTok{Iterator} \KeywordTok{for} \NormalTok{Drain<}\OtherTok{'a}\NormalTok{, T> \{}
    \KeywordTok{type} \NormalTok{Item = T;}
    \KeywordTok{fn} \NormalTok{next(&}\KeywordTok{mut} \KeywordTok{self}\NormalTok{) -> }\DataTypeTok{Option}\NormalTok{<T> \{}
        \KeywordTok{if} \KeywordTok{self}\NormalTok{.start == }\KeywordTok{self}\NormalTok{.end \{}
            \ConstantTok{None}
\end{Highlighting}
\end{Shaded}

-- wait, this is seeming familiar. Let's do some more compression. Both
IntoIter and Drain have the exact same structure, let's just factor it
out.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{struct} \NormalTok{RawValIter<T> \{}
    \NormalTok{start: *}\KeywordTok{const} \NormalTok{T,}
    \NormalTok{end: *}\KeywordTok{const} \NormalTok{T,}
\NormalTok{\}}

\KeywordTok{impl}\NormalTok{<T> RawValIter<T> \{}
    \CommentTok{// unsafe to construct because it has no associated lifetimes.}
    \CommentTok{// This is necessary to store a RawValIter in the same struct as}
    \CommentTok{// its actual allocation. OK since it's a private implementation}
    \CommentTok{// detail.}
    \KeywordTok{unsafe} \KeywordTok{fn} \NormalTok{new(slice: &[T]) -> }\KeywordTok{Self} \NormalTok{\{}
        \NormalTok{RawValIter \{}
            \NormalTok{start: slice.as_ptr(),}
            \NormalTok{end: }\KeywordTok{if} \NormalTok{slice.len() == }\DecValTok{0} \NormalTok{\{}
                \CommentTok{// if `len = 0`, then this is not actually allocated memory.}
                \CommentTok{// Need to avoid offsetting because that will give wrong}
                \CommentTok{// information to LLVM via GEP.}
                \NormalTok{slice.as_ptr()}
            \NormalTok{\} }\KeywordTok{else} \NormalTok{\{}
                \NormalTok{slice.as_ptr().offset(slice.len() }\KeywordTok{as} \DataTypeTok{isize}\NormalTok{)}
            \NormalTok{\}}
        \NormalTok{\}}
    \NormalTok{\}}
\NormalTok{\}}

\CommentTok{// Iterator and DoubleEndedIterator impls identical to IntoIter.}
\end{Highlighting}
\end{Shaded}

And IntoIter becomes the following:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{pub} \KeywordTok{struct} \NormalTok{IntoIter<T> \{}
    \NormalTok{_buf: RawVec<T>, }\CommentTok{// we don't actually care about this. Just need it to live.}
    \NormalTok{iter: RawValIter<T>,}
\NormalTok{\}}

\KeywordTok{impl}\NormalTok{<T> }\BuiltInTok{Iterator} \KeywordTok{for} \NormalTok{IntoIter<T> \{}
    \KeywordTok{type} \NormalTok{Item = T;}
    \KeywordTok{fn} \NormalTok{next(&}\KeywordTok{mut} \KeywordTok{self}\NormalTok{) -> }\DataTypeTok{Option}\NormalTok{<T> \{ }\KeywordTok{self}\NormalTok{.iter.next() \}}
    \KeywordTok{fn} \NormalTok{size_hint(&}\KeywordTok{self}\NormalTok{) -> (}\DataTypeTok{usize}\NormalTok{, }\DataTypeTok{Option}\NormalTok{<}\DataTypeTok{usize}\NormalTok{>) \{ }\KeywordTok{self}\NormalTok{.iter.size_hint() \}}
\NormalTok{\}}

\KeywordTok{impl}\NormalTok{<T> }\BuiltInTok{DoubleEndedIterator} \KeywordTok{for} \NormalTok{IntoIter<T> \{}
    \KeywordTok{fn} \NormalTok{next_back(&}\KeywordTok{mut} \KeywordTok{self}\NormalTok{) -> }\DataTypeTok{Option}\NormalTok{<T> \{ }\KeywordTok{self}\NormalTok{.iter.next_back() \}}
\NormalTok{\}}

\KeywordTok{impl}\NormalTok{<T> }\BuiltInTok{Drop} \KeywordTok{for} \NormalTok{IntoIter<T> \{}
    \KeywordTok{fn} \NormalTok{drop(&}\KeywordTok{mut} \KeywordTok{self}\NormalTok{) \{}
        \KeywordTok{for} \NormalTok{_ }\KeywordTok{in} \NormalTok{&}\KeywordTok{mut} \KeywordTok{self}\NormalTok{.iter \{\}}
    \NormalTok{\}}
\NormalTok{\}}

\KeywordTok{impl}\NormalTok{<T> }\DataTypeTok{Vec}\NormalTok{<T> \{}
    \KeywordTok{pub} \KeywordTok{fn} \NormalTok{into_iter(}\KeywordTok{self}\NormalTok{) -> IntoIter<T> \{}
        \KeywordTok{unsafe} \NormalTok{\{}
            \KeywordTok{let} \NormalTok{iter = RawValIter::new(&}\KeywordTok{self}\NormalTok{);}

            \KeywordTok{let} \NormalTok{buf = ptr::read(&}\KeywordTok{self}\NormalTok{.buf);}
            \NormalTok{mem::forget(}\KeywordTok{self}\NormalTok{);}

            \NormalTok{IntoIter \{}
                \NormalTok{iter: iter,}
                \NormalTok{_buf: buf,}
            \NormalTok{\}}
        \NormalTok{\}}
    \NormalTok{\}}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

Note that I've left a few quirks in this design to make upgrading Drain
to work with arbitrary subranges a bit easier. In particular we
\emph{could} have RawValIter drain itself on drop, but that won't work
right for a more complex Drain. We also take a slice to simplify Drain
initialization.

Alright, now Drain is really easy:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{use} \NormalTok{std::marker::PhantomData;}

\KeywordTok{pub} \KeywordTok{struct} \NormalTok{Drain<}\OtherTok{'a}\NormalTok{, T: }\OtherTok{'a}\NormalTok{> \{}
    \NormalTok{vec: PhantomData<&}\OtherTok{'a} \KeywordTok{mut} \DataTypeTok{Vec}\NormalTok{<T>>,}
    \NormalTok{iter: RawValIter<T>,}
\NormalTok{\}}

\KeywordTok{impl}\NormalTok{<}\OtherTok{'a}\NormalTok{, T> }\BuiltInTok{Iterator} \KeywordTok{for} \NormalTok{Drain<}\OtherTok{'a}\NormalTok{, T> \{}
    \KeywordTok{type} \NormalTok{Item = T;}
    \KeywordTok{fn} \NormalTok{next(&}\KeywordTok{mut} \KeywordTok{self}\NormalTok{) -> }\DataTypeTok{Option}\NormalTok{<T> \{ }\KeywordTok{self}\NormalTok{.iter.next() \}}
    \KeywordTok{fn} \NormalTok{size_hint(&}\KeywordTok{self}\NormalTok{) -> (}\DataTypeTok{usize}\NormalTok{, }\DataTypeTok{Option}\NormalTok{<}\DataTypeTok{usize}\NormalTok{>) \{ }\KeywordTok{self}\NormalTok{.iter.size_hint() \}}
\NormalTok{\}}

\KeywordTok{impl}\NormalTok{<}\OtherTok{'a}\NormalTok{, T> }\BuiltInTok{DoubleEndedIterator} \KeywordTok{for} \NormalTok{Drain<}\OtherTok{'a}\NormalTok{, T> \{}
    \KeywordTok{fn} \NormalTok{next_back(&}\KeywordTok{mut} \KeywordTok{self}\NormalTok{) -> }\DataTypeTok{Option}\NormalTok{<T> \{ }\KeywordTok{self}\NormalTok{.iter.next_back() \}}
\NormalTok{\}}

\KeywordTok{impl}\NormalTok{<}\OtherTok{'a}\NormalTok{, T> }\BuiltInTok{Drop} \KeywordTok{for} \NormalTok{Drain<}\OtherTok{'a}\NormalTok{, T> \{}
    \KeywordTok{fn} \NormalTok{drop(&}\KeywordTok{mut} \KeywordTok{self}\NormalTok{) \{}
        \KeywordTok{for} \NormalTok{_ }\KeywordTok{in} \NormalTok{&}\KeywordTok{mut} \KeywordTok{self}\NormalTok{.iter \{\}}
    \NormalTok{\}}
\NormalTok{\}}

\KeywordTok{impl}\NormalTok{<T> }\DataTypeTok{Vec}\NormalTok{<T> \{}
    \KeywordTok{pub} \KeywordTok{fn} \NormalTok{drain(&}\KeywordTok{mut} \KeywordTok{self}\NormalTok{) -> Drain<T> \{}
        \KeywordTok{unsafe} \NormalTok{\{}
            \KeywordTok{let} \NormalTok{iter = RawValIter::new(&}\KeywordTok{self}\NormalTok{);}

            \CommentTok{// this is a mem::forget safety thing. If Drain is forgotten, we just}
            \CommentTok{// leak the whole Vec's contents. Also we need to do this *eventually*}
            \CommentTok{// anyway, so why not do it now?}
            \KeywordTok{self}\NormalTok{.len = }\DecValTok{0}\NormalTok{;}

            \NormalTok{Drain \{}
                \NormalTok{iter: iter,}
                \NormalTok{vec: PhantomData,}
            \NormalTok{\}}
        \NormalTok{\}}
    \NormalTok{\}}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

For more details on the \texttt{mem::forget} problem, see the
\protect\hyperlink{sec--leaking}{section on leaks}.

\section{Handling Zero-Sized Types}\label{sec--vec-zsts}

It's time. We're going to fight the specter that is zero-sized types.
Safe Rust \emph{never} needs to care about this, but Vec is very
intensive on raw pointers and raw allocations, which are exactly the two
things that care about zero-sized types. We need to be careful of two
things:

\begin{itemize}
\tightlist
\item
  The raw allocator API has undefined behavior if you pass in 0 for an
  allocation size.
\item
  raw pointer offsets are no-ops for zero-sized types, which will break
  our C-style pointer iterator.
\end{itemize}

Thankfully we abstracted out pointer-iterators and allocating handling
into RawValIter and RawVec respectively. How mysteriously convenient.

\subsubsection{Allocating Zero-Sized
Types}\label{allocating-zero-sized-types}

So if the allocator API doesn't support zero-sized allocations, what on
earth do we store as our allocation? Why, \texttt{heap::EMPTY} of
course! Almost every operation with a ZST is a no-op since ZSTs have
exactly one value, and therefore no state needs to be considered to
store or load them. This actually extends to \texttt{ptr::read} and
\texttt{ptr::write}: they won't actually look at the pointer at all. As
such we never need to change the pointer.

Note however that our previous reliance on running out of memory before
overflow is no longer valid with zero-sized types. We must explicitly
guard against capacity overflow for zero-sized types.

Due to our current architecture, all this means is writing 3 guards, one
in each method of RawVec.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{impl}\NormalTok{<T> RawVec<T> \{}
    \KeywordTok{fn} \NormalTok{new() -> }\KeywordTok{Self} \NormalTok{\{}
        \KeywordTok{unsafe} \NormalTok{\{}
            \CommentTok{// !0 is usize::MAX. This branch should be stripped at compile time.}
            \KeywordTok{let} \NormalTok{cap = }\KeywordTok{if} \NormalTok{mem::size_of::<T>() == }\DecValTok{0} \NormalTok{\{ !}\DecValTok{0} \NormalTok{\} }\KeywordTok{else} \NormalTok{\{ }\DecValTok{0} \NormalTok{\};}

            \CommentTok{// heap::EMPTY doubles as "unallocated" and "zero-sized allocation"}
            \NormalTok{RawVec \{ ptr: Unique::new(heap::EMPTY }\KeywordTok{as} \NormalTok{*}\KeywordTok{mut} \NormalTok{T), cap: cap \}}
        \NormalTok{\}}
    \NormalTok{\}}

    \KeywordTok{fn} \NormalTok{grow(&}\KeywordTok{mut} \KeywordTok{self}\NormalTok{) \{}
        \KeywordTok{unsafe} \NormalTok{\{}
            \KeywordTok{let} \NormalTok{elem_size = mem::size_of::<T>();}

            \CommentTok{// since we set the capacity to usize::MAX when elem_size is}
            \CommentTok{// 0, getting to here necessarily means the Vec is overfull.}
            \PreprocessorTok{assert!}\NormalTok{(elem_size != }\DecValTok{0}\NormalTok{, }\StringTok{"capacity overflow"}\NormalTok{);}

            \KeywordTok{let} \NormalTok{align = mem::align_of::<T>();}

            \KeywordTok{let} \NormalTok{(new_cap, ptr) = }\KeywordTok{if} \KeywordTok{self}\NormalTok{.cap == }\DecValTok{0} \NormalTok{\{}
                \KeywordTok{let} \NormalTok{ptr = heap::allocate(elem_size, align);}
                \NormalTok{(}\DecValTok{1}\NormalTok{, ptr)}
            \NormalTok{\} }\KeywordTok{else} \NormalTok{\{}
                \KeywordTok{let} \NormalTok{new_cap = }\DecValTok{2} \NormalTok{* }\KeywordTok{self}\NormalTok{.cap;}
                \KeywordTok{let} \NormalTok{ptr = heap::reallocate(*}\KeywordTok{self}\NormalTok{.ptr }\KeywordTok{as} \NormalTok{*}\KeywordTok{mut} \NormalTok{_,}
                                            \KeywordTok{self}\NormalTok{.cap * elem_size,}
                                            \NormalTok{new_cap * elem_size,}
                                            \NormalTok{align);}
                \NormalTok{(new_cap, ptr)}
            \NormalTok{\};}

            \CommentTok{// If allocate or reallocate fail, we'll get `null` back}
            \KeywordTok{if} \NormalTok{ptr.is_null() \{ oom() \}}

            \KeywordTok{self}\NormalTok{.ptr = Unique::new(ptr }\KeywordTok{as} \NormalTok{*}\KeywordTok{mut} \NormalTok{_);}
            \KeywordTok{self}\NormalTok{.cap = new_cap;}
        \NormalTok{\}}
    \NormalTok{\}}
\NormalTok{\}}

\KeywordTok{impl}\NormalTok{<T> }\BuiltInTok{Drop} \KeywordTok{for} \NormalTok{RawVec<T> \{}
    \KeywordTok{fn} \NormalTok{drop(&}\KeywordTok{mut} \KeywordTok{self}\NormalTok{) \{}
        \KeywordTok{let} \NormalTok{elem_size = mem::size_of::<T>();}

        \CommentTok{// don't free zero-sized allocations, as they were never allocated.}
        \KeywordTok{if} \KeywordTok{self}\NormalTok{.cap != }\DecValTok{0} \NormalTok{&& elem_size != }\DecValTok{0} \NormalTok{\{}
            \KeywordTok{let} \NormalTok{align = mem::align_of::<T>();}

            \KeywordTok{let} \NormalTok{num_bytes = elem_size * }\KeywordTok{self}\NormalTok{.cap;}
            \KeywordTok{unsafe} \NormalTok{\{}
                \NormalTok{heap::deallocate(*}\KeywordTok{self}\NormalTok{.ptr }\KeywordTok{as} \NormalTok{*}\KeywordTok{mut} \NormalTok{_, num_bytes, align);}
            \NormalTok{\}}
        \NormalTok{\}}
    \NormalTok{\}}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

That's it. We support pushing and popping zero-sized types now. Our
iterators (that aren't provided by slice Deref) are still busted,
though.

\subsubsection{Iterating Zero-Sized
Types}\label{iterating-zero-sized-types}

Zero-sized offsets are no-ops. This means that our current design will
always initialize \texttt{start} and \texttt{end} as the same value, and
our iterators will yield nothing. The current solution to this is to
cast the pointers to integers, increment, and then cast them back:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{impl}\NormalTok{<T> RawValIter<T> \{}
    \KeywordTok{unsafe} \KeywordTok{fn} \NormalTok{new(slice: &[T]) -> }\KeywordTok{Self} \NormalTok{\{}
        \NormalTok{RawValIter \{}
            \NormalTok{start: slice.as_ptr(),}
            \NormalTok{end: }\KeywordTok{if} \NormalTok{mem::size_of::<T>() == }\DecValTok{0} \NormalTok{\{}
                \NormalTok{((slice.as_ptr() }\KeywordTok{as} \DataTypeTok{usize}\NormalTok{) + slice.len()) }\KeywordTok{as} \NormalTok{*}\KeywordTok{const} \NormalTok{_}
            \NormalTok{\} }\KeywordTok{else} \KeywordTok{if} \NormalTok{slice.len() == }\DecValTok{0} \NormalTok{\{}
                \NormalTok{slice.as_ptr()}
            \NormalTok{\} }\KeywordTok{else} \NormalTok{\{}
                \NormalTok{slice.as_ptr().offset(slice.len() }\KeywordTok{as} \DataTypeTok{isize}\NormalTok{)}
            \NormalTok{\}}
        \NormalTok{\}}
    \NormalTok{\}}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

Now we have a different bug. Instead of our iterators not running at
all, our iterators now run \emph{forever}. We need to do the same trick
in our iterator impls. Also, our size\_hint computation code will divide
by 0 for ZSTs. Since we'll basically be treating the two pointers as if
they point to bytes, we'll just map size 0 to divide by 1.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{impl}\NormalTok{<T> }\BuiltInTok{Iterator} \KeywordTok{for} \NormalTok{RawValIter<T> \{}
    \KeywordTok{type} \NormalTok{Item = T;}
    \KeywordTok{fn} \NormalTok{next(&}\KeywordTok{mut} \KeywordTok{self}\NormalTok{) -> }\DataTypeTok{Option}\NormalTok{<T> \{}
        \KeywordTok{if} \KeywordTok{self}\NormalTok{.start == }\KeywordTok{self}\NormalTok{.end \{}
            \ConstantTok{None}
        \NormalTok{\} }\KeywordTok{else} \NormalTok{\{}
            \KeywordTok{unsafe} \NormalTok{\{}
                \KeywordTok{let} \NormalTok{result = ptr::read(}\KeywordTok{self}\NormalTok{.start);}
                \KeywordTok{self}\NormalTok{.start = }\KeywordTok{if} \NormalTok{mem::size_of::<T>() == }\DecValTok{0} \NormalTok{\{}
                    \NormalTok{(}\KeywordTok{self}\NormalTok{.start }\KeywordTok{as} \DataTypeTok{usize} \NormalTok{+ }\DecValTok{1}\NormalTok{) }\KeywordTok{as} \NormalTok{*}\KeywordTok{const} \NormalTok{_}
                \NormalTok{\} }\KeywordTok{else} \NormalTok{\{}
                    \KeywordTok{self}\NormalTok{.start.offset(}\DecValTok{1}\NormalTok{)}
                \NormalTok{\};}
                \ConstantTok{Some}\NormalTok{(result)}
            \NormalTok{\}}
        \NormalTok{\}}
    \NormalTok{\}}

    \KeywordTok{fn} \NormalTok{size_hint(&}\KeywordTok{self}\NormalTok{) -> (}\DataTypeTok{usize}\NormalTok{, }\DataTypeTok{Option}\NormalTok{<}\DataTypeTok{usize}\NormalTok{>) \{}
        \KeywordTok{let} \NormalTok{elem_size = mem::size_of::<T>();}
        \KeywordTok{let} \NormalTok{len = (}\KeywordTok{self}\NormalTok{.end }\KeywordTok{as} \DataTypeTok{usize} \NormalTok{- }\KeywordTok{self}\NormalTok{.start }\KeywordTok{as} \DataTypeTok{usize}\NormalTok{)}
                  \NormalTok{/ }\KeywordTok{if} \NormalTok{elem_size == }\DecValTok{0} \NormalTok{\{ }\DecValTok{1} \NormalTok{\} }\KeywordTok{else} \NormalTok{\{ elem_size \};}
        \NormalTok{(len, }\ConstantTok{Some}\NormalTok{(len))}
    \NormalTok{\}}
\NormalTok{\}}

\KeywordTok{impl}\NormalTok{<T> }\BuiltInTok{DoubleEndedIterator} \KeywordTok{for} \NormalTok{RawValIter<T> \{}
    \KeywordTok{fn} \NormalTok{next_back(&}\KeywordTok{mut} \KeywordTok{self}\NormalTok{) -> }\DataTypeTok{Option}\NormalTok{<T> \{}
        \KeywordTok{if} \KeywordTok{self}\NormalTok{.start == }\KeywordTok{self}\NormalTok{.end \{}
            \ConstantTok{None}
        \NormalTok{\} }\KeywordTok{else} \NormalTok{\{}
            \KeywordTok{unsafe} \NormalTok{\{}
                \KeywordTok{self}\NormalTok{.end = }\KeywordTok{if} \NormalTok{mem::size_of::<T>() == }\DecValTok{0} \NormalTok{\{}
                    \NormalTok{(}\KeywordTok{self}\NormalTok{.end }\KeywordTok{as} \DataTypeTok{usize} \NormalTok{- }\DecValTok{1}\NormalTok{) }\KeywordTok{as} \NormalTok{*}\KeywordTok{const} \NormalTok{_}
                \NormalTok{\} }\KeywordTok{else} \NormalTok{\{}
                    \KeywordTok{self}\NormalTok{.end.offset(-}\DecValTok{1}\NormalTok{)}
                \NormalTok{\};}
                \ConstantTok{Some}\NormalTok{(ptr::read(}\KeywordTok{self}\NormalTok{.end))}
            \NormalTok{\}}
        \NormalTok{\}}
    \NormalTok{\}}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

And that's it. Iteration works!

\section{Final Code}\label{sec--vec-final}

\begin{Shaded}
\begin{Highlighting}[]
\AttributeTok{#![}\NormalTok{feature}\AttributeTok{(}\NormalTok{unique}\AttributeTok{)]}
\AttributeTok{#![}\NormalTok{feature}\AttributeTok{(}\NormalTok{alloc}\AttributeTok{,} \NormalTok{heap_api}\AttributeTok{)]}

\KeywordTok{extern} \KeywordTok{crate} \NormalTok{alloc;}

\KeywordTok{use} \NormalTok{std::ptr::\{Unique, }\KeywordTok{self}\NormalTok{\};}
\KeywordTok{use} \NormalTok{std::mem;}
\KeywordTok{use} \NormalTok{std::ops::\{Deref, DerefMut\};}
\KeywordTok{use} \NormalTok{std::marker::PhantomData;}

\KeywordTok{use} \NormalTok{alloc::heap;}

\KeywordTok{struct} \NormalTok{RawVec<T> \{}
    \NormalTok{ptr: Unique<T>,}
    \NormalTok{cap: }\DataTypeTok{usize}\NormalTok{,}
\NormalTok{\}}

\KeywordTok{impl}\NormalTok{<T> RawVec<T> \{}
    \KeywordTok{fn} \NormalTok{new() -> }\KeywordTok{Self} \NormalTok{\{}
        \KeywordTok{unsafe} \NormalTok{\{}
            \CommentTok{// !0 is usize::MAX. This branch should be stripped at compile time.}
            \KeywordTok{let} \NormalTok{cap = }\KeywordTok{if} \NormalTok{mem::size_of::<T>() == }\DecValTok{0} \NormalTok{\{ !}\DecValTok{0} \NormalTok{\} }\KeywordTok{else} \NormalTok{\{ }\DecValTok{0} \NormalTok{\};}

            \CommentTok{// heap::EMPTY doubles as "unallocated" and "zero-sized allocation"}
            \NormalTok{RawVec \{ ptr: Unique::new(heap::EMPTY }\KeywordTok{as} \NormalTok{*}\KeywordTok{mut} \NormalTok{T), cap: cap \}}
        \NormalTok{\}}
    \NormalTok{\}}

    \KeywordTok{fn} \NormalTok{grow(&}\KeywordTok{mut} \KeywordTok{self}\NormalTok{) \{}
        \KeywordTok{unsafe} \NormalTok{\{}
            \KeywordTok{let} \NormalTok{elem_size = mem::size_of::<T>();}

            \CommentTok{// since we set the capacity to usize::MAX when elem_size is}
            \CommentTok{// 0, getting to here necessarily means the Vec is overfull.}
            \PreprocessorTok{assert!}\NormalTok{(elem_size != }\DecValTok{0}\NormalTok{, }\StringTok{"capacity overflow"}\NormalTok{);}

            \KeywordTok{let} \NormalTok{align = mem::align_of::<T>();}

            \KeywordTok{let} \NormalTok{(new_cap, ptr) = }\KeywordTok{if} \KeywordTok{self}\NormalTok{.cap == }\DecValTok{0} \NormalTok{\{}
                \KeywordTok{let} \NormalTok{ptr = heap::allocate(elem_size, align);}
                \NormalTok{(}\DecValTok{1}\NormalTok{, ptr)}
            \NormalTok{\} }\KeywordTok{else} \NormalTok{\{}
                \KeywordTok{let} \NormalTok{new_cap = }\DecValTok{2} \NormalTok{* }\KeywordTok{self}\NormalTok{.cap;}
                \KeywordTok{let} \NormalTok{ptr = heap::reallocate(*}\KeywordTok{self}\NormalTok{.ptr }\KeywordTok{as} \NormalTok{*}\KeywordTok{mut} \NormalTok{_,}
                                            \KeywordTok{self}\NormalTok{.cap * elem_size,}
                                            \NormalTok{new_cap * elem_size,}
                                            \NormalTok{align);}
                \NormalTok{(new_cap, ptr)}
            \NormalTok{\};}

            \CommentTok{// If allocate or reallocate fail, we'll get `null` back}
            \KeywordTok{if} \NormalTok{ptr.is_null() \{ oom() \}}

            \KeywordTok{self}\NormalTok{.ptr = Unique::new(ptr }\KeywordTok{as} \NormalTok{*}\KeywordTok{mut} \NormalTok{_);}
            \KeywordTok{self}\NormalTok{.cap = new_cap;}
        \NormalTok{\}}
    \NormalTok{\}}
\NormalTok{\}}

\KeywordTok{impl}\NormalTok{<T> }\BuiltInTok{Drop} \KeywordTok{for} \NormalTok{RawVec<T> \{}
    \KeywordTok{fn} \NormalTok{drop(&}\KeywordTok{mut} \KeywordTok{self}\NormalTok{) \{}
        \KeywordTok{let} \NormalTok{elem_size = mem::size_of::<T>();}
        \KeywordTok{if} \KeywordTok{self}\NormalTok{.cap != }\DecValTok{0} \NormalTok{&& elem_size != }\DecValTok{0} \NormalTok{\{}
            \KeywordTok{let} \NormalTok{align = mem::align_of::<T>();}

            \KeywordTok{let} \NormalTok{num_bytes = elem_size * }\KeywordTok{self}\NormalTok{.cap;}
            \KeywordTok{unsafe} \NormalTok{\{}
                \NormalTok{heap::deallocate(*}\KeywordTok{self}\NormalTok{.ptr }\KeywordTok{as} \NormalTok{*}\KeywordTok{mut} \NormalTok{_, num_bytes, align);}
            \NormalTok{\}}
        \NormalTok{\}}
    \NormalTok{\}}
\NormalTok{\}}





\KeywordTok{pub} \KeywordTok{struct} \DataTypeTok{Vec}\NormalTok{<T> \{}
    \NormalTok{buf: RawVec<T>,}
    \NormalTok{len: }\DataTypeTok{usize}\NormalTok{,}
\NormalTok{\}}

\KeywordTok{impl}\NormalTok{<T> }\DataTypeTok{Vec}\NormalTok{<T> \{}
    \KeywordTok{fn} \NormalTok{ptr(&}\KeywordTok{self}\NormalTok{) -> *}\KeywordTok{mut} \NormalTok{T \{ *}\KeywordTok{self}\NormalTok{.buf.ptr \}}

    \KeywordTok{fn} \NormalTok{cap(&}\KeywordTok{self}\NormalTok{) -> }\DataTypeTok{usize} \NormalTok{\{ }\KeywordTok{self}\NormalTok{.buf.cap \}}

    \KeywordTok{pub} \KeywordTok{fn} \NormalTok{new() -> }\KeywordTok{Self} \NormalTok{\{}
        \DataTypeTok{Vec} \NormalTok{\{ buf: RawVec::new(), len: }\DecValTok{0} \NormalTok{\}}
    \NormalTok{\}}
    \KeywordTok{pub} \KeywordTok{fn} \NormalTok{push(&}\KeywordTok{mut} \KeywordTok{self}\NormalTok{, elem: T) \{}
        \KeywordTok{if} \KeywordTok{self}\NormalTok{.len == }\KeywordTok{self}\NormalTok{.cap() \{ }\KeywordTok{self}\NormalTok{.buf.grow(); \}}

        \KeywordTok{unsafe} \NormalTok{\{}
            \NormalTok{ptr::write(}\KeywordTok{self}\NormalTok{.ptr().offset(}\KeywordTok{self}\NormalTok{.len }\KeywordTok{as} \DataTypeTok{isize}\NormalTok{), elem);}
        \NormalTok{\}}

        \CommentTok{// Can't fail, we'll OOM first.}
        \KeywordTok{self}\NormalTok{.len += }\DecValTok{1}\NormalTok{;}
    \NormalTok{\}}

    \KeywordTok{pub} \KeywordTok{fn} \NormalTok{pop(&}\KeywordTok{mut} \KeywordTok{self}\NormalTok{) -> }\DataTypeTok{Option}\NormalTok{<T> \{}
        \KeywordTok{if} \KeywordTok{self}\NormalTok{.len == }\DecValTok{0} \NormalTok{\{}
            \ConstantTok{None}
        \NormalTok{\} }\KeywordTok{else} \NormalTok{\{}
            \KeywordTok{self}\NormalTok{.len -= }\DecValTok{1}\NormalTok{;}
            \KeywordTok{unsafe} \NormalTok{\{}
                \ConstantTok{Some}\NormalTok{(ptr::read(}\KeywordTok{self}\NormalTok{.ptr().offset(}\KeywordTok{self}\NormalTok{.len }\KeywordTok{as} \DataTypeTok{isize}\NormalTok{)))}
            \NormalTok{\}}
        \NormalTok{\}}
    \NormalTok{\}}

    \KeywordTok{pub} \KeywordTok{fn} \NormalTok{insert(&}\KeywordTok{mut} \KeywordTok{self}\NormalTok{, index: }\DataTypeTok{usize}\NormalTok{, elem: T) \{}
        \PreprocessorTok{assert!}\NormalTok{(index <= }\KeywordTok{self}\NormalTok{.len, }\StringTok{"index out of bounds"}\NormalTok{);}
        \KeywordTok{if} \KeywordTok{self}\NormalTok{.cap() == }\KeywordTok{self}\NormalTok{.len \{ }\KeywordTok{self}\NormalTok{.buf.grow(); \}}

        \KeywordTok{unsafe} \NormalTok{\{}
            \KeywordTok{if} \NormalTok{index < }\KeywordTok{self}\NormalTok{.len \{}
                \NormalTok{ptr::copy(}\KeywordTok{self}\NormalTok{.ptr().offset(index }\KeywordTok{as} \DataTypeTok{isize}\NormalTok{),}
                          \KeywordTok{self}\NormalTok{.ptr().offset(index }\KeywordTok{as} \DataTypeTok{isize} \NormalTok{+ }\DecValTok{1}\NormalTok{),}
                          \KeywordTok{self}\NormalTok{.len - index);}
            \NormalTok{\}}
            \NormalTok{ptr::write(}\KeywordTok{self}\NormalTok{.ptr().offset(index }\KeywordTok{as} \DataTypeTok{isize}\NormalTok{), elem);}
            \KeywordTok{self}\NormalTok{.len += }\DecValTok{1}\NormalTok{;}
        \NormalTok{\}}
    \NormalTok{\}}

    \KeywordTok{pub} \KeywordTok{fn} \NormalTok{remove(&}\KeywordTok{mut} \KeywordTok{self}\NormalTok{, index: }\DataTypeTok{usize}\NormalTok{) -> T \{}
        \PreprocessorTok{assert!}\NormalTok{(index < }\KeywordTok{self}\NormalTok{.len, }\StringTok{"index out of bounds"}\NormalTok{);}
        \KeywordTok{unsafe} \NormalTok{\{}
            \KeywordTok{self}\NormalTok{.len -= }\DecValTok{1}\NormalTok{;}
            \KeywordTok{let} \NormalTok{result = ptr::read(}\KeywordTok{self}\NormalTok{.ptr().offset(index }\KeywordTok{as} \DataTypeTok{isize}\NormalTok{));}
            \NormalTok{ptr::copy(}\KeywordTok{self}\NormalTok{.ptr().offset(index }\KeywordTok{as} \DataTypeTok{isize} \NormalTok{+ }\DecValTok{1}\NormalTok{),}
                      \KeywordTok{self}\NormalTok{.ptr().offset(index }\KeywordTok{as} \DataTypeTok{isize}\NormalTok{),}
                      \KeywordTok{self}\NormalTok{.len - index);}
            \NormalTok{result}
        \NormalTok{\}}
    \NormalTok{\}}

    \KeywordTok{pub} \KeywordTok{fn} \NormalTok{into_iter(}\KeywordTok{self}\NormalTok{) -> IntoIter<T> \{}
        \KeywordTok{unsafe} \NormalTok{\{}
            \KeywordTok{let} \NormalTok{iter = RawValIter::new(&}\KeywordTok{self}\NormalTok{);}
            \KeywordTok{let} \NormalTok{buf = ptr::read(&}\KeywordTok{self}\NormalTok{.buf);}
            \NormalTok{mem::forget(}\KeywordTok{self}\NormalTok{);}

            \NormalTok{IntoIter \{}
                \NormalTok{iter: iter,}
                \NormalTok{_buf: buf,}
            \NormalTok{\}}
        \NormalTok{\}}
    \NormalTok{\}}

    \KeywordTok{pub} \KeywordTok{fn} \NormalTok{drain(&}\KeywordTok{mut} \KeywordTok{self}\NormalTok{) -> Drain<T> \{}
        \KeywordTok{unsafe} \NormalTok{\{}
            \KeywordTok{let} \NormalTok{iter = RawValIter::new(&}\KeywordTok{self}\NormalTok{);}

            \CommentTok{// this is a mem::forget safety thing. If Drain is forgotten, we just}
            \CommentTok{// leak the whole Vec's contents. Also we need to do this *eventually*}
            \CommentTok{// anyway, so why not do it now?}
            \KeywordTok{self}\NormalTok{.len = }\DecValTok{0}\NormalTok{;}

            \NormalTok{Drain \{}
                \NormalTok{iter: iter,}
                \NormalTok{vec: PhantomData,}
            \NormalTok{\}}
        \NormalTok{\}}
    \NormalTok{\}}
\NormalTok{\}}

\KeywordTok{impl}\NormalTok{<T> }\BuiltInTok{Drop} \KeywordTok{for} \DataTypeTok{Vec}\NormalTok{<T> \{}
    \KeywordTok{fn} \NormalTok{drop(&}\KeywordTok{mut} \KeywordTok{self}\NormalTok{) \{}
        \KeywordTok{while} \KeywordTok{let} \ConstantTok{Some}\NormalTok{(_) = }\KeywordTok{self}\NormalTok{.pop() \{\}}
        \CommentTok{// allocation is handled by RawVec}
    \NormalTok{\}}
\NormalTok{\}}

\KeywordTok{impl}\NormalTok{<T> Deref }\KeywordTok{for} \DataTypeTok{Vec}\NormalTok{<T> \{}
    \KeywordTok{type} \NormalTok{Target = [T];}
    \KeywordTok{fn} \NormalTok{deref(&}\KeywordTok{self}\NormalTok{) -> &[T] \{}
        \KeywordTok{unsafe} \NormalTok{\{}
            \NormalTok{::std::slice::from_raw_parts(}\KeywordTok{self}\NormalTok{.ptr(), }\KeywordTok{self}\NormalTok{.len)}
        \NormalTok{\}}
    \NormalTok{\}}
\NormalTok{\}}

\KeywordTok{impl}\NormalTok{<T> DerefMut }\KeywordTok{for} \DataTypeTok{Vec}\NormalTok{<T> \{}
    \KeywordTok{fn} \NormalTok{deref_mut(&}\KeywordTok{mut} \KeywordTok{self}\NormalTok{) -> &}\KeywordTok{mut} \NormalTok{[T] \{}
        \KeywordTok{unsafe} \NormalTok{\{}
            \NormalTok{::std::slice::from_raw_parts_mut(}\KeywordTok{self}\NormalTok{.ptr(), }\KeywordTok{self}\NormalTok{.len)}
        \NormalTok{\}}
    \NormalTok{\}}
\NormalTok{\}}





\KeywordTok{struct} \NormalTok{RawValIter<T> \{}
    \NormalTok{start: *}\KeywordTok{const} \NormalTok{T,}
    \NormalTok{end: *}\KeywordTok{const} \NormalTok{T,}
\NormalTok{\}}

\KeywordTok{impl}\NormalTok{<T> RawValIter<T> \{}
    \KeywordTok{unsafe} \KeywordTok{fn} \NormalTok{new(slice: &[T]) -> }\KeywordTok{Self} \NormalTok{\{}
        \NormalTok{RawValIter \{}
            \NormalTok{start: slice.as_ptr(),}
            \NormalTok{end: }\KeywordTok{if} \NormalTok{mem::size_of::<T>() == }\DecValTok{0} \NormalTok{\{}
                \NormalTok{((slice.as_ptr() }\KeywordTok{as} \DataTypeTok{usize}\NormalTok{) + slice.len()) }\KeywordTok{as} \NormalTok{*}\KeywordTok{const} \NormalTok{_}
            \NormalTok{\} }\KeywordTok{else} \KeywordTok{if} \NormalTok{slice.len() == }\DecValTok{0} \NormalTok{\{}
                \NormalTok{slice.as_ptr()}
            \NormalTok{\} }\KeywordTok{else} \NormalTok{\{}
                \NormalTok{slice.as_ptr().offset(slice.len() }\KeywordTok{as} \DataTypeTok{isize}\NormalTok{)}
            \NormalTok{\}}
        \NormalTok{\}}
    \NormalTok{\}}
\NormalTok{\}}

\KeywordTok{impl}\NormalTok{<T> }\BuiltInTok{Iterator} \KeywordTok{for} \NormalTok{RawValIter<T> \{}
    \KeywordTok{type} \NormalTok{Item = T;}
    \KeywordTok{fn} \NormalTok{next(&}\KeywordTok{mut} \KeywordTok{self}\NormalTok{) -> }\DataTypeTok{Option}\NormalTok{<T> \{}
        \KeywordTok{if} \KeywordTok{self}\NormalTok{.start == }\KeywordTok{self}\NormalTok{.end \{}
            \ConstantTok{None}
        \NormalTok{\} }\KeywordTok{else} \NormalTok{\{}
            \KeywordTok{unsafe} \NormalTok{\{}
                \KeywordTok{let} \NormalTok{result = ptr::read(}\KeywordTok{self}\NormalTok{.start);}
                \KeywordTok{self}\NormalTok{.start = }\KeywordTok{if} \NormalTok{mem::size_of::<T>() == }\DecValTok{0} \NormalTok{\{}
                    \NormalTok{(}\KeywordTok{self}\NormalTok{.start }\KeywordTok{as} \DataTypeTok{usize} \NormalTok{+ }\DecValTok{1}\NormalTok{) }\KeywordTok{as} \NormalTok{*}\KeywordTok{const} \NormalTok{_}
                \NormalTok{\} }\KeywordTok{else} \NormalTok{\{}
                    \KeywordTok{self}\NormalTok{.start.offset(}\DecValTok{1}\NormalTok{)}
                \NormalTok{\};}
                \ConstantTok{Some}\NormalTok{(result)}
            \NormalTok{\}}
        \NormalTok{\}}
    \NormalTok{\}}

    \KeywordTok{fn} \NormalTok{size_hint(&}\KeywordTok{self}\NormalTok{) -> (}\DataTypeTok{usize}\NormalTok{, }\DataTypeTok{Option}\NormalTok{<}\DataTypeTok{usize}\NormalTok{>) \{}
        \KeywordTok{let} \NormalTok{elem_size = mem::size_of::<T>();}
        \KeywordTok{let} \NormalTok{len = (}\KeywordTok{self}\NormalTok{.end }\KeywordTok{as} \DataTypeTok{usize} \NormalTok{- }\KeywordTok{self}\NormalTok{.start }\KeywordTok{as} \DataTypeTok{usize}\NormalTok{)}
                  \NormalTok{/ }\KeywordTok{if} \NormalTok{elem_size == }\DecValTok{0} \NormalTok{\{ }\DecValTok{1} \NormalTok{\} }\KeywordTok{else} \NormalTok{\{ elem_size \};}
        \NormalTok{(len, }\ConstantTok{Some}\NormalTok{(len))}
    \NormalTok{\}}
\NormalTok{\}}

\KeywordTok{impl}\NormalTok{<T> }\BuiltInTok{DoubleEndedIterator} \KeywordTok{for} \NormalTok{RawValIter<T> \{}
    \KeywordTok{fn} \NormalTok{next_back(&}\KeywordTok{mut} \KeywordTok{self}\NormalTok{) -> }\DataTypeTok{Option}\NormalTok{<T> \{}
        \KeywordTok{if} \KeywordTok{self}\NormalTok{.start == }\KeywordTok{self}\NormalTok{.end \{}
            \ConstantTok{None}
        \NormalTok{\} }\KeywordTok{else} \NormalTok{\{}
            \KeywordTok{unsafe} \NormalTok{\{}
                \KeywordTok{self}\NormalTok{.end = }\KeywordTok{if} \NormalTok{mem::size_of::<T>() == }\DecValTok{0} \NormalTok{\{}
                    \NormalTok{(}\KeywordTok{self}\NormalTok{.end }\KeywordTok{as} \DataTypeTok{usize} \NormalTok{- }\DecValTok{1}\NormalTok{) }\KeywordTok{as} \NormalTok{*}\KeywordTok{const} \NormalTok{_}
                \NormalTok{\} }\KeywordTok{else} \NormalTok{\{}
                    \KeywordTok{self}\NormalTok{.end.offset(-}\DecValTok{1}\NormalTok{)}
                \NormalTok{\};}
                \ConstantTok{Some}\NormalTok{(ptr::read(}\KeywordTok{self}\NormalTok{.end))}
            \NormalTok{\}}
        \NormalTok{\}}
    \NormalTok{\}}
\NormalTok{\}}




\KeywordTok{pub} \KeywordTok{struct} \NormalTok{IntoIter<T> \{}
    \NormalTok{_buf: RawVec<T>, }\CommentTok{// we don't actually care about this. Just need it to live.}
    \NormalTok{iter: RawValIter<T>,}
\NormalTok{\}}

\KeywordTok{impl}\NormalTok{<T> }\BuiltInTok{Iterator} \KeywordTok{for} \NormalTok{IntoIter<T> \{}
    \KeywordTok{type} \NormalTok{Item = T;}
    \KeywordTok{fn} \NormalTok{next(&}\KeywordTok{mut} \KeywordTok{self}\NormalTok{) -> }\DataTypeTok{Option}\NormalTok{<T> \{ }\KeywordTok{self}\NormalTok{.iter.next() \}}
    \KeywordTok{fn} \NormalTok{size_hint(&}\KeywordTok{self}\NormalTok{) -> (}\DataTypeTok{usize}\NormalTok{, }\DataTypeTok{Option}\NormalTok{<}\DataTypeTok{usize}\NormalTok{>) \{ }\KeywordTok{self}\NormalTok{.iter.size_hint() \}}
\NormalTok{\}}

\KeywordTok{impl}\NormalTok{<T> }\BuiltInTok{DoubleEndedIterator} \KeywordTok{for} \NormalTok{IntoIter<T> \{}
    \KeywordTok{fn} \NormalTok{next_back(&}\KeywordTok{mut} \KeywordTok{self}\NormalTok{) -> }\DataTypeTok{Option}\NormalTok{<T> \{ }\KeywordTok{self}\NormalTok{.iter.next_back() \}}
\NormalTok{\}}

\KeywordTok{impl}\NormalTok{<T> }\BuiltInTok{Drop} \KeywordTok{for} \NormalTok{IntoIter<T> \{}
    \KeywordTok{fn} \NormalTok{drop(&}\KeywordTok{mut} \KeywordTok{self}\NormalTok{) \{}
        \KeywordTok{for} \NormalTok{_ }\KeywordTok{in} \NormalTok{&}\KeywordTok{mut} \NormalTok{*}\KeywordTok{self} \NormalTok{\{\}}
    \NormalTok{\}}
\NormalTok{\}}




\KeywordTok{pub} \KeywordTok{struct} \NormalTok{Drain<}\OtherTok{'a}\NormalTok{, T: }\OtherTok{'a}\NormalTok{> \{}
    \NormalTok{vec: PhantomData<&}\OtherTok{'a} \KeywordTok{mut} \DataTypeTok{Vec}\NormalTok{<T>>,}
    \NormalTok{iter: RawValIter<T>,}
\NormalTok{\}}

\KeywordTok{impl}\NormalTok{<}\OtherTok{'a}\NormalTok{, T> }\BuiltInTok{Iterator} \KeywordTok{for} \NormalTok{Drain<}\OtherTok{'a}\NormalTok{, T> \{}
    \KeywordTok{type} \NormalTok{Item = T;}
    \KeywordTok{fn} \NormalTok{next(&}\KeywordTok{mut} \KeywordTok{self}\NormalTok{) -> }\DataTypeTok{Option}\NormalTok{<T> \{ }\KeywordTok{self}\NormalTok{.iter.next_back() \}}
    \KeywordTok{fn} \NormalTok{size_hint(&}\KeywordTok{self}\NormalTok{) -> (}\DataTypeTok{usize}\NormalTok{, }\DataTypeTok{Option}\NormalTok{<}\DataTypeTok{usize}\NormalTok{>) \{ }\KeywordTok{self}\NormalTok{.iter.size_hint() \}}
\NormalTok{\}}

\KeywordTok{impl}\NormalTok{<}\OtherTok{'a}\NormalTok{, T> }\BuiltInTok{DoubleEndedIterator} \KeywordTok{for} \NormalTok{Drain<}\OtherTok{'a}\NormalTok{, T> \{}
    \KeywordTok{fn} \NormalTok{next_back(&}\KeywordTok{mut} \KeywordTok{self}\NormalTok{) -> }\DataTypeTok{Option}\NormalTok{<T> \{ }\KeywordTok{self}\NormalTok{.iter.next_back() \}}
\NormalTok{\}}

\KeywordTok{impl}\NormalTok{<}\OtherTok{'a}\NormalTok{, T> }\BuiltInTok{Drop} \KeywordTok{for} \NormalTok{Drain<}\OtherTok{'a}\NormalTok{, T> \{}
    \KeywordTok{fn} \NormalTok{drop(&}\KeywordTok{mut} \KeywordTok{self}\NormalTok{) \{}
        \CommentTok{// pre-drain the iter}
        \KeywordTok{for} \NormalTok{_ }\KeywordTok{in} \NormalTok{&}\KeywordTok{mut} \KeywordTok{self}\NormalTok{.iter \{\}}
    \NormalTok{\}}
\NormalTok{\}}

\CommentTok{/// Abort the process, we're out of memory!}
\CommentTok{///}
\CommentTok{/// In practice this is probably dead code on most OSes}
\KeywordTok{fn} \NormalTok{oom() \{}
    \NormalTok{::std::process::exit(-}\DecValTok{9999}\NormalTok{);}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\chapter{Implementing Arc and Mutex}\label{sec--arc-and-mutex}

Knowing the theory is all fine and good, but the \emph{best} way to
understand something is to use it. To better understand atomics and
interior mutability, we'll be implementing versions of the standard
library's Arc and Mutex types.

TODO: ALL OF THIS OMG



\end{document}
